{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Dell\\OneDrive\\Desktop\\BoTNeTIoT-L01-v2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7062606, 27)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
      "0                  1.000000         98.000000          0.000000e+00   \n",
      "1                  1.931640         98.000000          1.818989e-12   \n",
      "2                  2.904273         86.981750          2.311822e+02   \n",
      "3                  3.902546         83.655268          2.040614e+02   \n",
      "4                  4.902545         81.685828          1.775746e+02   \n",
      "...                     ...               ...                   ...   \n",
      "7062601            2.937269        217.763487          1.770682e+04   \n",
      "7062602            1.730254        282.630543          1.054589e+04   \n",
      "7062603            2.730251        299.980395          7.204117e+03   \n",
      "7062604            2.882414        216.723647          1.775308e+04   \n",
      "7062605            2.032574        154.377267          1.303249e+04   \n",
      "\n",
      "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
      "0             1.000000    98.000000     0.000000e+00        1.000000   \n",
      "1             1.931640    98.000000     1.818989e-12        1.931640   \n",
      "2             2.904273    86.981750     2.311822e+02        1.000000   \n",
      "3             3.902546    83.655268     2.040614e+02        1.000000   \n",
      "4             4.902545    81.685828     1.775746e+02        2.000000   \n",
      "...                ...          ...              ...             ...   \n",
      "7062601       2.937269   217.763487     1.770682e+04        1.220882   \n",
      "7062602       1.730254   282.630543     1.054589e+04        1.213342   \n",
      "7062603       2.730251   299.980395     7.204117e+03        1.213352   \n",
      "7062604       2.882414   216.723647     1.775308e+04        1.209274   \n",
      "7062605       2.032574   154.377267     1.303249e+04        1.299681   \n",
      "\n",
      "         HH_L0.1_mean   HH_L0.1_std  HH_L0.1_magnitude  ...  HpHp_L0.1_mean  \\\n",
      "0           98.000000  0.000000e+00          98.000000  ...       98.000000   \n",
      "1           98.000000  1.348699e-06         138.592929  ...       98.000000   \n",
      "2           66.000000  0.000000e+00         114.856432  ...       66.000000   \n",
      "3           74.000000  0.000000e+00          74.000000  ...       74.000000   \n",
      "4           74.000000  9.536743e-07          74.000000  ...       74.000000   \n",
      "...               ...           ...                ...  ...             ...   \n",
      "7062601     60.000000  9.540000e-07          84.852814  ...       60.000000   \n",
      "7062602    330.000000  5.390000e-06         431.490440  ...      330.000000   \n",
      "7062603    330.000000  6.610000e-06         431.490440  ...      330.000000   \n",
      "7062604     60.000000  6.740000e-07          84.852814  ...       60.000000   \n",
      "7062605    145.339354  1.010891e+02         195.783485  ...      145.339354   \n",
      "\n",
      "         HpHp_L0.1_std  HpHp_L0.1_magnitude  HpHp_L0.1_radius  \\\n",
      "0         0.000000e+00            98.000000      0.000000e+00   \n",
      "1         1.348699e-06           138.592929      1.818989e-12   \n",
      "2         0.000000e+00           114.856432      0.000000e+00   \n",
      "3         0.000000e+00            74.000000      0.000000e+00   \n",
      "4         0.000000e+00            74.000000      0.000000e+00   \n",
      "...                ...                  ...               ...   \n",
      "7062601   9.540000e-07            84.852814      1.290000e-12   \n",
      "7062602   5.390000e-06           431.490440      2.910000e-11   \n",
      "7062603   6.610000e-06           431.490440      4.370000e-11   \n",
      "7062604   6.740000e-07            84.852814      4.550000e-13   \n",
      "7062605   1.010891e+02           195.783485      1.218303e+04   \n",
      "\n",
      "         HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
      "0                0.000000e+00   0.000000e+00   \n",
      "1                0.000000e+00   0.000000e+00   \n",
      "2                0.000000e+00   0.000000e+00   \n",
      "3                0.000000e+00   0.000000e+00   \n",
      "4                0.000000e+00   0.000000e+00   \n",
      "...                       ...            ...   \n",
      "7062601          1.720000e-29   1.890000e-17   \n",
      "7062602          7.390000e-83   0.000000e+00   \n",
      "7062603          1.560000e-81   0.000000e+00   \n",
      "7062604          8.910000e-30   0.000000e+00   \n",
      "7062605          1.917443e+03   2.328946e-01   \n",
      "\n",
      "                                      Device_Name  Attack  Attack_subType  \\\n",
      "0                                Danmini_Doorbell  gafgyt           combo   \n",
      "1                                Danmini_Doorbell  gafgyt           combo   \n",
      "2                                Danmini_Doorbell  gafgyt           combo   \n",
      "3                                Danmini_Doorbell  gafgyt           combo   \n",
      "4                                Danmini_Doorbell  gafgyt           combo   \n",
      "...                                           ...     ...             ...   \n",
      "7062601  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062602  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062603  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062604  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062605  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "\n",
      "         label  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "...        ...  \n",
      "7062601      1  \n",
      "7062602      1  \n",
      "7062603      1  \n",
      "7062604      1  \n",
      "7062605      1  \n",
      "\n",
      "[7062606 rows x 27 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
      "0                  1.000000         98.000000          0.000000e+00   \n",
      "1                  1.931640         98.000000          1.818989e-12   \n",
      "2                  2.904273         86.981750          2.311822e+02   \n",
      "3                  3.902546         83.655268          2.040614e+02   \n",
      "4                  4.902545         81.685828          1.775746e+02   \n",
      "...                     ...               ...                   ...   \n",
      "7062601            2.937269        217.763487          1.770682e+04   \n",
      "7062602            1.730254        282.630543          1.054589e+04   \n",
      "7062603            2.730251        299.980395          7.204117e+03   \n",
      "7062604            2.882414        216.723647          1.775308e+04   \n",
      "7062605            2.032574        154.377267          1.303249e+04   \n",
      "\n",
      "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
      "0             1.000000    98.000000     0.000000e+00        1.000000   \n",
      "1             1.931640    98.000000     1.818989e-12        1.931640   \n",
      "2             2.904273    86.981750     2.311822e+02        1.000000   \n",
      "3             3.902546    83.655268     2.040614e+02        1.000000   \n",
      "4             4.902545    81.685828     1.775746e+02        2.000000   \n",
      "...                ...          ...              ...             ...   \n",
      "7062601       2.937269   217.763487     1.770682e+04        1.220882   \n",
      "7062602       1.730254   282.630543     1.054589e+04        1.213342   \n",
      "7062603       2.730251   299.980395     7.204117e+03        1.213352   \n",
      "7062604       2.882414   216.723647     1.775308e+04        1.209274   \n",
      "7062605       2.032574   154.377267     1.303249e+04        1.299681   \n",
      "\n",
      "         HH_L0.1_mean   HH_L0.1_std  HH_L0.1_magnitude  ...  HpHp_L0.1_mean  \\\n",
      "0           98.000000  0.000000e+00          98.000000  ...       98.000000   \n",
      "1           98.000000  1.348699e-06         138.592929  ...       98.000000   \n",
      "2           66.000000  0.000000e+00         114.856432  ...       66.000000   \n",
      "3           74.000000  0.000000e+00          74.000000  ...       74.000000   \n",
      "4           74.000000  9.536743e-07          74.000000  ...       74.000000   \n",
      "...               ...           ...                ...  ...             ...   \n",
      "7062601     60.000000  9.540000e-07          84.852814  ...       60.000000   \n",
      "7062602    330.000000  5.390000e-06         431.490440  ...      330.000000   \n",
      "7062603    330.000000  6.610000e-06         431.490440  ...      330.000000   \n",
      "7062604     60.000000  6.740000e-07          84.852814  ...       60.000000   \n",
      "7062605    145.339354  1.010891e+02         195.783485  ...      145.339354   \n",
      "\n",
      "         HpHp_L0.1_std  HpHp_L0.1_magnitude  HpHp_L0.1_radius  \\\n",
      "0         0.000000e+00            98.000000      0.000000e+00   \n",
      "1         1.348699e-06           138.592929      1.818989e-12   \n",
      "2         0.000000e+00           114.856432      0.000000e+00   \n",
      "3         0.000000e+00            74.000000      0.000000e+00   \n",
      "4         0.000000e+00            74.000000      0.000000e+00   \n",
      "...                ...                  ...               ...   \n",
      "7062601   9.540000e-07            84.852814      1.290000e-12   \n",
      "7062602   5.390000e-06           431.490440      2.910000e-11   \n",
      "7062603   6.610000e-06           431.490440      4.370000e-11   \n",
      "7062604   6.740000e-07            84.852814      4.550000e-13   \n",
      "7062605   1.010891e+02           195.783485      1.218303e+04   \n",
      "\n",
      "         HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
      "0                0.000000e+00   0.000000e+00   \n",
      "1                0.000000e+00   0.000000e+00   \n",
      "2                0.000000e+00   0.000000e+00   \n",
      "3                0.000000e+00   0.000000e+00   \n",
      "4                0.000000e+00   0.000000e+00   \n",
      "...                       ...            ...   \n",
      "7062601          1.720000e-29   1.890000e-17   \n",
      "7062602          7.390000e-83   0.000000e+00   \n",
      "7062603          1.560000e-81   0.000000e+00   \n",
      "7062604          8.910000e-30   0.000000e+00   \n",
      "7062605          1.917443e+03   2.328946e-01   \n",
      "\n",
      "                                      Device_Name  Attack  Attack_subType  \\\n",
      "0                                Danmini_Doorbell  gafgyt           combo   \n",
      "1                                Danmini_Doorbell  gafgyt           combo   \n",
      "2                                Danmini_Doorbell  gafgyt           combo   \n",
      "3                                Danmini_Doorbell  gafgyt           combo   \n",
      "4                                Danmini_Doorbell  gafgyt           combo   \n",
      "...                                           ...     ...             ...   \n",
      "7062601  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062602  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062603  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062604  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "7062605  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
      "\n",
      "         label  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "...        ...  \n",
      "7062601      1  \n",
      "7062602      1  \n",
      "7062603      1  \n",
      "7062604      1  \n",
      "7062605      1  \n",
      "\n",
      "[7062606 rows x 27 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MI_dir_L0.1_weight', 'MI_dir_L0.1_mean', 'MI_dir_L0.1_variance',\n",
      "       'H_L0.1_weight', 'H_L0.1_mean', 'H_L0.1_variance', 'HH_L0.1_weight',\n",
      "       'HH_L0.1_mean', 'HH_L0.1_std', 'HH_L0.1_magnitude', 'HH_L0.1_radius',\n",
      "       'HH_L0.1_covariance', 'HH_L0.1_pcc', 'HH_jit_L0.1_weight',\n",
      "       'HH_jit_L0.1_mean', 'HH_jit_L0.1_variance', 'HpHp_L0.1_weight',\n",
      "       'HpHp_L0.1_mean', 'HpHp_L0.1_std', 'HpHp_L0.1_magnitude',\n",
      "       'HpHp_L0.1_radius', 'HpHp_L0.1_covariance', 'HpHp_L0.1_pcc',\n",
      "       'Device_Name', 'Attack', 'Attack_subType', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_dir_L0.1_weight      0\n",
      "MI_dir_L0.1_mean        0\n",
      "MI_dir_L0.1_variance    0\n",
      "H_L0.1_weight           0\n",
      "H_L0.1_mean             0\n",
      "H_L0.1_variance         0\n",
      "HH_L0.1_weight          0\n",
      "HH_L0.1_mean            0\n",
      "HH_L0.1_std             0\n",
      "HH_L0.1_magnitude       0\n",
      "HH_L0.1_radius          0\n",
      "HH_L0.1_covariance      0\n",
      "HH_L0.1_pcc             0\n",
      "HH_jit_L0.1_weight      0\n",
      "HH_jit_L0.1_mean        0\n",
      "HH_jit_L0.1_variance    0\n",
      "HpHp_L0.1_weight        0\n",
      "HpHp_L0.1_mean          0\n",
      "HpHp_L0.1_std           0\n",
      "HpHp_L0.1_magnitude     0\n",
      "HpHp_L0.1_radius        0\n",
      "HpHp_L0.1_covariance    0\n",
      "HpHp_L0.1_pcc           0\n",
      "Device_Name             0\n",
      "Attack                  0\n",
      "Attack_subType          0\n",
      "label                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7062606 entries, 0 to 7062605\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   MI_dir_L0.1_weight    float64\n",
      " 1   MI_dir_L0.1_mean      float64\n",
      " 2   MI_dir_L0.1_variance  float64\n",
      " 3   H_L0.1_weight         float64\n",
      " 4   H_L0.1_mean           float64\n",
      " 5   H_L0.1_variance       float64\n",
      " 6   HH_L0.1_weight        float64\n",
      " 7   HH_L0.1_mean          float64\n",
      " 8   HH_L0.1_std           float64\n",
      " 9   HH_L0.1_magnitude     float64\n",
      " 10  HH_L0.1_radius        float64\n",
      " 11  HH_L0.1_covariance    float64\n",
      " 12  HH_L0.1_pcc           float64\n",
      " 13  HH_jit_L0.1_weight    float64\n",
      " 14  HH_jit_L0.1_mean      float64\n",
      " 15  HH_jit_L0.1_variance  float64\n",
      " 16  HpHp_L0.1_weight      float64\n",
      " 17  HpHp_L0.1_mean        float64\n",
      " 18  HpHp_L0.1_std         float64\n",
      " 19  HpHp_L0.1_magnitude   float64\n",
      " 20  HpHp_L0.1_radius      float64\n",
      " 21  HpHp_L0.1_covariance  float64\n",
      " 22  HpHp_L0.1_pcc         float64\n",
      " 23  Device_Name           object \n",
      " 24  Attack                object \n",
      " 25  Attack_subType        object \n",
      " 26  label                 int64  \n",
      "dtypes: float64(23), int64(1), object(3)\n",
      "memory usage: 1.4+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0                  1.000000         98.000000          0.000000e+00   \n",
       "1                  1.931640         98.000000          1.818989e-12   \n",
       "2                  2.904273         86.981750          2.311822e+02   \n",
       "3                  3.902546         83.655268          2.040614e+02   \n",
       "4                  4.902545         81.685828          1.775746e+02   \n",
       "...                     ...               ...                   ...   \n",
       "7062601            2.937269        217.763487          1.770682e+04   \n",
       "7062602            1.730254        282.630543          1.054589e+04   \n",
       "7062603            2.730251        299.980395          7.204117e+03   \n",
       "7062604            2.882414        216.723647          1.775308e+04   \n",
       "7062605            2.032574        154.377267          1.303249e+04   \n",
       "\n",
       "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
       "0             1.000000    98.000000     0.000000e+00        1.000000   \n",
       "1             1.931640    98.000000     1.818989e-12        1.931640   \n",
       "2             2.904273    86.981750     2.311822e+02        1.000000   \n",
       "3             3.902546    83.655268     2.040614e+02        1.000000   \n",
       "4             4.902545    81.685828     1.775746e+02        2.000000   \n",
       "...                ...          ...              ...             ...   \n",
       "7062601       2.937269   217.763487     1.770682e+04        1.220882   \n",
       "7062602       1.730254   282.630543     1.054589e+04        1.213342   \n",
       "7062603       2.730251   299.980395     7.204117e+03        1.213352   \n",
       "7062604       2.882414   216.723647     1.775308e+04        1.209274   \n",
       "7062605       2.032574   154.377267     1.303249e+04        1.299681   \n",
       "\n",
       "         HH_L0.1_mean   HH_L0.1_std  HH_L0.1_magnitude  ...  HpHp_L0.1_mean  \\\n",
       "0           98.000000  0.000000e+00          98.000000  ...       98.000000   \n",
       "1           98.000000  1.348699e-06         138.592929  ...       98.000000   \n",
       "2           66.000000  0.000000e+00         114.856432  ...       66.000000   \n",
       "3           74.000000  0.000000e+00          74.000000  ...       74.000000   \n",
       "4           74.000000  9.536743e-07          74.000000  ...       74.000000   \n",
       "...               ...           ...                ...  ...             ...   \n",
       "7062601     60.000000  9.540000e-07          84.852814  ...       60.000000   \n",
       "7062602    330.000000  5.390000e-06         431.490440  ...      330.000000   \n",
       "7062603    330.000000  6.610000e-06         431.490440  ...      330.000000   \n",
       "7062604     60.000000  6.740000e-07          84.852814  ...       60.000000   \n",
       "7062605    145.339354  1.010891e+02         195.783485  ...      145.339354   \n",
       "\n",
       "         HpHp_L0.1_std  HpHp_L0.1_magnitude  HpHp_L0.1_radius  \\\n",
       "0         0.000000e+00            98.000000      0.000000e+00   \n",
       "1         1.348699e-06           138.592929      1.818989e-12   \n",
       "2         0.000000e+00           114.856432      0.000000e+00   \n",
       "3         0.000000e+00            74.000000      0.000000e+00   \n",
       "4         0.000000e+00            74.000000      0.000000e+00   \n",
       "...                ...                  ...               ...   \n",
       "7062601   9.540000e-07            84.852814      1.290000e-12   \n",
       "7062602   5.390000e-06           431.490440      2.910000e-11   \n",
       "7062603   6.610000e-06           431.490440      4.370000e-11   \n",
       "7062604   6.740000e-07            84.852814      4.550000e-13   \n",
       "7062605   1.010891e+02           195.783485      1.218303e+04   \n",
       "\n",
       "         HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
       "0                0.000000e+00   0.000000e+00   \n",
       "1                0.000000e+00   0.000000e+00   \n",
       "2                0.000000e+00   0.000000e+00   \n",
       "3                0.000000e+00   0.000000e+00   \n",
       "4                0.000000e+00   0.000000e+00   \n",
       "...                       ...            ...   \n",
       "7062601          1.720000e-29   1.890000e-17   \n",
       "7062602          7.390000e-83   0.000000e+00   \n",
       "7062603          1.560000e-81   0.000000e+00   \n",
       "7062604          8.910000e-30   0.000000e+00   \n",
       "7062605          1.917443e+03   2.328946e-01   \n",
       "\n",
       "                                      Device_Name  Attack  Attack_subType  \\\n",
       "0                                Danmini_Doorbell  gafgyt           combo   \n",
       "1                                Danmini_Doorbell  gafgyt           combo   \n",
       "2                                Danmini_Doorbell  gafgyt           combo   \n",
       "3                                Danmini_Doorbell  gafgyt           combo   \n",
       "4                                Danmini_Doorbell  gafgyt           combo   \n",
       "...                                           ...     ...             ...   \n",
       "7062601  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
       "7062602  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
       "7062603  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
       "7062604  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
       "7062605  SimpleHome_XCS7_1003_WHT_Security_Camera  Normal          Normal   \n",
       "\n",
       "         label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "7062601      1  \n",
       "7062602      1  \n",
       "7062603      1  \n",
       "7062604      1  \n",
       "7062605      1  \n",
       "\n",
       "[7062606 rows x 27 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display first 10 rows in the dataset\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.1_mean</th>\n",
       "      <th>MI_dir_L0.1_variance</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.1_mean</th>\n",
       "      <th>H_L0.1_variance</th>\n",
       "      <th>HH_L0.1_weight</th>\n",
       "      <th>HH_L0.1_mean</th>\n",
       "      <th>HH_L0.1_std</th>\n",
       "      <th>HH_L0.1_magnitude</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L0.1_mean</th>\n",
       "      <th>HH_jit_L0.1_variance</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.1_mean</th>\n",
       "      <th>HpHp_L0.1_std</th>\n",
       "      <th>HpHp_L0.1_magnitude</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "      <td>7.062606e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.400682e+03</td>\n",
       "      <td>1.794441e+02</td>\n",
       "      <td>1.931062e+04</td>\n",
       "      <td>3.400682e+03</td>\n",
       "      <td>1.794441e+02</td>\n",
       "      <td>1.931066e+04</td>\n",
       "      <td>1.892359e+03</td>\n",
       "      <td>1.792406e+02</td>\n",
       "      <td>4.415659e+00</td>\n",
       "      <td>1.865562e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.497349e+08</td>\n",
       "      <td>1.114786e+16</td>\n",
       "      <td>1.369083e+02</td>\n",
       "      <td>1.792334e+02</td>\n",
       "      <td>1.912623e+00</td>\n",
       "      <td>1.842961e+02</td>\n",
       "      <td>9.254144e+02</td>\n",
       "      <td>9.101316e+01</td>\n",
       "      <td>1.845142e-03</td>\n",
       "      <td>7.871485e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.897012e+03</td>\n",
       "      <td>1.537109e+02</td>\n",
       "      <td>2.636844e+04</td>\n",
       "      <td>2.897012e+03</td>\n",
       "      <td>1.537107e+02</td>\n",
       "      <td>2.636842e+04</td>\n",
       "      <td>2.523083e+03</td>\n",
       "      <td>2.059018e+02</td>\n",
       "      <td>2.243629e+01</td>\n",
       "      <td>2.067658e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.459028e+08</td>\n",
       "      <td>7.282259e+16</td>\n",
       "      <td>6.510637e+02</td>\n",
       "      <td>2.061473e+02</td>\n",
       "      <td>2.013019e+01</td>\n",
       "      <td>2.077680e+02</td>\n",
       "      <td>1.463365e+04</td>\n",
       "      <td>1.976009e+03</td>\n",
       "      <td>5.208508e-02</td>\n",
       "      <td>2.692932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484468e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.312975e+05</td>\n",
       "      <td>-1.586467e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.041758e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.644882e+03</td>\n",
       "      <td>7.412707e+01</td>\n",
       "      <td>9.807711e+01</td>\n",
       "      <td>3.644882e+03</td>\n",
       "      <td>7.412707e+01</td>\n",
       "      <td>9.810144e+01</td>\n",
       "      <td>1.071281e+00</td>\n",
       "      <td>7.020764e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.399665e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.745729e+08</td>\n",
       "      <td>1.501619e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.600001e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.354692e+03</td>\n",
       "      <td>3.486463e+02</td>\n",
       "      <td>4.887076e+04</td>\n",
       "      <td>6.354692e+03</td>\n",
       "      <td>3.486463e+02</td>\n",
       "      <td>4.887076e+04</td>\n",
       "      <td>4.201684e+03</td>\n",
       "      <td>9.314709e+01</td>\n",
       "      <td>3.293467e+00</td>\n",
       "      <td>1.344109e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505914e+09</td>\n",
       "      <td>6.062294e+10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.370625e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.946997e+03</td>\n",
       "      <td>1.401994e+03</td>\n",
       "      <td>4.520011e+05</td>\n",
       "      <td>8.946997e+03</td>\n",
       "      <td>1.401994e+03</td>\n",
       "      <td>4.520011e+05</td>\n",
       "      <td>7.944987e+03</td>\n",
       "      <td>1.470000e+03</td>\n",
       "      <td>6.784580e+02</td>\n",
       "      <td>1.470000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534253e+09</td>\n",
       "      <td>5.880000e+17</td>\n",
       "      <td>4.594455e+03</td>\n",
       "      <td>1.470000e+03</td>\n",
       "      <td>6.863705e+02</td>\n",
       "      <td>1.470000e+03</td>\n",
       "      <td>5.014297e+05</td>\n",
       "      <td>1.406094e+05</td>\n",
       "      <td>2.760701e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "count        7.062606e+06      7.062606e+06          7.062606e+06   \n",
       "mean         3.400682e+03      1.794441e+02          1.931062e+04   \n",
       "std          2.897012e+03      1.537109e+02          2.636844e+04   \n",
       "min          1.000000e+00      6.000000e+01          0.000000e+00   \n",
       "25%          1.000000e+00      6.000000e+01          0.000000e+00   \n",
       "50%          3.644882e+03      7.412707e+01          9.807711e+01   \n",
       "75%          6.354692e+03      3.486463e+02          4.887076e+04   \n",
       "max          8.946997e+03      1.401994e+03          4.520011e+05   \n",
       "\n",
       "       H_L0.1_weight   H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
       "count   7.062606e+06  7.062606e+06     7.062606e+06    7.062606e+06   \n",
       "mean    3.400682e+03  1.794441e+02     1.931066e+04    1.892359e+03   \n",
       "std     2.897012e+03  1.537107e+02     2.636842e+04    2.523083e+03   \n",
       "min     1.000000e+00  6.000000e+01     0.000000e+00    1.000000e+00   \n",
       "25%     1.000000e+00  6.000000e+01     0.000000e+00    1.000000e+00   \n",
       "50%     3.644882e+03  7.412707e+01     9.810144e+01    1.071281e+00   \n",
       "75%     6.354692e+03  3.486463e+02     4.887076e+04    4.201684e+03   \n",
       "max     8.946997e+03  1.401994e+03     4.520011e+05    7.944987e+03   \n",
       "\n",
       "       HH_L0.1_mean   HH_L0.1_std  HH_L0.1_magnitude  ...  HH_jit_L0.1_mean  \\\n",
       "count  7.062606e+06  7.062606e+06       7.062606e+06  ...      7.062606e+06   \n",
       "mean   1.792406e+02  4.415659e+00       1.865562e+02  ...      7.497349e+08   \n",
       "std    2.059018e+02  2.243629e+01       2.067658e+02  ...      7.459028e+08   \n",
       "min    6.000000e+01  0.000000e+00       6.000000e+01  ...      2.484468e-03   \n",
       "25%    6.000000e+01  0.000000e+00       6.000000e+01  ...      4.041758e+01   \n",
       "50%    7.020764e+01  0.000000e+00       7.399665e+01  ...      6.745729e+08   \n",
       "75%    9.314709e+01  3.293467e+00       1.344109e+02  ...      1.505914e+09   \n",
       "max    1.470000e+03  6.784580e+02       1.470000e+03  ...      1.534253e+09   \n",
       "\n",
       "       HH_jit_L0.1_variance  HpHp_L0.1_weight  HpHp_L0.1_mean  HpHp_L0.1_std  \\\n",
       "count          7.062606e+06      7.062606e+06    7.062606e+06   7.062606e+06   \n",
       "mean           1.114786e+16      1.369083e+02    1.792334e+02   1.912623e+00   \n",
       "std            7.282259e+16      6.510637e+02    2.061473e+02   2.013019e+01   \n",
       "min            0.000000e+00      1.000000e+00    6.000000e+01   0.000000e+00   \n",
       "25%            0.000000e+00      1.000000e+00    6.000000e+01   0.000000e+00   \n",
       "50%            1.501619e-03      1.000000e+00    6.600001e+01   0.000000e+00   \n",
       "75%            6.062294e+10      1.000000e+00    9.800000e+01   0.000000e+00   \n",
       "max            5.880000e+17      4.594455e+03    1.470000e+03   6.863705e+02   \n",
       "\n",
       "       HpHp_L0.1_magnitude  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
       "count         7.062606e+06      7.062606e+06          7.062606e+06   \n",
       "mean          1.842961e+02      9.254144e+02          9.101316e+01   \n",
       "std           2.077680e+02      1.463365e+04          1.976009e+03   \n",
       "min           6.000000e+01      0.000000e+00         -1.312975e+05   \n",
       "25%           6.000000e+01      0.000000e+00          0.000000e+00   \n",
       "50%           7.400000e+01      0.000000e+00          0.000000e+00   \n",
       "75%           1.370625e+02      0.000000e+00          0.000000e+00   \n",
       "max           1.470000e+03      5.014297e+05          1.406094e+05   \n",
       "\n",
       "       HpHp_L0.1_pcc         label  \n",
       "count   7.062606e+06  7.062606e+06  \n",
       "mean    1.845142e-03  7.871485e-02  \n",
       "std     5.208508e-02  2.692932e-01  \n",
       "min    -1.586467e+00  0.000000e+00  \n",
       "25%     0.000000e+00  0.000000e+00  \n",
       "50%     0.000000e+00  0.000000e+00  \n",
       "75%     0.000000e+00  0.000000e+00  \n",
       "max     2.760701e+00  1.000000e+00  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sn.countplot(y=data['Attack'])\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAIjCAYAAABs0vDpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC13UlEQVR4nOzdd3xO5//H8fcdkb3MxEyQIYkRRK1+EXvTUqNaouhQmxq1YleNoq3RqoQ2VtFSq1TN2COhpFat2qUSsSX37w9x/9ySkEQi2r6ej8d5PNznXOc6n3Ny823e3+u6jsFoNBoFAAAAAACA/zyLrC4AAAAAAAAALweCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCAAAAAABAIoIiAAAAAAAASCIoAgAAAAAAQCKCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAD8Y4WEhMhgMLyQa1WvXl3Vq1c3fd64caMMBoMWL178Qq4fHBwsDw+PF3Kt9IqLi1OnTp3k5uYmg8Ggnj17vpDrBgcHy8HBIUP7fPLnDQD/FQRFAAAAeCmEhYXJYDCYNhsbG+XPn19169bV1KlTdePGjQy5zvnz5xUSEqLIyMgM6S8jvcy1pcaYMWMUFhamDz74QN9++63efvvtFNt6eHioUaNGL7A6AEBqWGZ1AQAAAMDjRowYoSJFiuj+/fu6ePGiNm7cqJ49e2rSpElavny5SpUqZWo7ePBgDRgwIE39nz9/XsOHD5eHh4cCAgJSfd7atWvTdJ30eFptX3/9tRISEjK9hufx66+/qmLFiho2bFhWlwIASCeCIgAAALxU6tevr8DAQNPngQMH6tdff1WjRo3UpEkTRUdHy9bWVpJkaWkpS8vM/U/aW7duyc7OTlZWVpl6nWfJnj17ll4/NS5fviw/P7+sLgMA8ByYegYAAICXXo0aNTRkyBCdPn1a3333nWl/cmsUrVu3Tq+++qpcXFzk4OAgHx8fffzxx5IeritUvnx5SVKHDh1M09zCwsIkPVyXpkSJEtq7d6+qVq0qOzs707kprVkTHx+vjz/+WG5ubrK3t1eTJk109uxZszYeHh4KDg5Ocu7jfT6rtuTWKLp586b69OmjQoUKydraWj4+PpowYYKMRqNZO4PBoK5du+rHH39UiRIlZG1tLX9/f61Zsyb5B/6Ey5cvq2PHjnJ1dZWNjY1Kly6tOXPmmI4/Wq/p5MmTWrlypan2U6dOpar/lGzZskVvvPGGChcuLGtraxUqVEi9evXS7du3k23/xx9/qG7durK3t1f+/Pk1YsSIJM8iISFBkydPlr+/v2xsbOTq6qr33ntPf//99zPr+fzzz+Xv7y87OzvlyJFDgYGBmjdv3nPdIwC8bBhRBAAAgH+Et99+Wx9//LHWrl2rzp07J9vm0KFDatSokUqVKqURI0bI2tpax48fV0REhCTJ19dXI0aM0NChQ/Xuu+/qf//7nySpcuXKpj6uXr2q+vXrq3Xr1nrrrbfk6ur61LpGjx4tg8Gg/v376/Lly5o8ebJq1aqlyMhI08in1EhNbY8zGo1q0qSJNmzYoI4dOyogIEA///yzPvroI507d06fffaZWfutW7dq6dKl6tKlixwdHTV16lQ1b95cZ86cUa5cuVKs6/bt26pevbqOHz+url27qkiRIvr+++8VHBys69evq0ePHvL19dW3336rXr16qWDBgurTp48kKU+ePKm+/+R8//33unXrlj744APlypVLu3bt0ueff64///xT33//vVnb+Ph41atXTxUrVtSnn36qNWvWaNiwYXrw4IFGjBhhavfee+8pLCxMHTp0UPfu3XXy5El98cUX2r9/vyIiIlIcufX111+re/fuatGihXr06KE7d+7owIED2rlzp958883nuk8AeKkYAQAAgJdAaGioUZJx9+7dKbZxdnY2lilTxvR52LBhxsf/k/azzz4zSjJeuXIlxT52795tlGQMDQ1NcqxatWpGScYZM2Yke6xatWqmzxs2bDBKMhYoUMAYGxtr2r9o0SKjJOOUKVNM+9zd3Y3t27d/Zp9Pq619+/ZGd3d30+cff/zRKMk4atQos3YtWrQwGgwG4/Hjx037JBmtrKzM9kVFRRklGT///PMk13rc5MmTjZKM3333nWnfvXv3jJUqVTI6ODiY3bu7u7uxYcOGT+0vLW1v3bqVZN/YsWONBoPBePr0adO+9u3bGyUZu3XrZtqXkJBgbNiwodHKysr0fdiyZYtRkjE8PNyszzVr1iTZ/+TPpmnTpkZ/f/9U3RsA/JMx9QwAAAD/GA4ODk99+5mLi4skadmyZele+Nna2lodOnRIdft27drJ0dHR9LlFixbKly+fVq1ala7rp9aqVauULVs2de/e3Wx/nz59ZDQatXr1arP9tWrVUrFixUyfS5UqJScnJ/3xxx/PvI6bm5vatGlj2pc9e3Z1795dcXFx2rRpUwbcTfIeH5F18+ZN/fXXX6pcubKMRqP279+fpH3Xrl1Nf3403e7evXv65ZdfJD0coeTs7KzatWvrr7/+Mm3lypWTg4ODNmzYkGItLi4u+vPPP7V79+4MvEMAePkQFAEAAOAfIy4uziyUeVKrVq1UpUoVderUSa6urmrdurUWLVqUptCoQIECaVq42svLy+yzwWCQp6fnc6/P8yynT59W/vz5kzwPX19f0/HHFS5cOEkfOXLkeObaPKdPn5aXl5csLMx/dUjpOhnpzJkzCg4OVs6cOeXg4KA8efKoWrVqkqSYmBizthYWFipatKjZPm9vb0ky/SyOHTummJgY5c2bV3ny5DHb4uLidPny5RRr6d+/vxwcHPTKK6/Iy8tLH374oWlKIwD8m7BGEQAAAP4R/vzzT8XExMjT0zPFNra2ttq8ebM2bNiglStXas2aNVq4cKFq1KihtWvXKlu2bM+8TlrWFUqtJxfcfiQ+Pj5VNWWElK5jfGKx55dFfHy8ateurWvXrql///4qXry47O3tde7cOQUHB6drxFhCQoLy5s2r8PDwZI8/bU0lX19fHTlyRCtWrNCaNWu0ZMkSTZs2TUOHDtXw4cPTXAsAvKwIigAAAPCP8O2330qS6tat+9R2FhYWqlmzpmrWrKlJkyZpzJgxGjRokDZs2KBatWqlGNqk17Fjx8w+G41GHT9+XKVKlTLty5Ejh65fv57k3NOnT5uNgklLbe7u7vrll19048YNs1FFv//+u+l4RnB3d9eBAweUkJBgNqooo6/zpIMHD+ro0aOaM2eO2rVrZ9q/bt26ZNsnJCTojz/+MI0ikqSjR49KkultccWKFdMvv/yiKlWqpCsQtLe3V6tWrdSqVSvdu3dPr7/+ukaPHq2BAwfKxsYmzf0BwMuIqWcAAAB46f36668aOXKkihQporZt26bY7tq1a0n2BQQESJLu3r0r6eEv+5KSDW7SY+7cuWbrJi1evFgXLlxQ/fr1TfuKFSumHTt26N69e6Z9K1as0NmzZ836SkttDRo0UHx8vL744guz/Z999pkMBoPZ9Z9HgwYNdPHiRS1cuNC078GDB/r888/l4OBgmgqW0R6NgHp8xJPRaNSUKVNSPOfxZ2E0GvXFF18oe/bsqlmzpiSpZcuWio+P18iRI5Oc++DBg6c+96tXr5p9trKykp+fn4xGo+7fv5+qewKAfwJGFAEAAOClsnr1av3+++968OCBLl26pF9//VXr1q2Tu7u7li9f/tSRGyNGjNDmzZvVsGFDubu76/Lly5o2bZoKFiyoV199VdLD0MbFxUUzZsyQo6Oj7O3tVaFCBRUpUiRd9ebMmVOvvvqqOnTooEuXLmny5Mny9PRU586dTW06deqkxYsXq169emrZsqVOnDih7777zmxx6bTW1rhxYwUFBWnQoEE6deqUSpcurbVr12rZsmXq2bNnkr7T691339XMmTMVHBysvXv3ysPDQ4sXL1ZERIQmT5781DWjnuX48eMaNWpUkv1lypRRnTp1VKxYMfXt21fnzp2Tk5OTlixZkuKaSjY2NlqzZo3at2+vChUqaPXq1Vq5cqU+/vhj05SyatWq6b333tPYsWMVGRmpOnXqKHv27Dp27Ji+//57TZkyRS1atEi2/zp16sjNzU1VqlSRq6uroqOj9cUXX6hhw4bP9QwA4KWTdS9cAwAAAP5faGioUZJps7KyMrq5uRlr165tnDJlitlr2B8ZNmyY8fH/pF2/fr2xadOmxvz58xutrKyM+fPnN7Zp08Z49OhRs/OWLVtm9PPzM1paWpq9jr5atWopvgL9ydelb9iwwSjJOH/+fOPAgQONefPmNdra2hobNmxo9ur2RyZOnGgsUKCA0dra2lilShXjnj17kvT5tNrat29vdHd3N2t748YNY69evYz58+c3Zs+e3ejl5WUcP368MSEhwaydJOOHH36YpCZ3d3dj+/btk73fx126dMnYoUMHY+7cuY1WVlbGkiVLmup6sr9nvfL+8baP/7wf3zp27Gg0Go3Gw4cPG2vVqmV0cHAw5s6d29i5c2djVFSU2XMxGh8+G3t7e+OJEyeMderUMdrZ2RldXV2Nw4YNM8bHxye59ldffWUsV66c0dbW1ujo6GgsWbKksV+/fsbz58+b2jz5s5k5c6axatWqxly5chmtra2NxYoVM3700UfGmJiYVN0vAPxTGIzGl3T1OgAAAAAAALxQrFEEAAAAAAAASQRFAAAAAAAASERQBAAAAAAAAEkERQAAAAAAAEhEUAQAAAAAAABJBEUAAAAAAABIZJnVBQAAMk9CQoLOnz8vR0dHGQyGrC4HAAAAQBYxGo26ceOG8ufPLwuLlMcNERQBwL/Y+fPnVahQoawuAwAAAMBL4uzZsypYsGCKxwmKAOBfzNHRUdLD/zFwcnLK4moAAAAAZJXY2FgVKlTI9DtCSgiKAOBf7NF0MycnJ4IiAAAAAM9ckoLFrAEAAAAAACCJoAgAAAAAAACJmHoGAP8BVQfPVzZr26wuAwAAAEhi7/h2WV0CHsOIIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCAAAAAABAIoIiAAAAAAAASCIoAgAAAAAAQCKCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCAAAAAABAIoIiAAAAAAAASCIoAgAAAAAAQCKCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCkAVOnTolg8GgyMjIVJ8TEhKigICATKspo6XnHpNTvXp19ezZ0/TZw8NDkydPfq4+AQAAACAlBEXAv1BwcLAMBoMMBoOyZ88uV1dX1a5dW7Nnz1ZCQkJWl6dChQrpwoULKlGiRKrP6du3r9avX5+qtiEhIab7t7S0VO7cuVW1alVNnjxZd+/eTW/ZAAAAAPCvR1AE/EvVq1dPFy5c0KlTp7R69WoFBQWpR48eatSokR48eJCltWXLlk1ubm6ytLRM9TkODg7KlStXqtv7+/vrwoULOnPmjDZs2KA33nhDY8eOVeXKlXXjxo30lJ1q9+7dy9T+AQAAACCzEBQB/1LW1tZyc3NTgQIFVLZsWX388cdatmyZVq9erbCwMEnSpEmTVLJkSdnb26tQoULq0qWL4uLiTH2EhYXJxcVFP//8s3x9feXg4GAKoB4JDg5Ws2bNNGbMGLm6usrFxUUjRozQgwcP9NFHHylnzpwqWLCgQkNDTec8OS1r48aNMhgMWr9+vQIDA2VnZ6fKlSvryJEjpnPSOvXM0tJSbm5uyp8/v0qWLKlu3bpp06ZN+u233zRu3DhTu7///lvt2rVTjhw5ZGdnp/r16+vYsWNmfS1ZskT+/v6ytraWh4eHJk6caHbcw8NDI0eOVLt27eTk5KR3333XdOz3339X5cqVZWNjoxIlSmjTpk1m5/7222+qX7++HBwc5Orqqrffflt//fVXqu/zSXfv3lVsbKzZBgAAAACpRVAE/IfUqFFDpUuX1tKlSyVJFhYWmjp1qg4dOqQ5c+bo119/Vb9+/czOuXXrliZMmKBvv/1Wmzdv1pkzZ9S3b1+zNr/++qvOnz+vzZs3a9KkSRo2bJgaNWqkHDlyaOfOnXr//ff13nvv6c8//3xqfYMGDdLEiRO1Z88eWVpa6p133snQ+y9evLjq169vun/pYdC1Z88eLV++XNu3b5fRaFSDBg10//59SdLevXvVsmVLtW7dWgcPHlRISIiGDBliCtsemTBhgkqXLq39+/dryJAhpv0fffSR+vTpo/3796tSpUpq3Lixrl69Kkm6fv26atSooTJlymjPnj1as2aNLl26pJYtW6b7HseOHStnZ2fTVqhQoXT3BQAAAOC/h6AI+I8pXry4Tp06JUnq2bOngoKC5OHhoRo1amjUqFFatGiRWfv79+9rxowZCgwMVNmyZdW1a9ckawXlzJlTU6dOlY+Pj9555x35+Pjo1q1b+vjjj+Xl5aWBAwfKyspKW7dufWpto0ePVrVq1eTn56cBAwZo27ZtunPnTqbd/7Fjx7R8+XLNmjVL//vf/1S6dGmFh4fr3Llz+vHHHyU9HHVVs2ZNDRkyRN7e3goODlbXrl01fvx4s35r1KihPn36qFixYipWrJhpf9euXdW8eXP5+vpq+vTpcnZ21jfffCNJ+uKLL1SmTBmNGTNGxYsXV5kyZTR79mxt2LBBR48eTdf9DRw4UDExMabt7Nmz6eoHAAAAwH8TQRHwH2M0GmUwGCRJv/zyi2rWrKkCBQrI0dFRb7/9tq5evapbt26Z2tvZ2ZkFH/ny5dPly5fN+vT395eFxf//c+Lq6qqSJUuaPmfLlk25cuVKct6TSpUqZXYdSc88J60ev//o6GhZWlqqQoUKpuO5cuWSj4+PoqOjTW2qVKli1keVKlV07NgxxcfHm/YFBgYme71KlSqZ/mxpaanAwEBT31FRUdqwYYMcHBxMW/HixSVJJ06cSNf9WVtby8nJyWwDAAAAgNRK/UqyAP4VoqOjVaRIEZ06dUqNGjXSBx98oNGjRytnzpzaunWrOnbsqHv37snOzk6SlD17drPzDQaDjEaj2b7k2iS371lvXHv8nEdhTka/pe3R/Wc0e3v7NJ8TFxenxo0bm62Z9MijoAwAAAAAXiRGFAH/Ib/++qsOHjyo5s2ba+/evUpISNDEiRNVsWJFeXt76/z581ldYqb6/ffftWbNGjVv3lyS5OvrqwcPHmjnzp2mNlevXtWRI0fk5+dnahMREWHWT0REhLy9vZUtW7ZnXnPHjh2mPz948EB79+6Vr6+vJKls2bI6dOiQPDw85OnpabalJ3gCAAAAgOdFUAT8S929e1cXL17UuXPntG/fPo0ZM0ZNmzZVo0aN1K5dO3l6eur+/fv6/PPP9ccff+jbb7/VjBkzsrrsDPPgwQNdvHhR58+f18GDB/X555+rWrVqCggI0EcffSRJ8vLyUtOmTdW5c2dt3bpVUVFReuutt1SgQAE1bdpUktSnTx+tX79eI0eO1NGjRzVnzhx98cUXSRb0TsmXX36pH374Qb///rs+/PBD/f3336ZFuj/88ENdu3ZNbdq00e7du3XixAn9/PPP6tChg9m0NgAAAAB4UQiKgH+pNWvWKF++fPLw8FC9evW0YcMGTZ06VcuWLVO2bNlUunRpTZo0SePGjVOJEiUUHh6usWPHZnXZGebQoUPKly+fChcurOrVq2vRokUaOHCgtmzZIgcHB1O70NBQlStXTo0aNVKlSpVkNBq1atUq0zS4smXLatGiRVqwYIFKlCihoUOHasSIEQoODk5VHZ988ok++eQTlS5dWlu3btXy5cuVO3duSVL+/PkVERGh+Ph41alTRyVLllTPnj3l4uJituYTAAAAALwoBuOTi40AAP41YmNj5ezsrNLdZiibtW1WlwMAAAAksXd8u6wu4T/h0e8GMTExT33pDf+XNQAAAAAAACQRFAH4B3r8dfJPblu2bMnq8gAAAADgH8syqwsAgLSKjIxM8ViBAgVeXCEAAAAA8C9DUATgH8fT0zOrSwAAAACAfyWmngEAAAAAAEASQREAAAAAAAASERQBAAAAAABAEkERAAAAAAAAEhEUAQAAAAAAQBJBEQAAAAAAABIRFAEAAAAAAEASQREAAAAAAAASERQBAAAAAABAkmSZ1QUAADLf5lFt5OTklNVlAAAAAHjJMaIIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIky6wuAACQ+c5+UlGONtmyugwAAIBUKzz0YFaXAPwnMaIIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIioD/NA8PD02ePDmry3iqkJAQBQQEZHUZAAAAAPCfQFAEvMSCg4NlMBiSbPXq1cvq0p7bxo0bk723x7eNGzdmdZkZLjg4WM2aNUvzeQRmAAAAAF4Ey6wuAMDT1atXT6GhoWb7rK2ts6iajFO5cmVduHDB9LlHjx6KjY01u9ecOXNmSlhkNBoVHx8vS0v+CQQAAACAxzGiCHjJWVtby83NzWzLkSOHJOn69et677335OrqKhsbG5UoUUIrVqwwnbtkyRL5+/vL2tpaHh4emjhxYpL+b9y4oTZt2sje3l4FChTQl19+aXb8+vXr6tSpk/LkySMnJyfVqFFDUVFRZm2WLVumsmXLysbGRkWLFtXw4cP14MGDp96XlZWV2T3Z2tomuVcrKytT+2+//VYeHh5ydnZW69atdePGDdOxhIQEjR07VkWKFJGtra1Kly6txYsXm44/Gr20evVqlStXTtbW1tq6dauqV6+ubt26qWfPnsqRI4dcXV319ddf6+bNm+rQoYMcHR3l6emp1atXm9W+adMmvfLKK7K2tla+fPk0YMAAs/tdvHixSpYsKVtbW+XKlUu1atXSzZs3FRISojlz5mjZsmVJRk31799f3t7esrOzU9GiRTVkyBDdv39fkhQWFqbhw4crKirKdF5YWNhTny8AAAAApAdBEfAPlZCQoPr16ysiIkLfffedDh8+rE8++UTZsmWTJO3du1ctW7ZU69atdfDgQYWEhGjIkCFJAobx48erdOnS2r9/vwYMGKAePXpo3bp1puNvvPGGLl++rNWrV2vv3r0qW7asatasqWvXrkmStmzZonbt2qlHjx46fPiwZs6cqbCwMI0ePTrD7vXEiRP68ccftWLFCq1YsUKbNm3SJ598Yjo+duxYzZ07VzNmzNChQ4fUq1cvvfXWW9q0aZNZPwMGDNAnn3yi6OholSpVSpI0Z84c5c6dW7t27VK3bt30wQcf6I033lDlypW1b98+1alTR2+//bZu3bolSTp37pwaNGig8uXLKyoqStOnT9c333yjUaNGSZIuXLigNm3a6J133lF0dLQ2btyo119/XUajUX379lXLli1Vr149XbhwQRcuXFDlypUlSY6OjgoLC9Phw4c1ZcoUff311/rss88kSa1atVKfPn3k7+9vOq9Vq1bJPqu7d+8qNjbWbAMAAACA1DIYjUZjVhcBIHnBwcH67rvvZGNjY7b/448/VmBgoOrXr6/o6Gh5e3snObdt27a6cuWK1q5da9rXr18/rVy5UocOHZL0cDFrX19fsxEzrVu3VmxsrFatWqWtW7eqYcOGunz5stl0N09PT/Xr10/vvvuuatWqpZo1a2rgwIGm499995369eun8+fPp+ler1+/rh9//NFsf0hIiMaPH6+LFy/K0dHRdB+bN2/Wjh07dPfuXeXMmVO//PKLKlWqZDqvU6dOunXrlubNm6eNGzcqKChIP/74o5o2bWpqU716dcXHx2vLli2SpPj4eDk7O+v111/X3LlzJUkXL15Uvnz5tH37dlWsWFGDBg3SkiVLFB0dLYPBIEmaNm2a+vfvr5iYGEVGRqpcuXI6deqU3N3dU32fT5owYYIWLFigPXv2mJ7Djz/+qMjIyKeeFxISouHDhyfZ/9tAXznaZHvquQAAAC+TwkMPZnUJwL9KbGysnJ2dFRMTIycnpxTbsUAH8JILCgrS9OnTzfblzJlTs2bNUsGCBZMNiSQpOjraLBSRpCpVqmjy5MmKj483jTx6PFx59PnRm9CioqIUFxenXLlymbW5ffu2Tpw4YWoTERFhNoIoPj5ed+7c0a1bt2RnZ5f2m36Ch4eHKSSSpHz58uny5cuSpOPHj+vWrVuqXbu22Tn37t1TmTJlzPYFBgYm6fvRyCJJypYtm3LlyqWSJUua9rm6ukqS6XrR0dGqVKmSKSSSHj7XuLg4/fnnnypdurRq1qypkiVLqm7duqpTp45atGhhmi6YkoULF2rq1Kk6ceKE4uLi9ODBg6f+452SgQMHqnfv3qbPsbGxKlSoUJr7AQAAAPDfRFAEvOTs7e3l6emZZL+trW2mXzsuLk758uVLdkFpFxcXU5vhw4fr9ddfT9LmyZFQ6ZU9e3azzwaDQQkJCabrS9LKlStVoEABs3ZPLvptb2+fqr4f3/coEHp0vWfJli2b1q1bp23btmnt2rX6/PPPNWjQIO3cuVNFihRJ9pzt27erbdu2Gj58uOrWrStnZ2ctWLAg2TWlnsXa2vpfsdg5AAAAgKxBUAT8Q5UqVUp//vmnjh49muyoIl9fX0VERJjti4iIkLe3t2k0kSTt2LHDrM2OHTvk6+srSSpbtqwuXrwoS0tLeXh4JFtH2bJldeTIkWTDrBfBz89P1tbWOnPmjKpVq5bp1/P19dWSJUtkNBpNIVJERIQcHR1VsGBBSQ/DpSpVqqhKlSoaOnSo3N3d9cMPP6h3796ysrJSfHy8WZ/btm2Tu7u7Bg0aZNp3+vRpszbJnQcAAAAAGY2gCHjJ3b17VxcvXjTbZ2lpqWrVqqlq1apq3ry5Jk2aJE9PT/3+++8yGAyqV6+e+vTpo/Lly2vkyJFq1aqVtm/fri+++ELTpk0z6ysiIkKffvqpmjVrpnXr1un777/XypUrJUm1atVSpUqV1KxZM3366afy9vbW+fPntXLlSr322msKDAzU0KFD1ahRIxUuXFgtWrSQhYWFoqKi9Ntvv5kWeM5Mjo6O6tu3r3r16qWEhAS9+uqriomJUUREhJycnNS+ffsMvV6XLl00efJkdevWTV27dtWRI0c0bNgw9e7dWxYWFtq5c6fWr1+vOnXqKG/evNq5c6euXLliCt88PDz0888/68iRI8qVK5ecnZ3l5eWlM2fOaMGCBSpfvrxWrlypH374wey6Hh4eOnnypCIjI1WwYEE5OjoycggAAABAhuOtZ8BLbs2aNcqXL5/Z9uqrr0qSlixZovLly6tNmzby8/NTv379TKNOypYtq0WLFmnBggUqUaKEhg4dqhEjRig4ONis/z59+mjPnj0qU6aMRo0apUmTJqlu3bqSHo6MWbVqlapWraoOHTrI29tbrVu31unTp01r99StW1crVqzQ2rVrVb58eVWsWFGfffZZsgs5Z5aRI0dqyJAhGjt2rHx9fVWvXj2tXLkyxalez6NAgQJatWqVdu3apdKlS+v9999Xx44dNXjwYEmSk5OTNm/erAYNGsjb21uDBw/WxIkTVb9+fUlS586d5ePjo8DAQOXJk0cRERFq0qSJevXqpa5duyogIEDbtm3TkCFDzK7bvHlz1atXT0FBQcqTJ4/mz5+f4fcGAAAAALz1DAD+xR692YC3ngEAgH8a3noGZKzUvvWMEUUAAAAAAACQRFAEIBOFh4fLwcEh2c3f3z+rywMAAAAAPIHFrAFkmiZNmqhChQrJHnvytfQAAAAAgKxHUAQg0zg6OsrR0TGrywAAAAAApBJTzwAAAAAAACCJoAgAAAAAAACJCIoAAAAAAAAgiaAIAAAAAAAAiQiKAAAAAAAAIImgCAAAAAAAAIkIigAAAAAAACCJoAgAAAAAAACJCIoAAAAAAAAgSbLM6gIAAJmv0IAdcnJyyuoyAAAAALzkGFEEAAAAAAAASQRFAAAAAAAASERQBAAAAAAAAEkERQAAAAAAAEhEUAQAAAAAAABJBEUAAAAAAABIRFAEAAAAAAAASQRFAAAAAAAASERQBAAAAAAAAEkERQAAAAAAAEhkmdUFAAAyX+0ZtWVpyz/5wD9JRLeIrC4BAAD8BzGiCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAhAlgsJCVFAQEBWl5GhgoOD1axZs+fqY+PGjTIYDLp+/bokKSwsTC4uLs9dGwAAAACkhKAIwFMFBwfLYDAk2erVq5dh1+jbt6/Wr1+fYf09Xqe9vb28vLwUHBysvXv3Ztg1AAAAAODfiKAIwDPVq1dPFy5cMNvmz5+fYf07ODgoV65cGdafJIWGhurChQs6dOiQvvzyS8XFxalChQqaO3duhl7nSfHx8UpISMjUawAAAABAZiEoAvBM1tbWcnNzM9ty5Mgh6eHonVmzZum1116TnZ2dvLy8tHz5ctO5j6ZPrV+/XoGBgbKzs1PlypV15MgRU5snp54lJCRoxIgRKliwoKytrRUQEKA1a9akqWYXFxe5ubnJw8NDderU0eLFi9W2bVt17dpVf//9t6ndkiVL5O/vL2tra3l4eGjixIlm/fz9999q166dcuTIITs7O9WvX1/Hjh0zHX80HWz58uXy8/OTtbW1zpw5Yzo+fPhw5cmTR05OTnr//fd17949s/scO3asihQpIltbW5UuXVqLFy9O030CAAAAQEYiKALw3IYPH66WLVvqwIEDatCggdq2batr166ZtRk0aJAmTpyoPXv2yNLSUu+8806K/U2ZMkUTJ07UhAkTdODAAdWtW1dNmjQxC2jSo1evXrpx44bWrVsnSdq7d69atmyp1q1b6+DBgwoJCdGQIUMUFhZmOic4OFh79uzR8uXLtX37dhmNRjVo0ED37983tbl165bGjRunWbNm6dChQ8qbN68kaf369YqOjtbGjRs1f/58LV26VMOHDzedN3bsWM2dO1czZszQoUOH1KtXL7311lvatGlTuu/x7t27io2NNdsAAAAAILUIigA804oVK+Tg4GC2jRkzxnQ8ODhYbdq0kaenp8aMGaO4uDjt2rXLrI/Ro0erWrVq8vPz04ABA7Rt2zbduXMn2etNmDBB/fv3V+vWreXj46Nx48YpICBAkydPfq77KF68uCTp1KlTkqRJkyapZs2aGjJkiLy9vRUcHKyuXbtq/PjxkqRjx45p+fLlmjVrlv73v/+pdOnSCg8P17lz5/Tjjz+a+r1//76mTZumypUry8fHR3Z2dpIkKysrzZ49W/7+/mrYsKFGjBihqVOnKiEhQXfv3tWYMWM0e/Zs1a1bV0WLFlVwcLDeeustzZw5M933OHbsWDk7O5u2QoUKpbsvAAAAAP89llldAICXX1BQkKZPn262L2fOnKY/lypVyvRne3t7OTk56fLly2btH2+TL18+SdLly5dVuHBhs3axsbE6f/68qlSpYra/SpUqioqKeq77MBqNkh5Ol5Ok6OhoNW3aNMl1Jk+erPj4eEVHR8vS0lIVKlQwHc+VK5d8fHwUHR1t2mdlZWV2f4+ULl3aFBpJUqVKlRQXF6ezZ88qLi5Ot27dUu3atc3OuXfvnsqUKZPuexw4cKB69+5t+hwbG0tYBAAAACDVCIoAPJO9vb08PT1TPJ49e3azzwaDIcmCzo+3eRTUvOhFnx+FO0WKFMnQfm1tbU33lFpxcXGSpJUrV6pAgQJmx6ytrdNdi7W19XOdDwAAAOC/jalnAF4qTk5Oyp8/vyIiIsz2R0REyM/P77n6njx5spycnFSrVi1Jkq+vb7LX8fb2VrZs2eTr66sHDx5o586dpuNXr17VkSNHUlVLVFSUbt++bfq8Y8cOOTg4qFChQmYLX3t6epptjAACAAAAkFUYUQTgme7evauLFy+a7bO0tFTu3Lkz5XofffSRhg0bpmLFiikgIEChoaGKjIxUeHh4qvu4fv26Ll68qLt37+ro0aOaOXOmfvzxR82dO1cuLi6SpD59+qh8+fIaOXKkWrVqpe3bt+uLL77QtGnTJEleXl5q2rSpOnfurJkzZ8rR0VEDBgxQgQIFkkxZS869e/fUsWNHDR48WKdOndKwYcPUtWtXWVhYyNHRUX379lWvXr2UkJCgV199VTExMYqIiJCTk5Pat2+frmcHAAAAAM+DoAjAM61Zs8a0rtAjPj4++v333zPlet27d1dMTIz69Omjy5cvy8/PT8uXL5eXl1eq++jQoYMkycbGRgUKFNCrr76qXbt2qWzZsqY2ZcuW1aJFizR06FCNHDlS+fLl04gRIxQcHGxqExoaqh49eqhRo0a6d++eqlatqlWrViWZbpecmjVrysvLS1WrVtXdu3fVpk0bhYSEmI6PHDlSefLk0dixY/XHH3/IxcVFZcuW1ccff5zq+wQAAACAjGQwPlrdFQDwrxMbGytnZ2e9Mu4VWdry/w0A/yQR3SKe3QgAACCVHv1uEBMTIycnpxTbsUYRAAAAAAAAJBEUAfiHGTNmjBwcHJLd6tevn9XlAQAAAMA/GvMQAPyjvP/++2rZsmWyx2xtbV9wNQAAAADw70JQBOAfJWfOnMqZM2dWlwEAAAAA/0pMPQMAAAAAAIAkgiIAAAAAAAAkIigCAAAAAACAJIIiAAAAAAAAJCIoAgAAAAAAgCSCIgAAAAAAACQiKAIAAAAAAIAkgiIAAAAAAAAkIigCAAAAAACAJIIiAAAAAAAAJLLM6gIAAJlv3fvr5OTklNVlAAAAAHjJMaIIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIIigAAAAAAAJCIoAgAAAAAAACSCIoAAAAAAACQiKAIAAAAAAAAkgiKAAAAAAAAkIigCAAAAAAAAJIky6wuAACQ+bbWqy97S/7JBwAAAF6Uaps3ZXUJ6cKIIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCAAAAAABAIoIiAAAAAAAASCIoAgAAAAAAQCKCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIigCAAAAAABAIoIiAAAAAAAASCIoAgAAAAAAQCKCIgAAAAAAAEgiKAIAAAAAAEAigiIAAAAAAABIIihCFgoLC5OLi8tT2wQHB6tZs2amz9WrV1fPnj1Nnz08PDR58uRMqQ8v3pM/33+D1HzPAQAAAOBlQVCETBUcHCyDwSCDwSArKyt5enpqxIgRevDgQarOnzJlisLCwlI8vnv3br377rsZVO3TeXh4mO4lW7Zsyp8/vzp27Ki///7b1ObOnTsKDg5WyZIlZWlpaRZyPbJ06VLVrl1befLkkZOTkypVqqSff/45Sbsvv/xSHh4esrGxUYUKFbRr165k69mxY4fZ/p49e6p69eqmz4cOHVLz5s1N7VMK1p51ved9Ni+DkJAQGQwG1atXL8mx8ePHy2AwmD27jNCqVSsdPXrUrIaAgIAMvQYAAAAAZBSCImS6evXq6cKFCzp27Jj69OmjkJAQjR8/PlXnOjs7P3U0Rp48eWRnZ5dBlT7biBEjdOHCBZ05c0bh4eHavHmzunfvbjoeHx8vW1tbde/eXbVq1Uq2j82bN6t27dpatWqV9u7dq6CgIDVu3Fj79+83tVm4cKF69+6tYcOGad++fSpdurTq1q2ry5cvm/VlY2Oj/v37P7XmW7duqWjRovrkk0/k5uaWbJvUXu9pnvVsXhb58uXThg0b9Oeff5rtnz17tgoXLpzh17O1tVXevHkzvN979+5leJ8AAAAAQFCETGdtbS03Nze5u7vrgw8+UK1atbR8+XLT8Z9//lm+vr5ycHAwhUqPPDn17ElPTj0zGAyaPn266tevL1tbWxUtWlSLFy82Hb937566du2qfPnyycbGRu7u7ho7dmyq78XR0VFubm4qUKCAgoKC1L59e+3bt8903N7eXtOnT1fnzp1TDGUmT56sfv36qXz58vLy8tKYMWPk5eWln376ydRm0qRJ6ty5szp06CA/Pz/NmDFDdnZ2mj17tllf7777rnbs2KFVq1alWHP58uU1fvx4tW7dWtbW1sm2Se31nufZXL16VW3atFGBAgVkZ2enkiVLav78+Un6efDggbp27SpnZ2flzp1bQ4YMkdFolPQwjCpRokSScwICAjRkyJBU1Zk3b17VqVNHc+bMMe3btm2b/vrrLzVs2NCsbUJCgkaMGKGCBQvK2tpaAQEBWrNmjen4qVOnZDAYtHTpUgUFBcnOzk6lS5fW9u3bTW0en3oWFham4cOHKyoqyjQC69GIuTNnzqhp06ZycHCQk5OTWrZsqUuXLpn6eTQSadasWSpSpIhsbGySvb+7d+8qNjbWbAMAAACA1CIowgtna2trGg1x69YtTZgwQd9++602b96sM2fOqG/fvs/V/5AhQ9S8eXNFRUWpbdu2at26taKjoyVJU6dO1fLly7Vo0SIdOXJE4eHh8vDwSNd1zp07p59++kkVKlR4rnoTEhJ048YN5cyZU9LDMGvv3r1mI5IsLCxUq1YtswBCkooUKaL3339fAwcOVEJCQrqun5brpVZyz+bOnTsqV66cVq5cqd9++03vvvuu3n777SRT3ObMmSNLS0vt2rVLU6ZM0aRJkzRr1ixJ0jvvvKPo6Gjt3r3b1H7//v06cOCAOnTokOr63nnnHbMpjbNnz1bbtm1lZWVl1m7KlCmaOHGiJkyYoAMHDqhu3bpq0qSJjh07ZtZu0KBB6tu3ryIjI+Xt7a02bdokO72yVatW6tOnj/z9/XXhwgVduHBBrVq1UkJCgpo2bapr165p06ZNWrdunf744w+1atXK7Pzjx49ryZIlWrp0qSIjI5O9t7Fjx8rZ2dm0FSpUKNXPBQAAAAAIivDCGI1G/fLLL/r5559Vo0YNSdL9+/c1Y8YMBQYGqmzZsuratavWr1//XNd544031KlTJ3l7e2vkyJEKDAzU559/LunhqA0vLy+9+uqrcnd316uvvqo2bdqkuu/+/fvLwcFBtra2KliwoAwGgyZNmvRc9U6YMEFxcXFq2bKlJOmvv/5SfHy8XF1dzdq5urrq4sWLSc4fPHiwTp48qfDw8HRdP63XS8mznk2BAgXUt29fBQQEqGjRourWrZvq1aunRYsWmfVTqFAhffbZZ/Lx8VHbtm3VrVs3ffbZZ5KkggULqm7dugoNDTW1Dw0NVbVq1VS0aNFU19qoUSPFxsZq8+bNunnzphYtWqR33nknSbsJEyaof//+at26tXx8fDRu3DgFBAQkWeepb9++atiwoby9vTV8+HCdPn1ax48fT9Kfra2tHBwcZGlpKTc3N7m5ucnW1lbr16/XwYMHNW/ePJUrV04VKlTQ3LlztWnTJrNQ7N69e5o7d67KlCmjUqVKJXtvAwcOVExMjGk7e/Zsqp8LAAAAABAUIdOtWLFCDg4OsrGxUf369dWqVSuFhIRIkuzs7FSsWDFT23z58qVpXZzkVKpUKcnnRyOKgoODFRkZKR8fH3Xv3l1r165NU98fffSRIiMjdeDAAVOg1bBhQ8XHx6er1nnz5mn48OFatGhRutexyZMnj/r27auhQ4dm6bo1z3o28fHxGjlypEqWLKmcOXPKwcFBP//8s86cOWPWT8WKFWUwGEyfK1WqpGPHjpn66dy5s+bPn687d+7o3r17mjdvXrIhz9Nkz55db731lkJDQ/X999/L29s7SfASGxur8+fPq0qVKmb7q1SpYvo+PfL4ufny5ZOkNH2Po6OjVahQIbPRP35+fnJxcTG7lru7u/LkyfPUvqytreXk5GS2AQAAAEBqWWZ1Afj3CwoK0vTp02VlZaX8+fPL0vL/v3bZs2c3a2swGEzr0WSGsmXL6uTJk1q9erV++eUXtWzZUrVq1TJbx+hpcufOLU9PT0mSl5eXJk+erEqVKmnDhg0pLl6dkgULFqhTp076/vvvzc7NnTu3smXLZrY+jSRdunQpxXWPevfurWnTpmnatGlpqiG910upn6c9m/Hjx2vKlCmaPHmySpYsKXt7e/Xs2TPN4Vbjxo1lbW2tH374QVZWVrp//75atGiRpj6kh9PPKlSooN9++y3NQdOTHv8ePwq50jsV8Gns7e0zvE8AAAAAeBwjipDp7O3t5enpqcKFC5uFRJnlydfF79ixQ76+vqbPTk5OatWqlb7++mstXLhQS5Ys0bVr19J1rWzZskmSbt++nabz5s+frw4dOmj+/PlJFlC2srJSuXLlzKbgJSQkaP369UlGSz3i4OCgIUOGaPTo0bpx40aaaknP9VLjyWcTERGhpk2b6q233lLp0qVVtGhRs9fGP7Jz506zzzt27JCXl5epP0tLS7Vv316hoaEKDQ1V69atZWtrm+b6/P395e/vr99++01vvvlmkuNOTk7Knz+/IiIizPZHRETIz88vzdd7xMrKKskINF9fX509e9Zsmtjhw4d1/fr157oWAAAAAKQVI4rwr/P9998rMDBQr776qsLDw7Vr1y598803kh6+3StfvnwqU6aMLCws9P3338vNzc30VqpnuXHjhi5evCij0aizZ8+qX79+ypMnjypXrmxqc/jwYd27d0/Xrl3TjRs3TIsOBwQESHo43ax9+/aaMmWKKlSoYFoHyNbWVs7OzpIejhBq3769AgMD9corr2jy5Mm6efPmUxdsfvfdd/XZZ59p3rx5ZotI37t3T4cPHzb9+dy5c4qMjJSDg4NpBFB6rpfWZ+Pl5aXFixdr27ZtypEjhyZNmqRLly4lCULOnDmj3r1767333tO+ffv0+eefa+LEiWZtOnXqZAr/ngxy0uLXX3/V/fv3U/z5f/TRRxo2bJiKFSumgIAAhYaGKjIyMt3rQUkP39R38uRJRUZGqmDBgnJ0dFStWrVUsmRJtW3bVpMnT9aDBw/UpUsXVatWTYGBgem+FgAAAACkFUER/nWGDx+uBQsWqEuXLsqXL5/mz59vCiMcHR316aef6tixY8qWLZvKly+vVatWycIidYPrhg4dqqFDh0p6uDZQ+fLltXbtWuXKlcvUpkGDBjp9+rTpc5kyZSTJNKXuq6++0oMHD/Thhx/qww8/NLVr37696U1crVq10pUrVzR06FBdvHjR9Fr2Jxecflz27Nk1cuTIJKNjzp8/b6pBerhA84QJE1StWjVt3Lgx3ddL67MZPHiw/vjjD9WtW1d2dnZ699131axZM8XExJj1065dO92+fVuvvPKKsmXLph49eujdd981a+Pl5aXKlSvr2rVrz/XWuWdN5erevbtiYmLUp08fXb58WX5+flq+fLm8vLzSfc3mzZtr6dKlCgoK0vXr1xUaGqrg4GAtW7ZM3bp1U9WqVWVhYaF69eqZFmEHAAAAgBfFYMzMBWGAF8xgMOiHH35Qs2bNsroUZCKj0SgvLy916dJFvXv3zupyXmqxsbFydnbWykqVZf8Cpn4CAAAAeKja5k1ZXYKZR78bxMTEPPWlN8+1RtGWLVv01ltvqVKlSjp37pwk6dtvv9XWrVufp1sASNGVK1f0xRdf6OLFi2maGgcAAAAAeLZ0B0VLlixR3bp1ZWtrq/379+vu3buSpJiYGI0ZMybDCgRehPDwcDk4OCS7+fv7Z3V5WeplezZ58+bViBEj9NVXXylHjhxmx1Kq08HBQVu2bHnhtQIAAADAP026p56VKVNGvXr1Urt27eTo6KioqCgVLVpU+/fvV/369U0L9AL/BDdu3EjyevhHsmfPLnd39xdc0cvjn/Rsjh8/nuKxAgUKpOvtaP90TD0DAAAAssY/depZun9rOHLkiKpWrZpkv7Ozs65fv57eboEs4ejoKEdHx6wu46X0T3o2j97iBgAAAABIn3RPPXNzc0v2/73funWrihYt+lxFAQAAAAAA4MVLd1DUuXNn9ejRQzt37pTBYND58+cVHh6uvn376oMPPsjIGgEAAAAAAPACpHvq2YABA5SQkKCaNWvq1q1bqlq1qqytrdW3b19169YtI2sEAAAAAADAC5DuxawfuXfvno4fP664uDj5+fnJwcEho2oDADwnFrMGAAAAssZ/bjHrR6ysrOTn5/e83QAAAAAAACCLpTsounPnjj7//HNt2LBBly9fVkJCgtnxffv2PXdxAAAAAAAAeHHSHRR17NhRa9euVYsWLfTKK6/IYDBkZF0AAAAAAAB4wdIdFK1YsUKrVq1SlSpVMrIeAAAAAAAAZBGL9J5YoEABOTo6ZmQtAAAAAAAAyELpfuvZ6tWrNXXqVM2YMUPu7u4ZXRcAIAOk9s0GAAAAAP7dMv2tZ4GBgbpz546KFi0qOzs7Zc+e3ez4tWvX0ts1AAAAAAAAskC6g6I2bdro3LlzGjNmjFxdXVnMGgAAAAAA4B8u3UHRtm3btH37dpUuXToj6wEAAAAAAEAWSfdi1sWLF9ft27czshYAAAAAAABkoXQHRZ988on69OmjjRs36urVq4qNjTXbAAAAAAAA8M+S7reeWVg8zJieXJvIaDTKYDAoPj7++asDADwX3noGAAAAQHoBbz3bsGFDek8FAAAAAADASyjdQVG1atUysg4AAAAAAABksXQHRY/cunVLZ86c0b1798z2lypV6nm7BgAAAAAAwAuU7qDoypUr6tChg1avXp3scdYoAoCXx8yPV8vW2i6rywAAAEhW14mNs7oEAInS/daznj176vr169q5c6dsbW21Zs0azZkzR15eXlq+fHlG1ggAAAAAAIAXIN0jin799VctW7ZMgYGBsrCwkLu7u2rXri0nJyeNHTtWDRs2zMg6AQAAAAAAkMnSPaLo5s2byps3ryQpR44cunLliiSpZMmS2rdvX8ZUBwAAAAAAgBcm3UGRj4+Pjhw5IkkqXbq0Zs6cqXPnzmnGjBnKly9fhhUIAAAAAACAFyPdU8969OihCxcuSJKGDRumevXqKTw8XFZWVgoLC8uo+gAAAAAAAPCCpDsoeuutt0x/LleunE6fPq3ff/9dhQsXVu7cuTOkOAAAAAAAALw46Q6KnmRnZ6eyZctmVHcAAAAAAAB4wdIcFI0YMSJV7YYOHZrmYgAAAAAAAJB10hwU/fDDD089fvToUd25c4egCAAAAAAA4B8mzUHR/v37k90fGRmpAQMG6NChQ+rcufNzFwYAAAAAAIAXy+J5Ozh58qTeeustlS9fXs7Ozjp06JBmzJiREbUBAAAAAADgBUp3UPTXX3+pW7duKl68uC5cuKBt27Zp4cKF8vLyysj6AAAAAAAA8IKkeerZzZs3NWHCBE2aNEmenp766aefVKdOncyoDQAAAAAAAC9QmoOiYsWK6caNG+rWrZvatGkjg8GgAwcOJGlXqlSpDCkQAAAAAAAAL0aag6LLly9Lkj799FONHz9eRqPRdMxgMMhoNMpgMCg+Pj7jqgQAAAAAAECmS/MaRSdPnjRtf/zxR7Kf//jjj8yoFS+hsLAwubi4ZHhb/HcYDAb9+OOPWV0GAAAAAEDpCIrc3d1TtT3SpUsX/fXXXxlaNJIXHBwsg8Egg8EgKysreXp6asSIEXrw4EGmXbNVq1Y6evRohrfNCKdOnTI9D4PBoFy5cqlOnTrav39/kmPJbWFhYU/tPyQkJNnz7O3tTW2WLl2qwMBAubi4yN7eXgEBAfr222/N+knp+uPHj39mmwULFqTqWXz99dcqXbq0HBwc5OLiojJlymjs2LGpf5iZ6MKFC6pfv76k//+ZRUZGZug1jEajvvrqK1WoUMH0DAIDAzV58mTdunUrQ68FAAAAAP9kaZ56llbfffed+vbtq9y5c2f2pSCpXr16Cg0N1d27d7Vq1Sp9+OGHyp49uwYOHGjW7t69e7Kysnru69na2srW1jbD22akX375Rf7+/vrzzz/VvXt31a9fX4cOHdKFCxdMbSZMmKA1a9bol19+Me1zdnZ+ar99+/bV+++/b7avZs2aKl++vOlzzpw5NWjQIBUvXlxWVlZasWKFOnTooLx586pu3bqSZFaHJK1evVodO3ZU8+bNzfaHhoaqXr16ZvtSM0Jr9uzZ6tmzp6ZOnapq1arp7t27OnDggH777bdnnpuZHn0H3dzcMv1ab7/9tpYuXarBgwfriy++UJ48eRQVFaXJkyfLw8NDzZo1y/Qa0uL+/fvKnj17VpcBAAAA4D8ozSOK0urxNYyQ+aytreXm5iZ3d3d98MEHqlWrlpYvX67g4GA1a9ZMo0ePVv78+eXj4yNJOnjwoGrUqCFbW1vlypVL7777ruLi4iRJa9eulY2Nja5fv252jR49eqhGjRqSkk4ni4qKUlBQkBwdHeXk5KRy5cppz549ybaVpOnTp6tYsWKysrKSj49PsqNtZs2apddee012dnby8vLS8uXL0/RMcuXKJTc3NwUGBmrChAm6dOmS9uzZIzc3N9Pm4OAgS0tLs33PCrUcHBzM2l+6dEmHDx9Wx44dTW2qV6+u1157Tb6+vipWrJh69OihUqVKaevWraY2j/fh5uamZcuWKSgoSEWLFjW7nouLS5K2NjY2z7z/5cuXq2XLlurYsaM8PT3l7++vNm3aaPTo0WbtZs2aJV9fX9nY2Kh48eKaNm2a2fE///xTbdq0Uc6cOWVvb6/AwEDt3LlTkkzfr8f17NlT1atXN3sWXbt2Vc+ePZU7d25TUPb41LMiRYpIksqUKSODwaDq1atr8+bNyp49uy5evJik///973/PvP9FixYpPDxc8+fP18cff6zy5cvLw8NDTZs21a+//qqgoCBJ0u7du1W7dm3lzp1bzs7Oqlatmvbt22fWl8Fg0MyZM9WoUSPZ2dnJ19dX27dv1/Hjx1W9enXZ29urcuXKOnHihNl5y5YtU9myZWVjY6OiRYtq+PDhZiP9DAaDpk+friZNmsje3l6jR49WfHy8OnbsqCJFisjW1lY+Pj6aMmXKM+8XAAAAAJ5HpgdFyFq2tra6d++eJGn9+vU6cuSI1q1bpxUrVujmzZuqW7eucuTIod27d+v777/XL7/8oq5du0p6ODrGxcVFS5YsMfUXHx+vhQsXqm3btsler23btipYsKB2796tvXv3asCAASmOjPjhhx/Uo0cP9enTR7/99pvee+89dejQQRs2bDBrN3z4cLVs2VIHDhxQgwYN1LZtW127di3dz0OS6ZlkpFmzZsnb2zvF8MJoNJp+BlWrVk22zaVLl7Ry5UqzsOl5ubm5aceOHTp9+nSKbcLDwzV06FCNHj1a0dHRGjNmjIYMGaI5c+ZIkuLi4lStWjWdO3dOy5cvV1RUlPr166eEhIQ01TJnzhxZWVkpIiJCM2bMSHJ8165dkh6OArtw4YKWLl2qqlWrqmjRomYh4v379xUeHq533nnnmdcMDw+Xj4+PmjZtmuSYwWAwjRy7ceOG2rdvr61bt2rHjh3y8vJSgwYNdOPGDbNzRo4cqXbt2ikyMlLFixfXm2++qffee08DBw7Unj17ZDQaTX+HJGnLli1q166devToocOHD2vmzJkKCwtLEtSFhITotdde08GDB/XOO+8oISFBBQsW1Pfff6/Dhw9r6NCh+vjjj7Vo0aKn3u/du3cVGxtrtgEAAABAamX61DNkjUehxM8//6xu3brpypUrsre316xZs0xTzr7++mvduXNHc+fONa2r88UXX6hx48YaN26cXF1d1bp1a82bN88UXKxfv17Xr19PMi3qkTNnzuijjz5S8eLFJUleXl4p1jhhwgQFBwerS5cukqTevXtrx44dmjBhgmmUh/RwtEqbNm0kSWPGjNHUqVO1a9euJNOwnuX69esaOXKkHBwc9Morr6Tp3Ge5c+eOwsPDNWDAgCTHYmJiVKBAAd29e1fZsmXTtGnTVLt27WT7mTNnjhwdHfX6668nOdamTRtly5bNbN/hw4dVuHDhp9Y2bNgwvf766/Lw8JC3t7cqVaqkBg0aqEWLFrKwsDC1mThxoum6RYoUMYUa7du317x583TlyhXt3r1bOXPmlCR5eno++8E8wcvLS59++mmKx/PkySPp/0eBPdKxY0eFhobqo48+kiT99NNPunPnjlq2bPnMax47dsw0gu5pHo2Se+Srr76Si4uLNm3apEaNGpn2d+jQwXTd/v37q1KlShoyZIhphFSPHj3UoUMHU/vhw4drwIABat++vSSpaNGiGjlypPr166dhw4aZ2r355ptm5z0695EiRYpo+/btWrRo0VPve+zYsWbnAQAAAEBaMKLoX2bFihVycHCQjY2N6tevr1atWikkJESSVLJkSbN1iaKjo1W6dGmzxZerVKmihIQEHTlyRNLDEUIbN27U+fPnJT0cndGwYcMU18bp3bu3OnXqpFq1aumTTz5JMgXncdHR0apSpYrZvipVqig6OtpsX6lSpUx/tre3l5OTky5fvvzsh5GocuXKcnBwUI4cORQVFaWFCxfK1dU11eenxg8//GAakfIkR0dHRUZGavfu3Ro9erR69+6tjRs3JtvP7Nmz1bZt22SnlH322WeKjIw02/Lnz//M2vLly6ft27fr4MGD6tGjhx48eKD27durXr16SkhI0M2bN3XixAl17NhRDg4Opm3UqFGmn19kZKTKlCljConSq1y5cuk6Lzg4WMePH9eOHTskPZzG2LJlS7PvbkpSO/310qVL6ty5s7y8vOTs7CwnJyfFxcXpzJkzZu0e/z4++h6VLFnSbN+dO3dMI3mioqI0YsQIs2fbuXNnXbhwwWwh7cDAwCQ1ffnllypXrpzy5MkjBwcHffXVV0nqedLAgQMVExNj2s6ePZuq+wcAAAAAiRFF/zpBQUGaPn26rKyslD9/flla/v+PODW/VD+pfPnyKlasmBYsWKAPPvhAP/zww1PfBhYSEqI333xTK1eu1OrVqzVs2DAtWLBAr732WnpuR5KSTF0zGAxpmvK0cOFC+fn5KVeuXKla/Dk9Zs2apUaNGiUbQFlYWJhG3wQEBCg6Olpjx441W79HejhF6ciRI1q4cGGy13Bzc0vXKJ5HSpQooRIlSqhLly56//339b///U+bNm2Sn5+fpIcjzCpUqGB2zqMRTM9ar8nCwiJJIHP//v0k7dLzHZSkvHnzqnHjxgoNDVWRIkW0evXqFMO2J3l7e+v3339/Zrv27dvr6tWrmjJlitzd3WVtba1KlSolmab4+PfRYDCkuO/RdzQuLk7Dhw9PdpTY44Hgk89mwYIF6tu3ryZOnKhKlSrJ0dFR48ePN60LlRJra2tZW1s/834BAAAAIDmZHhS99dZbcnJyyuzLIJG9vX2qwwRfX1+FhYXp5s2bpl9SIyIiZGFhYTZVp23btgoPD1fBggVlYWGhhg0bPrVfb29veXt7q1evXmrTpo1CQ0OTDYp8fX0VERFhNgonIiLCFFxklEKFCqlYsWIZ2ufjTp48qQ0bNqR6ke2EhATdvXs3yf5vvvlG5cqVU+nSpTO6xCQePeObN2/K1dVV+fPn1x9//JHi2lOlSpXSrFmzdO3atWRHFeXJkyfJW9QiIyPT/OauRyPe4uPjkxzr1KmT2rRpo4IFC6pYsWJJRqOl5M0331Tr1q21bNmyJOsUGY1GxcbGytnZWREREZo2bZoaNGggSTp79qz++uuvNNWfnLJly+rIkSNpDvkiIiJUuXJl09RMSU8doQcAAAAAGeG5pp5t2bJFb731lipVqqRz585Jkr799luzNzpNnz5duXPnfr4qkSkeTXFq3769fvvtN23YsEHdunXT22+/bTYypm3bttq3b59Gjx6tFi1apDha4fbt2+ratas2btyo06dPKyIiQrt375avr2+y7T/66COFhYVp+vTpOnbsmCZNmqSlS5eqb9++mXK/mWX27NnKly+f6tevn+TY2LFjtW7dOv3xxx+Kjo7WxIkT9e233+qtt94yaxcbG6vvv/9enTp1SvE6169f18WLF822mzdvPrO+Dz74QCNHjlRERIROnz6tHTt2qF27dsqTJ48qVaok6eFaOGPHjtXUqVN19OhRHTx4UKGhoZo0aZKkh+sjubm5qVmzZoqIiNAff/yhJUuWaPv27ZIeru+zZ88ezZ07V8eOHdOwYcOSBEepkTdvXtna2mrNmjW6dOmSYmJiTMfq1q0rJycnjRo1KslaPk/TsmVLtWrVSm3atNGYMWO0Z88enT59WitWrFCtWrVMi6d7eXnp22+/VXR0tHbu3Km2bds+cyRVagwdOlRz587V8OHDdejQIUVHR2vBggUaPHjwU8/z8vLSnj179PPPP+vo0aMaMmSIdu/e/dz1AAAAAMDTpDsoWrJkierWrStbW1vt37/fNEIiJiZGY8aMybACkXns7Oz0888/69q1aypfvrxatGihmjVr6osvvjBr5+npqVdeeUUHDhxIccSJ9HCa0tWrV9WuXTt5e3urZcuWql+/fooL6zZr1kxTpkzRhAkT5O/vr5kzZyo0NDTJlKyXWUJCgsLCwhQcHJxkoWnp4YidLl26yN/fX1WqVNGSJUv03XffJQmEFixYIKPRaFq0OzkdOnRQvnz5zLbPP//8mTXWqlVLO3bs0BtvvCFvb281b95cNjY2Wr9+vXLlyiXp4WidWbNmKTQ0VCVLllS1atUUFhZmel29lZWV1q5dq7x586pBgwYqWbKkPvnkE9M9161bV0OGDFG/fv1Uvnx53bhxQ+3atUv1c3zE0tJSU6dO1cyZM5U/f36zEUAWFhYKDg5WfHx8mvo2GAyaN2+eJk2apB9//FHVqlVTqVKlFBISoqZNm5oWof7mm2/0999/q2zZsnr77bfVvXt35c2bN8338KS6detqxYoVWrt2rcqXL6+KFSvqs88+k7u7+1PPe++99/T666+rVatWqlChgq5evWo2uggAAAAAMoPBmNqVXp9QpkwZ9erVS+3atZOjo6OioqJUtGhR7d+/X/Xr19fFixczulYA/3EdO3bUlStXUj3NDzJNrfv0wwWytbbL6nIAAACS1XVi46wuAfjXe/S7QUxMzFOXCEr3GkVHjhxR1apVk+x3dnbW9evX09stACQRExOjgwcPat68eYREAAAAAJCJ0j31zM3NTcePH0+yf+vWrSpatOhzFQWkxvvvv2/2yvHHt/fff/+5+69fv36K/b9M0yv/KXU+j6ZNm6pOnTp6//33Vbt2bbNj/4X7BwAAAIAXJd0jijp37qwePXpo9uzZMhgMOn/+vLZv366+fftqyJAhGVkjkKwRI0akuPB1Rrxpb9asWbp9+3ayx5J781dW+afU+Tw2btyY4rH/wv0DAAAAwIuS7qBowIABSkhIUM2aNXXr1i1VrVpV1tbW6tu3r7p165aRNQLJyps3b4YsNpySAgUKZFrfGemfUmdm+a/fPwAAAABkpHQHRQaDQYMGDdJHH32k48ePKy4uTn5+fnJwcMjI+gAAAAAAAPCCpDsoiomJUXx8vHLmzCk/Pz/T/mvXrsnS0jJDpv4AAAAAAADgxUn3YtatW7fWggULkuxftGiRWrdu/VxFAQAAAAAA4MVLd1C0c+dOBQUFJdlfvXp17dy587mKAgAAAAAAwIuX7qDo7t27evDgQZL99+/fT/ENRAAAAAAAAHh5pTsoeuWVV/TVV18l2T9jxgyVK1fuuYoCAAAAAADAi5fuxaxHjRqlWrVqKSoqSjVr1pQkrV+/Xrt379batWszrEAAAAAAAAC8GOkeUVSlShVt375dhQoV0qJFi/TTTz/J09NTBw4c0P/+97+MrBEAAAAAAAAvQLpHFElSQECAwsPDM6oWAAAAAAAAZKE0BUWxsbFycnIy/flpHrUDAGS998bU599lAAAAAM+UpqAoR44cunDhgvLmzSsXFxcZDIYkbYxGowwGg+Lj4zOsSAAAAAAAAGS+NAVFv/76q3LmzGn6c3JBEQAAAAAAAP6ZDEaj0ZjVRQAAMkdsbKycnZ0VExPD1DMAAADgPyy1vxuk+61nXl5eCgkJ0bFjx9LbBQAAAAAAAF4i6Q6KunTpopUrV6p48eIqX768pkyZoosXL2ZkbQAAAAAAAHiB0h0U9erVS7t371Z0dLQaNGigL7/8UoUKFVKdOnU0d+7cjKwRAAAAAAAAL0CGrlG0Y8cOffDBBzpw4ABvPQOAlwBrFAEAAACQUv+7QZreepaSXbt2ad68eVq4cKFiY2P1xhtvZES3AAAAAAAAeIHSHRQdPXpU4eHhmj9/vk6ePKkaNWpo3Lhxev311+Xg4JCRNQIAAAAAAOAFSHdQ9GgR6w8//FCtW7eWq6trRtYFAAAAAACAFyzdQdGRI0fk5eWVkbUAADLJ+M5vyyZ79qwuAwAAIE0Gfbc4q0sA/nPS/dYzLy8vXb9+XbNmzdLAgQN17do1SdK+fft07ty5DCsQAAAAAAAAL0a6RxQdOHBANWvWlIuLi06dOqXOnTsrZ86cWrp0qc6cOaO5c+dmZJ0AAAAAAADIZOkeUdSrVy916NBBx44dk42NjWl/gwYNtHnz5gwpDgAAAAAAAC9OukcU7dmzR1999VWS/QUKFNDFixefqygAAAAAAAC8eOkeUWRtba3Y2Ngk+48ePao8efI8V1EAAAAAAAB48dIdFDVp0kQjRozQ/fv3JUkGg0FnzpxR//791bx58wwrEAAAAAAAAC9GuoOiiRMnKi4uTnny5NHt27dVrVo1eXp6ytHRUaNHj87IGgEAAAAAAPACpHuNImdnZ61bt04RERGKiopSXFycypYtq1q1amVkfQAAAAAAAHhB0hUUJSQkKCwsTEuXLtWpU6dkMBhUpEgRubm5yWg0ymAwZHSdAAAAAAAAyGRpnnpmNBrVpEkTderUSefOnVPJkiXl7++v06dPKzg4WK+99lpm1AkAAAAAAIBMluYRRWFhYdq8ebPWr1+voKAgs2O//vqrmjVrprlz56pdu3YZViQAAAAAAAAyX5pHFM2fP18ff/xxkpBIkmrUqKEBAwYoPDw8Q4oDAAAAAADAi5PmoOjAgQOqV69eisfr16+vqKio5yoKAAAAAAAAL16ag6Jr167J1dU1xeOurq76+++/n6soAAAAAAAAvHhpDori4+NlaZny0kbZsmXTgwcPnqso/LuEhYXJxcUlw9vi3yEkJEQBAQFZXQYAAAAAQOl861lwcLBef/31ZLd33nknM+pEBgkODpbBYJDBYJCVlZU8PT01YsSITA33WrVqpaNHj2Z424xw6tQp0/MwGAzKlSuX6tSpo/379yc5ltwWFhb2zGv8/PPPqlixohwdHZUnTx41b95cp06dMh3funWrqlSpoly5csnW1lbFixfXZ599ZtZHfHy8hgwZoiJFisjW1lbFihXTyJEjZTQaU3WfJ0+e1Jtvvqn8+fPLxsZGBQsWVNOmTfX777+n5XFlir59+2r9+vWmz8HBwWrWrFmGX+f48ePq0KGDChYsKGtraxUpUkRt2rTRnj17MvxaAAAAAPBPlea3nrVv3/6ZbXjj2cutXr16Cg0N1d27d7Vq1Sp9+OGHyp49uwYOHGjW7t69e7Kysnru69na2srW1jbD22akX375Rf7+/vrzzz/VvXt31a9fX4cOHdKFCxdMbSZMmKA1a9bol19+Me1zdnZ+ar8nT55U06ZN1bt3b4WHhysmJka9evXS66+/rn379kmS7O3t1bVrV5UqVUr29vbaunWr3nvvPdnb2+vdd9+VJI0bN07Tp0/XnDlz5O/vrz179qhDhw5ydnZW9+7dn1rD/fv3Vbt2bfn4+Gjp0qXKly+f/vzzT61evVrXr19P5xN7fkajUfHx8XJwcJCDg0OmXmvPnj2qWbOmSpQooZkzZ6p48eK6ceOGli1bpj59+mjTpk2Zev20yqi/ewAAAACQVmkeURQaGpqqDS8va2trubm5yd3dXR988IFq1aql5cuXm0ZyjB49Wvnz55ePj48k6eDBg6pRo4ZsbW2VK1cuvfvuu4qLi5MkrV27VjY2NkkChx49eqhGjRqSkk4ni4qKUlBQkBwdHeXk5KRy5cqZRnUkN/Vs+vTpKlasmKysrOTj46Nvv/3W7LjBYNCsWbP02muvyc7OTl5eXlq+fHmankmuXLnk5uamwMBATZgwQZcuXdKePXvk5uZm2hwcHGRpaWm271mh1t69exUfH69Ro0apWLFiKlu2rPr27avIyEjdv39fklSmTBm1adNG/v7+8vDw0FtvvaW6detqy5Ytpn62bdumpk2bqmHDhvLw8FCLFi1Up04d7dq165n3dujQIZ04cULTpk1TxYoV5e7uripVqmjUqFGqWLGiqd3Zs2fVsmVLubi4KGfOnGratKnZyCdJmj17tvz9/WVtba18+fKpa9eukv5/ZFZkZKSp7fXr12UwGLRx40ZJ0saNG2UwGLR69WqVK1dO1tbW2rp1q9nUs5CQEM2ZM0fLli0zjdrauHGjatSoYbrWI1euXJGVlZXZaKTkPBoF6eXlpS1btqhhw4YqVqyYAgICNGzYMC1btszUtn///vL29padnZ2KFi2qIUOGmH5Oj+oLCAjQ7NmzVbhwYTk4OKhLly6Kj4/Xp59+Kjc3N+XNm1ejR482q+H69evq1KmT8uTJIycnJ9WoUcNs0f9H/c6aNUtFihSRjY2NJGnNmjV69dVX5eLioly5cqlRo0Y6ceLEU+8XAAAAAJ5HmoMi/PvY2trq3r17kqT169fryJEjWrdunVasWKGbN2+qbt26ypEjh3bv3q3vv/9ev/zyi+mX9po1a8rFxUVLliwx9RcfH6+FCxeqbdu2yV6vbdu2KliwoHbv3q29e/dqwIAByp49e7Jtf/jhB/Xo0UN9+vTRb7/9pvfee08dOnTQhg0bzNoNHz5cLVu21IEDB9SgQQO1bdtW165dS/fzkGR6Js+jXLlysrCwUGhoqOLj4xUTE6Nvv/1WtWrVSvGe9+/fr23btqlatWqmfZUrV9b69etN0/KioqK0detW1a9f/5k15MmTRxYWFlq8eLHi4+OTbXP//n3VrVtXjo6O2rJliyIiIuTg4KB69eqZnsP06dP14Ycf6t1339XBgwe1fPlyeXp6pvWRaMCAAfrkk08UHR2tUqVKmR3r27evWrZsqXr16unChQu6cOGCKleurE6dOmnevHm6e/euqe13332nAgUKmALJlERGRurQoUPq06ePLCyS/pP3eDDp6OiosLAwHT58WFOmTNHXX3+dZBrgiRMntHr1aq1Zs0bz58/XN998o4YNG+rPP//Upk2bNG7cOA0ePFg7d+40nfPGG2/o8uXLWr16tfbu3auyZcuqZs2aZt/R48ePa8mSJVq6dKkpcLt586Z69+6tPXv2aP369bKwsNBrr72mhISEFO/37t27io2NNdsAAAAAILXSPPUM/x5Go1Hr16/Xzz//rG7duunKlSuyt7fXrFmzTNNevv76a925c0dz586Vvb29JOmLL75Q48aNNW7cOLm6uqp169aaN2+eOnbsKOlh2HT9+nU1b9482eueOXNGH330kYoXLy5J8vLySrHGCRMmKDg4WF26dJEk9e7dWzt27NCECRMUFBRkahccHKw2bdpIksaMGaOpU6dq165dqlevXpqeyfXr1zVy5Eg5ODjolVdeSdO5ySlSpIjWrl2rli1b6r333lN8fLwqVaqkVatWJWlbsGBBXblyRQ8ePFBISIg6depkOjZgwADFxsaqePHiypYtm+Lj4zV69OgUw7jHFShQQFOnTlW/fv00fPhwBQYGKigoSG3btlXRokUlSQsXLlRCQoJmzZolg8Eg6eHoQRcXF23cuFF16tTRqFGj1KdPH/Xo0cPUd/ny5dP8TEaMGKHatWsne8zBwUG2tra6e/eu3NzcTPtff/11de3aVcuWLVPLli0lPRx99mjNrac5duyYJJm+b08zePBg0589PDzUt29fLViwQP369TPtT0hI0OzZs+Xo6Cg/Pz8FBQXpyJEjWrVqlSwsLOTj46Nx48Zpw4YNqlChgrZu3apdu3bp8uXLsra2lvTwe/3jjz9q8eLFpumF9+7d09y5c5UnTx7TtZ78OzR79mzlyZNHhw8fVokSJZK9h7Fjx2r48OHPvFcAAAAASA4jiv6DVqxYIQcHB9nY2Kh+/fpq1aqVQkJCJEklS5Y0WxslOjpapUuXNoVEklSlShUlJCToyJEjkh6OENq4caPOnz8vSQoPD1fDhg1TfHtZ79691alTJ9WqVUuffPLJU6fSREdHq0qVKmb7qlSpoujoaLN9j49Msbe3l5OTky5fvvzsh5GocuXKcnBwUI4cORQVFaWFCxfK1dU11een5OLFi+rcubPat2+v3bt3a9OmTbKyslKLFi2SLES9ZcsW7dmzRzNmzNDkyZM1f/5807FFixYpPDxc8+bN0759+zRnzhxNmDBBc+bMSVUdH374oS5evKjw8HBVqlRJ33//vfz9/bVu3TpJD0coHT9+XI6OjqY1g3LmzKk7d+7oxIkTunz5ss6fP6+aNWs+9zMJDAxM8zk2NjZ6++23NXv2bEnSvn379Ntvvyk4OPiZ56Z2wW/pYWBWpUoV01TDwYMH68yZM2ZtPDw85OjoaPrs6uoqPz8/s9FKrq6upu9fVFSU4uLilCtXLtOzdXBw0MmTJ82+++7u7mYhkfQw5GrTpo2KFi0qJycneXh4SFKSmh43cOBAxcTEmLazZ8+m+v4BAAAAgBFF/0FBQUGaPn26rKyslD9/flla/v/X4PFAKLXKly+vYsWKacGCBfrggw/0ww8/PPVtYCEhIXrzzTe1cuVKrV69WsOGDdOCBQv02muvped2JCnJNC6DwfDU6TlPWrhwofz8/JQrV64UA670+PLLL+Xs7KxPP/3UtO+7775ToUKFtHPnTrM1gooUKSLpYVh36dIlhYSEmEZJffTRRxowYIBat25tanP69GmNHTs2VQvMSw+nVTVu3FiNGzfWqFGjVLduXY0aNUq1a9dWXFycypUrp/Dw8CTnPZq69jSPjj8eyjy+ts/j0vMdk6ROnTopICBAf/75p0JDQ1WjRg25u7s/8zxvb29J0u+//64yZcqk2G779u1q27athg8frrp168rZ2VkLFizQxIkTzdol91172vcvLi5O+fLlM63V9LjHv2vJPZfGjRvL3d1dX3/9tfLnz6+EhASVKFHiqdMira2tTSOXAAAAACCtGFH0H2Rvby9PT08VLlzYLCRKjq+vr6KionTz5k3TvoiICNMUm0fatm2r8PBw/fTTT7KwsFDDhg2f2q+3t7d69eqltWvX6vXXX09xAXRfX19FRESY7YuIiJCfn9+zbjNNChUqpGLFimVoSCRJt27dShKyZMuWTZKeGmQlJCSYrceTUj9pCcMeZzAYVLx4cdPPtWzZsjp27Jjy5s0rT09Ps83Z2VmOjo7y8PBIceHoRyNhHn9L3OMLW6eFlZVVsmsplSxZUoGBgfr66681b948vfPOO6nqLyAgQH5+fpo4cWKyz+vRQuzbtm2Tu7u7Bg0apMDAQHl5een06dPpuofHlS1bVhcvXpSlpWWSZ5s7d+4Uz7t69aqOHDmiwYMHq2bNmvL19dXff//93PUAAAAAwNMQFOGp2rZtKxsbG7Vv316//fabNmzYoG7duuntt982m5rVtm1b7du3T6NHj1aLFi1SHNFw+/Ztde3aVRs3btTp06cVERGh3bt3y9fXN9n2H330kcLCwjR9+nQdO3ZMkyZN0tKlS9W3b99Mud+M1rBhQ+3evVsjRozQsWPHtG/fPnXo0EHu7u6m0S1ffvmlfvrpJx07dkzHjh3TN998owkTJuitt94y9dO4cWONHj1aK1eu1KlTp/TDDz9o0qRJqRqFFRkZqaZNm2rx4sU6fPiwjh8/rm+++UazZ89W06ZNJT38+eXOnVtNmzbVli1bdPLkSW3cuFHdu3fXn3/+KenhSLCJEydq6tSppnv5/PPPJT1cALxixYqmRao3bdpktt5PWnh4eOjAgQM6cuSI/vrrL7ORSZ06ddInn3wio9GY6hFoBoNBoaGhOnr0qP73v/9p1apV+uOPP3TgwAGNHj3a9Ay8vLx05swZLViwQCdOnNDUqVP1ww8/pOseHlerVi1VqlRJzZo109q1a3Xq1Clt27ZNgwYNMr3tLzk5cuRQrly59NVXX+n48eP69ddf1bt37+euBwAAAACehqAIT2VnZ6eff/5Z165dU/ny5dWiRQvVrFlTX3zxhVk7T09PvfLKKzpw4MBTF1jOli2brl69qnbt2snb21stW7ZU/fr1U1x8t1mzZpoyZYomTJggf39/zZw5U6GhoapevXpG3mamqVGjhubNm6cff/xRZcqUUb169WRtba01a9aY3q6WkJCggQMHKiAgQIGBgfryyy81btw4jRgxwtTP559/rhYtWqhLly7y9fVV37599d5772nkyJHPrKFgwYLy8PDQ8OHDVaFCBZUtW1ZTpkzR8OHDNWjQIEkPf86bN29W4cKF9frrr8vX11cdO3bUnTt35OTkJElq3769Jk+erGnTpsnf31+NGjUyLRQtPVxo+cGDBypXrpx69uypUaNGpeuZde7cWT4+PgoMDFSePHnMRpS1adNGlpaWatOmjekV8qnxyiuvaM+ePfL09FTnzp3l6+urJk2a6NChQ5o8ebIkqUmTJurVq5e6du2qgIAAbdu2TUOGDEnXPTzOYDBo1apVqlq1qjp06CBvb2+1bt1ap0+ffuo6WBYWFlqwYIH27t2rEiVKqFevXho/fvxz1wMAAAAAT2MwpmWlVwDIQqdOnVKxYsW0e/dulS1bNqvL+UeIjY2Vs7OzBrdsIpsn1lICAAB42Q36bnFWlwD8azz63SAmJsY0ICA5LGYN4KV3//59Xb16VYMHD1bFihUJiQAAAAAgkzD1DP9q77//vtkryR/f3n///efuv379+in2P2bMmAy4g2fbsmVLijU4ODi8kBoyW0REhPLly6fdu3drxowZZsf+C/cPAAAAAC8KU8/wr3b58mXFxsYme8zJyUl58+Z9rv7PnTun27dvJ3ssZ86cypkz53P1nxq3b9/WuXPnUjzu6emZ6TVkpf/6/T8LU88AAMA/GVPPgIzD1DNAUt68eZ87DHqaAgUKZFrfqWVra/ufDkP+6/cPAAAAABmJqWcAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQERQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQGo9FozOoiAACZIzY2Vs7OzoqJiZGTk1NWlwMAAAAgi6T2dwNGFAEAAAAAAEASQREAAAAAAAASERQBAAAAAABAEkERAAAAAAAAEhEUAQAAAAAAQBJBEQAAAAAAABIRFAEAAAAAAEASQREAAAAAAAASERQBAAAAAABAkmSZ1QUAADLfkfGb5GBjn9VlAMhkvoNqZHUJAADgH44RRQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQERQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQERQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQRFAEAM8UHBysZs2aZXUZAAAAAJDpCIqQLleuXNEHH3ygwoULy9raWm5ubqpbt64iIiKyurQs9/XXX6t06dJycHCQi4uLypQpo7Fjx5qOh4SEyGAw6P333zc7LzIyUgaDQadOnZIknTp1SgaDQZGRkUmuUb16dfXs2TNV9SxdulR16tRRrly5Uuzvzp07+vDDD5UrVy45ODioefPmunTpklmb7t27q1y5crK2tlZAQECyfQQHB6tkyZKytLRMc7ASFhYmg8GgevXqme2/fv26DAaDNm7c+Mw+KlasmOS5zpgxQwaDQWFhYWb7g4OD9b///S9NNQIAAADAvx1BEdKlefPm2r9/v+bMmaOjR49q+fLlql69uq5evZrVpWWp2bNnq2fPnurevbsiIyMVERGhfv36KS4uzqydjY2NvvnmGx07dizTa7p586ZeffVVjRs3LsU2vXr10k8//aTvv/9emzZt0vnz5/X6668naffOO++oVatWyfYRHx8vW1tbde/eXbVq1UpXrZaWlvrll1+0YcOGdJ0fFBSUJFDasGGDChUqlGT/xo0bVaNGjXRdBwAAAAD+rQiKkGbXr1/Xli1bNG7cOAUFBcnd3V2vvPKKBg4cqCZNmkiSJk2apJIlS8re3l6FChVSly5dzMKSsLAwubi4aMWKFfLx8ZGdnZ1atGihW7duac6cOfLw8FCOHDnUvXt3xcfHm86bNm2avLy8ZGNjI1dXV7Vo0cJ0zMPDQ5MnTzarNSAgQCEhIabPBoNBs2bN0muvvSY7Ozt5eXlp+fLlZucsX77cdI2goCDNmTNHBoNB169ff+azWb58uVq2bKmOHTvK09NT/v7+atOmjUaPHm3WzsfHR0FBQRo0aNAz+3xeb7/9toYOHZpieBMTE6NvvvlGkyZNUo0aNVSuXDmFhoZq27Zt2rFjh6nd1KlT9eGHH6po0aLJ9mNvb6/p06erc+fOcnNzS1et9vb2eueddzRgwIB0nR8UFKQjR47o4sWLpn2bNm3SgAEDzIKikydP6vTp0woKCpIknT17Vi1btpSLi4ty5syppk2bmkZ2PW748OHKkyePnJyc9P777+vevXumYwkJCfr000/l6ekpa2trFS5c2Ozn3r9/f3l7e8vOzk5FixbVkCFDdP/+fdPxkJAQBQQEaPbs2SpcuLAcHBzUpUsXxcfH69NPP5Wbm5vy5s2b5Lv0pLt37yo2NtZsAwAAAIDUIihCmjk4OMjBwUE//vij7t69m2wbCwsLTZ06VYcOHdKcOXP066+/ql+/fmZtbt26palTp2rBggVas2aNNm7cqNdee02rVq3SqlWr9O2332rmzJlavHixJGnPnj3q3r27RowYoSNHjmjNmjWqWrVqmusfPny4WrZsqQMHDqhBgwZq27atrl27JulhgNCiRQs1a9ZMUVFReu+999IU5ri5uWnHjh06ffr0M9t+8sknWrJkifbs2ZPme8hIe/fu1f37982CpOLFi6tw4cLavn37C68nJCREBw8eNP3c06JKlSrKnj27aUTS4cOHdfv2bXXs2FFXr17VyZMnJT0cZWRjY6NKlSrp/v37qlu3rhwdHbVlyxZFRETIwcFB9erVMwuC1q9fr+joaG3cuFHz58/X0qVLNXz4cNPxgQMH6pNPPtGQIUN0+PBhzZs3T66urqbjjo6OCgsL0+HDhzVlyhR9/fXX+uyzz8zqP3HihFavXq01a9Zo/vz5+uabb9SwYUP9+eef2rRpk8aNG6fBgwdr586dKT6DsWPHytnZ2bQVKlQozc8RAAAAwH8XQRHSzNLSUmFhYZozZ45cXFxUpUoVffzxxzpw4ICpTc+ePRUUFCQPDw/VqFFDo0aN0qJFi8z6uX//vqZPn64yZcqoatWqatGihbZu3apvvvlGfn5+atSokYKCgky/9J85c0b29vZq1KiR3N3dVaZMGXXv3j3N9QcHB6tNmzby9PTUmDFjFBcXp127dkmSZs6cKR8fH40fP14+Pj5q3bq1goODU933sGHD5OLiIg8PD/n4+Cg4OFiLFi1SQkJCkrZly5ZVy5Yt1b9//6f2WblyZVM492jbsmVLmu75aS5evCgrKyu5uLiY7Xd1dTUbmfOi5M+fXz169NCgQYP04MGDNJ1rb2+vV155xTR6aOPGjXr11VdlbW2typUrm+2vVKmSrK2ttXDhQiUkJGjWrFkqWbKkfH19FRoaqjNnzpiNQrKystLs2bPl7++vhg0basSIEZo6daoSEhJ048YNTZkyRZ9++qnat2+vYsWK6dVXX1WnTp1M5w8ePFiVK1eWh4eHGjdurL59+yb5O5GQkKDZs2fLz89PjRs3No2Qmjx5snx8fNShQwf5+Pg8dWrewIEDFRMTY9rOnj2bpmcIAAAA4L+NoAjp0rx5c50/f17Lly9XvXr1tHHjRpUtW9a0YPAvv/yimjVrqkCBAnJ0dNTbb7+tq1ev6tatW6Y+7OzsVKxYMdNnV1dXeXh4yMHBwWzf5cuXJUm1a9eWu7u7ihYtqrffflvh4eFm/aVWqVKlTH+2t7eXk5OT6RpHjhxR+fLlzdq/8sorqe47X7582r59uw4ePKgePXrowYMHat++verVq5dsWDRq1Cht2bJFa9euTbHPhQsXKjIy0mwLDAxMdU3/RP3799eVK1c0e/bsNJ9bvXp1s0CoevXqkqRq1aqZ7X807SwqKkrHjx+Xo6OjKYjLmTOn7ty5oxMnTpj6LV26tOzs7EyfK1WqpLi4OJ09e1bR0dG6e/euatasmWJdCxcuVJUqVeTm5iYHBwcNHjxYZ86cMWvj4eEhR0dH02dXV1f5+fnJwsLCbN+j72tyrK2t5eTkZLYBAAAAQGoRFCHdbGxsVLt2bQ0ZMkTbtm1TcHCwhg0bplOnTqlRo0YqVaqUlixZor179+rLL7+UJLOpPNmzZzfrz2AwJLvvUcDi6Oioffv2af78+cqXL5+GDh2q0qVLm9YOsrCwkNFoNDv/8TVgnnbd5EKc51GiRAl16dJF3333ndatW6d169Zp06ZNSdoVK1ZMnTt31oABA5LU/kihQoXk6elpttna2mZYrW5ubrp3716SNZguXbqU7rWGnpeLi4sGDhyo4cOHpzkMDAoK0tGjR3Xu3Dlt3LhR1apVk/T/QdGJEyd09uxZ00LWcXFxKleuXJIw7ujRo3rzzTdTdc1n/Ty2b9+utm3bqkGDBlqxYoX279+vQYMGmf19kNL+dwIAAAAAMhpBETKMn5+fbt68qb179yohIUETJ05UxYoV5e3trfPnz2fINSwtLVWrVi19+umnOnDggE6dOqVff/1VkpQnTx5duHDB1DY2Nta0Jk1q+fj4JFkzaPfu3c9Vs5+fn6SHbx9LztChQ3X06FEtWLDgua6TXuXKlVP27Nm1fv16074jR47ozJkzqlSpUpbUJEndunWThYWFpkyZkqbzKleuLCsrK02bNk137txRuXLlJEnly5c3jVJ6NEVNejgF8NixY8qbN2+SQM7Z2dnUb1RUlG7fvm36vGPHDjk4OKhQoULy8vKSra2t2TN83LZt2+Tu7q5BgwYpMDBQXl5eqVrHCgAAAABeNMusLgD/PFevXtUbb7yhd955R6VKlZKjo6P27NmjTz/9VE2bNpWnp6fu37+vzz//XI0bN1ZERIRmzJjx3NddsWKF/vjjD1WtWlU5cuTQqlWrlJCQIB8fH0lSjRo1FBYWpsaNG8vFxUVDhw5VtmzZ0nSN9957T5MmTVL//v3VsWNHRUZGmqbTGQyGZ57/wQcfKH/+/KpRo4YKFiyoCxcuaNSoUcqTJ0+KoYurq6t69+6t8ePHp6nW1Lp27ZrOnDljCuuOHDki6eFIIjc3Nzk7O6tjx47q3bu3cubMKScnJ3Xr1k2VKlVSxYoVTf0cP35ccXFxunjxom7fvq3IyEhJD4MwKysrSQ8Xj753756uXbumGzdumNoEBASkuW4bGxsNHz5cH374YZrOs7W1VcWKFfX555+rSpUqpu+AlZWV2f5HI3Xatm2r8ePHq2nTphoxYoQKFiyo06dPa+nSperXr58KFiwo6eFouI4dO2rw4ME6deqUhg0bpq5du8rCwkI2Njbq37+/+vXrJysrK1WpUkVXrlzRoUOH1LFjR3l5eenMmTNasGCBypcvr5UrV+qHH35I8zMBAAAAgMzGiCKkmYODgypUqKDPPvtMVatWVYkSJTRkyBB17txZX3zxhUqXLq1JkyZp3LhxKlGihMLDwzV27Njnvq6Li4uWLl2qGjVqyNfXVzNmzND8+fPl7+8v6eEivtWqVVOjRo3UsGFDNWvWzGwNpNQoUqSIFi9erKVLl6pUqVKaPn266a1n1tbWzzy/Vq1a2rFjh9544w15e3urefPmsrGx0fr165UrV64Uz+vbt6/Z2kwZafny5SpTpowaNmwoSWrdurXKlCljFt599tlnatSokZo3b66qVavKzc1NS5cuNeunU6dOKlOmjGbOnKmjR4+qTJkyKlOmjNlosQYNGqhMmTL66aeftHHjRlOb9Grfvr2KFi2a5vOCgoJ048YN0/pEj1SrVk03btwwrU8kPVwra/PmzSpcuLBef/11+fr6qmPHjrpz547Z+j41a9aUl5eXqlatqlatWqlJkyYKCQkxHR8yZIj69OmjoUOHytfXV61atTKtJdSkSRP16tVLXbt2VUBAgLZt26YhQ4ak+b4AAAAAILMZjCktjAJAkjR69GjNmDGDt0fhHyk2NlbOzs7aNXi5HGzss7ocAJnMd1CNrC4BAAC8pB79bhATE/PUl94w9Qx4wrRp01S+fHnlypVLERERGj9+vLp27ZrVZQEAAAAAkOmYegY84dixY2ratKn8/Pw0cuRI9enTxzTFqH79+qZXqD+5jRkz5oXXumXLlhTryaypbOnl7++fYp3h4eGp6mPMmDEp9lG/fv1MvgMAAAAA+Pdj6hmQBufOnTN789XjcubMqZw5c77Qem7fvq1z586leNzT0/MFVvN0p0+f1v3795M95urqKkdHx2f2ce3aNV27di3ZY7a2tipQoMBz1fhvxNQz4L+FqWcAACAlTD0DMsHLFkTY2tq+VGHQ07i7uz93H1kRxgEAAADAfwlTzwAAAAAAACCJoAgAAAAAAACJCIoAAAAAAAAgiaAIAAAAAAAAiQiKAAAAAAAAIImgCAAAAAAAAIkIigAAAAAAACCJoAgAAAAAAACJCIoAAAAAAAAgSbLM6gIAAJnP56NqcnJyyuoyAAAAALzkGFEEAAAAAAAASQRFAAAAAAAASERQBAAAAAAAAEkERQAAAAAAAEhEUAQAAAAAAABJBEUAAAAAAABIRFAEAAAAAAAASQRFAAAAAAAASERQBAAAAAAAAEmSZVYXAADIfGPHjpW1tXVWlwEAAJAlQkJCsroE4B+DEUUAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQERQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQRFAEAAAAAACARARFAAAAAAAAkERQBAAAAAAAgEQERQAAAAAAAJBEUAQAAAAAAIBEBEUAAAAAAACQ9H/t3XlYldX+/vE3giC4EcSBIUUQR8wBHBBnFMXhKJ46hsqRnDPTkzmmqZimKccyy8pTKurJOYdMDSsOKJmJc5aoqRD2VZxR0USF/ftDeX5tAQVLsbxf17WvC55hP5+1W5vc915rPQqKRERERERERETkDgVFIiIiIiIiIiIC/AmCIisrK9atW/fQr9OqVSuGDRv20K8jIrn17t2brl27FnUZIiIiIiIiT7wiD4rOnj3Liy++iKenJ3Z2dri5uRESEsK2bdsAOHXqFB06dCjiKnOLj4/HysqK9PT0XPu8vLx45513HnlNhTFmzBi8vLy4cuWKxfbOnTvTokULsrOzAdi7dy/dunXD1dWVEiVKULVqVQYMGMCRI0eMc9auXUvjxo1xcnLC0dGRWrVqWYRuvXv3xsrKKtejVq1aBap169atdO7cGQ8Pj3yDQ7PZzMSJE3F3d8fe3p7g4GB++ukni2MuXLhAeHg4pUqVwtnZmX79+pGRkWHsj4+PJzQ0FHd3d0qWLEm9evVYsmRJgWqMiYnBysqKtLQ0i+3u7u54eXlZbEtJScHKyorY2Fgg/5By4cKFODs7G8fk9RrmPFq1anXfGvfv30+XLl0oX748JUqUwMvLi7CwMM6cOVOgNj5Ms2fPZuHChcbvDyu4LUh/FhEREREReZIVeVD07LPPsnfvXhYtWsSRI0dYv349rVq14vz58wC4ublhZ2dXxFX+9UyePBmTycTw4cONbQsWLCAuLo7o6GiKFSvGhg0baNy4MZmZmSxZsoSkpCQ++eQTnJycmDBhAgCxsbGEhYXx7LPPkpiYyO7du5k6dSo3b940nnf27NmcOnXKeJw4cQIXFxe6detWoFqvXr1K3bp1ef/99/M9JioqinfffZe5c+eyY8cOSpYsSUhICNevXzeOCQ8P58cff+Srr75iw4YNbN26lYEDBxr7v/32W+rUqcPq1av5/vvv6dOnDxEREWzYsOG+NTZr1gwbGxvi4+ONbUlJSfz6669cvHiRlJQUY3tcXBx2dnY0bdq0QO0HWLNmjfH6JSYmAvD1118b29asWXPP88+ePUubNm1wcXFh8+bNJCUlER0djYeHB1evXi1wHX+0rKwssrOzcXJyMkKxh6Ug/flxcuPGjaIuQUREREREnkBFGhSlp6eTkJDAjBkzCAoKolKlSjRq1IixY8fSpUsXwHLqWc5IjJUrV9K8eXPs7e1p2LAhR44cYefOnTRo0ACTyUSHDh04e/ascZ2caS2vv/465cqVo1SpUgwaNOieH8QyMzMZOXIkTz31FCVLliQgIMAiBCiM1NRUQkNDMZlMlCpViueee47Tp08b+ydNmkS9evVYsGABnp6emEwmBg8eTFZWFlFRUbi5uVG+fHmmTp2a6/Xr37+/0abWrVuzf//+AtVkZ2fHokWLWLRoETExMaSmpvLKK68QFRWFj48P165do0+fPnTs2JH169cTHByMt7c3AQEBzJw5k//85z8AfP755zRt2pRRo0ZRvXp1qlWrRteuXS1CHScnJ9zc3IzHrl27uHjxIn369ClQrR06dOCNN97g73//e577zWYz77zzDuPHjyc0NJQ6deqwePFiTp48afSdpKQkYmJimDdvHgEBATRr1oz33nuP5cuXc/LkSQDGjRvHlClTaNKkCT4+Prz88su0b9/+viEMgMlkomHDhhZ9JD4+nmbNmtG0adNc2xs3bkyJEiUK1H4AFxcX4/UrV64cAGXKlDG2ubi43PP8bdu2cenSJebNm4efnx/e3t4EBQUxa9YsvL29jeN++OEHOnTogMlkwtXVlV69enHu3Dljf3Z2NlFRUVSpUgU7Ozs8PT2NfpnXKLt9+/ZhZWVlBGU5o6TWr1+Pr68vdnZ2pKamWkw96927N1u2bGH27NnGiKnk5GSqVKnCzJkzLdqV8/xHjx69Z/sL2p+zsrLo168f3t7e2NvbU716dWbPnm3xXDm1Tps2DVdXV5ydnZk8eTK3bt1i1KhRuLi4UKFCBaKjoy3OO3HiBM899xzOzs64uLgQGhpqESDmPO/UqVPx8PCgevXqAPz3v/+lQYMGODo64ubmRs+ePR+LUWAiIiIiIvLXVKRBkclkwmQysW7dOjIzMwt8XmRkJOPHj2fPnj3Y2NjQs2dPRo8ezezZs0lISODo0aNMnDjR4pzY2FiSkpKIj49n2bJlrFmzhtdffz3fawwZMoTt27ezfPlyvv/+e7p160b79u1zTWe6n+zsbEJDQ7lw4QJbtmzhq6++4vjx44SFhVkcd+zYMb744gtiYmJYtmwZ8+fPp1OnTvzyyy9s2bKFGTNmMH78eHbs2GGc061bN86cOcMXX3zB7t278ff3p02bNly4cKFAtdWvX5+xY8fSv39/evXqRaNGjXjxxRcB2Lx5M+fOnWP06NF5npsz+sPNzY0ff/yRH374ocCvyfz58wkODqZSpUoFPudekpOTSUtLIzg42Njm5OREQEAA27dvB2D79u04OzvToEED45jg4GCKFStm8Zre7dKlS/cNYXIEBQURFxdn/B4XF0erVq1o2bKlxfb4+HiCgoIK3L4/gpubG7du3WLt2rWYzeY8j0lPT6d169b4+fmxa9cuYmJiOH36NM8995xxzNixY5k+fToTJkzg4MGDLF26FFdX10LVcu3aNWbMmMG8efP48ccfKV++vMX+2bNnExgYyIABA4wRU56envTt2zdX+BIdHU2LFi2oUqXKPa9Z0P6cnZ1NhQoVWLVqFQcPHmTixImMGzeOlStXWhz/v//9j5MnT7J161befvttIiMj+dvf/kbp0qXZsWMHgwYN4oUXXuCXX34B4ObNm4SEhODo6EhCQgLbtm3DZDLRvn17i8A6NjaWw4cPG6Pecs6dMmUK+/fvZ926daSkpNC7d+9825qZmcnly5ctHiIiIiIiIgVlU6QXt7Fh4cKFDBgwgLlz5+Lv70/Lli3p3r07derUyfe8kSNHEhISAsDLL79Mjx49iI2NNaby9OvXz2K9EwBbW1sWLFiAg4MDtWrVYvLkyYwaNYopU6ZQrJhlXpaamkp0dDSpqal4eHgY14yJiSE6Oppp06YZx1aoUCFXfdeuXTN+jo2N5cCBAyQnJ1OxYkUAFi9eTK1atdi5cycNGzYEbn9AXbBgAY6Ojvj6+hIUFMThw4fZtGkTxYoVo3r16syYMYO4uDgCAgL45ptvSExM5MyZM8bUvJkzZ7Ju3To+/fRTiylV9zJ+/Hiio6PZsWMHR44cwcrKCsAIxGrUqHHP84cOHUpCQgK1a9emUqVKNG7cmHbt2hEeHp7nlMGTJ0/yxRdfsHTp0gLVVxA56wLdHVi4uroa+9LS0nIFEjY2Nri4uORaVyjHypUr2blzpzHa5H6CgoKYNm0ap06dwt3dnS1btjBq1Chu3brFhx9+CMDx48dJTU3NFRR98MEHzJs3z2LbrVu3CjXq6F4aN27MuHHj6NmzJ4MGDaJRo0a0bt2aiIgI43WbM2cOfn5+Fv17wYIFVKxYkSNHjuDu7s7s2bOZM2cOzz//PAA+Pj40a9asULXcvHmTDz74gLp16+a538nJCVtbWxwcHHBzczO29+7dm4kTJ5KYmEijRo24efMmS5cuzTXKKC8F7c/Fixe3CJC9vb3Zvn07K1eutAjMXFxcePfdd433ZlRUFNeuXWPcuHHA/w/UvvnmG7p3786KFSvIzs5m3rx5xnssOjoaZ2dn4uPjadeuHQAlS5Zk3rx52NraGtfq27ev8XPlypV59913adiwIRkZGZhMplxtePPNN+8ZgouIiIiIiNzLY7FG0cmTJ1m/fj3t27cnPj4ef3//XEHPb/02RMr5kFu7dm2LbXdPzahbty4ODg7G74GBgWRkZHDixIlcz3/gwAGysrKoVq2aMerJZDKxZcsWjh07ZnFsQkIC+/bts3jkhEtwe8pTxYoVjZAIwNfXF2dnZ5KSkoxtXl5eODo6WrTB19fXIsT6bbv2799PRkYGZcqUsagxOTk5V4338tVXX5GWlkZ2djY7d+40tuc36uRuJUuWZOPGjRw9epTx48djMpkYMWIEjRo1sgjMcixatAhnZ+fH/g5XcXFx9OnTh48//rjAi243adIEW1tb4uPjOXjwIL/++iv+/v40aNCAs2fPkpycTHx8PPb29jRu3Nji3PDw8Fz9aPLkyX9om6ZOnUpaWhpz586lVq1azJ07lxo1anDgwAHgdp+Ki4uz6E85wcqxY8dISkoiMzOTNm3a/K46bG1t7xkE58fDw4NOnTqxYMEC4Pa0x8zMzAKtdVXQ/gzw/vvvU79+fcqVK4fJZOKjjz4iNTXV4phatWrlem/+9m+QtbU1ZcqUsXi/Hj16FEdHR+O1dXFx4fr16xbv19q1a1uERAC7d++mc+fOeHp64ujoSMuWLQFy1ZRj7NixXLp0yXjk9TdOREREREQkP0U6oihHiRIlaNu2LW3btmXChAn079+fyMjIfKdXFC9e3Pg559v5u7fl3LXrQWRkZGBtbc3u3buxtra22Hf3N/je3t65FuG1sSn8y/rb+uF2G/LaltOujIwM3N3d81w3qaCLAl+8eJEBAwYwfvx4zGYzgwcPpmXLlpQtW5Zq1aoBcOjQIQIDA+/7XD4+Pvj4+NC/f39ee+01qlWrxooVKyzWITKbzSxYsIBevXrl+jD8e+SMOjl9+jTu7u7G9tOnT1OvXj3jmLvDw1u3bnHhwgWLUSsAW7ZsoXPnzsyaNYuIiIgC1+Hg4ECjRo2Ii4vjwoULNGvWDGtra6ytrWnSpAlxcXHExcXRtGnTXO13cnLKNX3q7hFQf4QyZcrQrVs3unXrxrRp0/Dz82PmzJksWrSIjIwMOnfuzIwZM3Kd5+7uzvHjx+/53DnByW9Dmd8uap7D3t7eeN8WVs40yVmzZhEdHU1YWJhFAJyfgvbn5cuXM3LkSN566y0CAwNxdHTk3//+d67piQ/yfq1fv36ed9HLWXMKbgevv3X16lVCQkIICQlhyZIllCtXjtTUVEJCQvJdY83Ozk43ABARERERkQf2WARFd/P19c3zFui/x/79+/n111+xt7cH4LvvvsNkMlmM9Mnh5+dHVlYWZ86coXnz5r/rujVr1uTEiROcOHHCuNbBgwdJT0/H19f3gZ/X39+ftLQ0bGxsct1+vaCGDh2Km5ubMV3ms88+46WXXmLFihW0a9eOsmXLEhUVxdq1a3Odm56enm8g5eXlhYODQ667aW3ZsoWjR4/Sr1+/B6o3P97e3ri5uREbG2sEQ5cvX2bHjh3GmkuBgYGkp6eze/du6tevD9xeZyY7O5uAgADjueLj4/nb3/7GjBkzCjx977eCgoJYvnw5Fy9etLhlfYsWLYiPj2fLli0MGjTowRv7B7K1tcXHx8f47+Tv78/q1avx8vLKM+ysWrUq9vb2xMbG0r9//1z7cwKPU6dOUbp0aeD2YtMPWltWVlau7R07dqRkyZJ8+OGHxMTEsHXr1gI9X0H787Zt22jSpAmDBw829hVmhF5+/P39WbFiBeXLl6dUqVIFPu/QoUOcP3+e6dOnG38/du3a9bvrERERERERyU+RTj07f/48rVu35pNPPuH7778nOTmZVatWERUVRWho6B96rRs3btCvXz8OHjzIpk2biIyMZMiQIbnWJ4Lbow/Cw8OJiIhgzZo1JCcnk5iYyJtvvsnGjRsLdd3g4GBq165NeHg4e/bsITExkYiICFq2bGmxsHJhBQcHExgYSNeuXfnyyy9JSUnh22+/5bXXXivQB8m1a9eyatUqFi1ahI2NDTY2NixatIh169axevVqY62UjRs30qVLF77++mtSUlLYtWsXo0ePNsKOSZMmMXr0aOLj40lOTmbv3r307duXmzdv0rZtW4trzp8/n4CAAJ5++ulCtTUjI8OYjgW3F6/et2+fMfXGysqKYcOG8cYbb7B+/XoOHDhAREQEHh4exhS3mjVr0r59ewYMGEBiYiLbtm1jyJAhdO/e3ZgqGBcXR6dOnfjXv/7Fs88+S1paGmlpaQVeHBxuB0U//fQTmzdvNqYIAbRs2ZJ169Zx4sSJR76QNdy+Nfw///lPNmzYwJEjRzh8+DAzZ85k06ZNxnvtpZde4sKFC/To0YOdO3dy7NgxNm/eTJ8+fcjKyqJEiRKMGTOG0aNHs3jxYo4dO8Z3333H/PnzAahSpQoVK1Zk0qRJ/PTTT2zcuJG33nrrger18vJix44dpKSkcO7cOWNkjrW1Nb1792bs2LFUrVq1QKPdgAL356pVq7Jr1y42b97MkSNHmDBhgsWUzAcVHh5O2bJlCQ0NJSEhwZiG+K9//ctY8Dovnp6e2Nra8t5773H8+HHWr1/PlClTfnc9IiIiIiIi+Snyu54FBAQwa9YsWrRowdNPP82ECRMYMGAAc+bM+UOv1aZNG6pWrUqLFi0ICwujS5cuTJo0Kd/jo6OjiYiIYMSIEVSvXp2uXbuyc+dOPD09C3VdKysrPvvsM0qXLk2LFi0IDg6mcuXKrFix4ne1x8rKik2bNtGiRQv69OlDtWrV6N69Oz///PN970J17tw5Bg0aRGRkpEVoU7t2bSIjIxk8eDDnzp0jNDSUb7/9luLFi9OzZ09q1KhBjx49uHTpEm+88QZwOwA5fvw4ERER1KhRgw4dOpCWlsaXX35p3N4bbt89bPXq1Q80mmjXrl34+fnh5+cHwPDhw/Hz87O4s93o0aMZOnQoAwcONBb6jYmJsVgMesmSJdSoUYM2bdrQsWNHmjVrxkcffWTsX7RoEdeuXePNN9/E3d3deDzzzDMFrjUwMBA7OzvMZrMxcgkgICCAmzdvYjKZjAXMHyVfX18cHBwYMWIE9erVo3HjxqxcuZJ58+bRq1cv4PYaQNu2bSMrK4t27dpRu3Zthg0bhrOzsxGoTpgwgREjRjBx4kRq1qxJWFiYMaWvePHiLFu2jEOHDlGnTh1mzJhh9JPCGjlyJNbW1vj6+hrTrXL069ePGzduWExrLIiC9OcXXniBZ555hrCwMAICAjh//rzF6KIH5eDgwNatW/H09OSZZ56hZs2a9OvXj+vXr99zhFG5cuVYuHAhq1atwtfXl+nTpxdo8W4REREREZEHZWUuzCqvf1K9e/cmPT39D5/OJiKPXkJCAm3atOHEiRP3DUXl9jRMJycnXn31Va1dJCIiIk+sew0SEHlS5Hw2uHTp0j2/sH4s1ygSEblbZmYmZ8+eZdKkSXTr1k0hkYiIiIiIyENQpFPP5OGpVauWxW3Of/vI685LRSU1NTXfOk0mU763AC8K96ozISGhSGtbsmRJvrXVqlWrSGv7oyxbtoxKlSqRnp5OVFSUxb4nof0iIiIiIiKPwhMx9exJ9PPPP+d5a3IAV1dXHB0dH3FFebt16xYpKSn57s/vDlxF4ejRo/nue+qpp4w76hWFK1eucPr06Tz3FS9enEqVKj3iih6tJ73996KpZyIiIiKaeiYCmnr2xPuzfDC2sbGhSpUqRV1GgTzOdTo6Oj424V9ReNLbLyIiIiIi8kfR1DMREREREREREQEUFImIiIiIiIiIyB0KikREREREREREBFBQJCIiIiIiIiIidygoEhERERERERERQEGRiIiIiIiIiIjcoaBIREREREREREQABUUiIiIiIiIiInKHgiIREREREREREQHAymw2m4u6CBEReTguX76Mk5MTly5dolSpUkVdjoiIiIiIFJGCfjbQiCIREREREREREQEUFImIiIiIiIiIyB0KikREREREREREBFBQJCIiIiIiIiIidygoEhERERERERERQEGRiIiIiIiIiIjcoaBIREREREREREQABUUiIiIiIiIiInKHgiIREREREREREQEUFImIiIiIiIiIyB02RV2AiIg8fGvWBuHgYF3UZYiIiIg8FM91SyzqEkT+MjSiSEREREREREREAAVFIiIiIiIiIiJyh4IiEREREREREREBFBSJiIiIiIiIiMgdCopERERERERERARQUCQiIiIiIiIiIncoKBIREREREREREUBBkYiIiIiIiIiI3KGgSEREREREREREAAVFIiIiIiIiIiJyh4IiEREREREREREBFBSJiIiIiIiIiMgdCopERERERERERARQUCQiIiIiIiIiInc89kGRlZUV69ate+jXadWqFcOGDXvo1xGR3Hr37k3Xrl2LugwREREREZEnXpEHRWfPnuXFF1/E09MTOzs73NzcCAkJYdu2bQCcOnWKDh06FHGVucXHx2NlZUV6enqufV5eXrzzzjuPvKbCGDNmDF5eXly5csVie+fOnWnRogXZ2dkA7N27l27duuHq6kqJEiWoWrUqAwYM4MiRI8Y5a9eupXHjxjg5OeHo6EitWrUsQrfevXtjZWWV61GrVq0C1bp161Y6d+6Mh4dHvsGh2Wxm4sSJuLu7Y29vT3BwMD/99JPFMRcuXCA8PJxSpUrh7OxMv379yMjIMPYfPnyYoKAgo62VK1dm/Pjx3Lx58741xsTEYGVlRVpamsV2d3d3vLy8LLalpKRgZWVFbGwskH9IuXDhQpydnY1j8noNcx6tWrW6b4379++nS5culC9fnhIlSuDl5UVYWBhnzpy577kP2+zZs1m4cKHx+8MKbgvSn0VERERERJ5kRR4UPfvss+zdu5dFixZx5MgR1q9fT6tWrTh//jwAbm5u2NnZFXGVfz2TJ0/GZDIxfPhwY9uCBQuIi4sjOjqaYsWKsWHDBho3bkxmZiZLliwhKSmJTz75BCcnJyZMmABAbGwsYWFhPPvssyQmJrJ7926mTp1qEa7Mnj2bU6dOGY8TJ07g4uJCt27dClTr1atXqVu3Lu+//36+x0RFRfHuu+8yd+5cduzYQcmSJQkJCeH69evGMeHh4fz444989dVXbNiwga1btzJw4EBjf/HixYmIiODLL7/k8OHDvPPOO3z88cdERkbet8ZmzZphY2NDfHy8sS0pKYlff/2VixcvkpKSYmyPi4vDzs6Opk2bFqj9AGvWrDFev8TERAC+/vprY9uaNWvuef7Zs2dp06YNLi4ubN68maSkJKKjo/Hw8ODq1asFruOPlpWVRXZ2Nk5OTkYo9rAUpD8/Tm7cuFHUJYiIiIiIyBOoSIOi9PR0EhISmDFjBkFBQVSqVIlGjRoxduxYunTpAlhOPcsZibFy5UqaN2+Ovb09DRs25MiRI+zcuZMGDRpgMpno0KEDZ8+eNa6TM63l9ddfp1y5cpQqVYpBgwbd84NYZmYmI0eO5KmnnqJkyZIEBARYhACFkZqaSmhoKCaTiVKlSvHcc89x+vRpY/+kSZOoV68eCxYswNPTE5PJxODBg8nKyiIqKgo3NzfKly/P1KlTc71+/fv3N9rUunVr9u/fX6Ca7OzsWLRoEYsWLSImJobU1FReeeUVoqKi8PHx4dq1a/Tp04eOHTuyfv16goOD8fb2JiAggJkzZ/Kf//wHgM8//5ymTZsyatQoqlevTrVq1ejatatFqOPk5ISbm5vx2LVrFxcvXqRPnz4FqrVDhw688cYb/P3vf89zv9ls5p133mH8+PGEhoZSp04dFi9ezMmTJ42+k5SURExMDPPmzSMgIIBmzZrx3nvvsXz5ck6ePAlA5cqV6dOnD3Xr1qVSpUp06dKF8PBwEhIS7lujyWSiYcOGFn0kPj6eZs2a0bRp01zbGzduTIkSJQrUfgAXFxfj9StXrhwAZcqUMba5uLjc8/xt27Zx6dIl5s2bh5+fH97e3gQFBTFr1iy8vb2N43744Qc6dOiAyWTC1dWVXr16ce7cOWN/dnY2UVFRVKlSBTs7Ozw9PY1+mdcou3379mFlZWUEZTmjpNavX4+vry92dnakpqZaTD3r3bs3W7ZsYfbs2caIqeTkZKpUqcLMmTMt2pXz/EePHr1n+wvan7OysujXrx/e3t7Y29tTvXp1Zs+ebfFcObVOmzYNV1dXnJ2dmTx5Mrdu3WLUqFG4uLhQoUIFoqOjLc47ceIEzz33HM7Ozri4uBAaGmoRIOY879SpU/Hw8KB69eoA/Pe//6VBgwY4Ojri5uZGz549H4tRYCIiIiIi8tdUpEGRyWTCZDKxbt06MjMzC3xeZGQk48ePZ8+ePdjY2NCzZ09Gjx7N7NmzSUhI4OjRo0ycONHinNjYWJKSkoiPj2fZsmWsWbOG119/Pd9rDBkyhO3bt7N8+XK+//57unXrRvv27XNNZ7qf7OxsQkNDuXDhAlu2bOGrr77i+PHjhIWFWRx37NgxvvjiC2JiYli2bBnz58+nU6dO/PLLL2zZsoUZM2Ywfvx4duzYYZzTrVs3zpw5wxdffMHu3bvx9/enTZs2XLhwoUC11a9fn7Fjx9K/f3969epFo0aNePHFFwHYvHkz586dY/To0XmemzP6w83NjR9//JEffvihwK/J/PnzCQ4OplKlSgU+516Sk5NJS0sjODjY2Obk5ERAQADbt28HYPv27Tg7O9OgQQPjmODgYIoVK2bxmv7W0aNHiYmJoWXLlgWqIygoiLi4OOP3uLg4WrVqRcuWLS22x8fHExQUVKg2/l5ubm7cunWLtWvXYjab8zwmPT2d1q1b4+fnx65du4iJieH06dM899xzxjFjx45l+vTpTJgwgYMHD7J06VJcXV0LVcu1a9eYMWMG8+bN48cff6R8+fIW+2fPnk1gYCADBgwwRkx5enrSt2/fXOFLdHQ0LVq0oEqVKve8ZkH7c3Z2NhUqVGDVqlUcPHiQiRMnMm7cOFauXGlx/P/+9z9OnjzJ1q1befvtt4mMjORvf/sbpUuXZseOHQwaNIgXXniBX375BYCbN28SEhKCo6MjCQkJbNu2DZPJRPv27S0C69jYWA4fPmyMess5d8qUKezfv59169aRkpJC7969821rZmYmly9ftniIiIiIiIgUlE2RXtzGhoULFzJgwADmzp2Lv78/LVu2pHv37tSpUyff80aOHElISAgAL7/8Mj169CA2NtaYytOvXz+L9U4AbG1tWbBgAQ4ODtSqVYvJkyczatQopkyZQrFilnlZamoq0dHRpKam4uHhYVwzJiaG6Ohopk2bZhxboUKFXPVdu3bN+Dk2NpYDBw6QnJxMxYoVAVi8eDG1atVi586dNGzYELj9AXXBggU4Ojri6+tLUFAQhw8fZtOmTRQrVozq1aszY8YM4uLiCAgI4JtvviExMZEzZ84YU/NmzpzJunXr+PTTTy2mVN3L+PHjiY6OZseOHRw5cgQrKysAIxCrUaPGPc8fOnQoCQkJ1K5dm0qVKtG4cWPatWtHeHh4nlMGT548yRdffMHSpUsLVF9B5KwLdHdg4erqauxLS0vLFUjY2Njg4uKSa12hJk2asGfPHjIzMxk4cCCTJ08uUB1BQUFMmzaNU6dO4e7uzpYtWxg1ahS3bt3iww8/BOD48eOkpqbmCoo++OAD5s2bZ7Ht1q1bhRp1dC+NGzdm3Lhx9OzZk0GDBtGoUSNat25NRESE8brNmTMHPz8/i/69YMECKlasyJEjR3B3d2f27NnMmTOH559/HgAfHx+aNWtWqFpu3rzJBx98QN26dfPc7+TkhK2tLQ4ODri5uRnbe/fuzcSJE0lMTKRRo0bcvHmTpUuX5hpllJeC9ufixYtbBMje3t5s376dlStXWgRmLi4uvPvuu8Z7MyoqimvXrjFu3Djg/wdq33zzDd27d2fFihVkZ2czb9484z0WHR2Ns7Mz8fHxtGvXDoCSJUsyb948bG1tjWv17dvX+Lly5cq8++67NGzYkIyMDEwmU642vPnmm/cMwUVERERERO7lsVij6OTJk6xfv5727dsTHx+Pv79/rqDnt34bIuV8yK1du7bFtrunZtStWxcHBwfj98DAQDIyMjhx4kSu5z9w4ABZWVlUq1bNGPVkMpnYsmULx44dszg2ISGBffv2WTxywiW4PeWpYsWKRkgE4Ovri7OzM0lJScY2Ly8vHB0dLdrg6+trEWL9tl379+8nIyODMmXKWNSYnJycq8Z7+eqrr0hLSyM7O5udO3ca2/MbdXK3kiVLsnHjRo4ePcr48eMxmUyMGDGCRo0aWQRmORYtWoSzs/NjfYerFStWsGfPHpYuXcrGjRsLFETA7YDJ1taW+Ph4Dh48yK+//oq/vz8NGjTg7NmzJCcnEx8fj729PY0bN7Y4Nzw8PFc/KmhAVVBTp04lLS2NuXPnUqtWLebOnUuNGjU4cOAAcLtPxcXFWfSnnGDl2LFjJCUlkZmZSZs2bX5XHba2tvcMgvPj4eFBp06dWLBgAXB72mNmZmaB1roqaH8GeP/996lfvz7lypXDZDLx0UcfkZqaanFMrVq1cr03f/s3yNramjJlyli8X48ePYqjo6Px2rq4uHD9+nWL92vt2rUtQiKA3bt307lzZzw9PXF0dDRGuN1dU46xY8dy6dIl45HX3zgREREREZH8FOmIohwlSpSgbdu2tG3blgkTJtC/f38iIyPznV5RvHhx4+ecb+fv3pZz164HkZGRgbW1Nbt378ba2tpi393f4Ht7e+dahNfGpvAv62/rh9ttyGtbTrsyMjJwd3fPc92kgi4KfPHiRQYMGMD48eMxm80MHjyYli1bUrZsWapVqwbAoUOHCAwMvO9z+fj44OPjQ//+/XnttdeoVq0aK1assFiHyGw2s2DBAnr16pXrw/DvkTPq5PTp07i7uxvbT58+Tb169Yxj7g4Pb926xYULFyxGrQBGqOfr60tWVhYDBw5kxIgRufrC3RwcHGjUqBFxcXFcuHCBZs2aYW1tjbW1NU2aNCEuLo64uDiaNm2aq/1OTk65pk/dPQLqj1CmTBm6detGt27dmDZtGn5+fsycOZNFixaRkZFB586dmTFjRq7z3N3dOX78+D2fOyc4+W0ok9cd4+zt7Y33bWHlTJOcNWsW0dHRhIWFWQTA+Slof16+fDkjR47krbfeIjAwEEdHR/7973/nmp74IO/X+vXrs2TJklzXzFlzCm4Hr7919epVQkJCCAkJYcmSJZQrV47U1FRCQkLyXWPNzs5ONwAQEREREZEH9lgERXfz9fXN8xbov8f+/fv59ddfsbe3B+C7777DZDJZjPTJ4efnR1ZWFmfOnKF58+a/67o1a9bkxIkTnDhxwrjWwYMHSU9Px9fX94Gf19/fn7S0NGxsbHLdfr2ghg4dipubmzFd5rPPPuOll15ixYoVtGvXjrJlyxIVFcXatWtznZuenp5vIOXl5YWDg0Ouu2lt2bKFo0eP0q9fvweqNz/e3t64ubkRGxtrBEOXL19mx44dxppLgYGBpKens3v3burXrw/cXmcmOzubgICAfJ87Ozubmzdvkp2dfd+gCG5PP1u+fDkXL160uGV9ixYtiI+PZ8uWLQwaNOjBG/sHsrW1xcfHx/jv5O/vz+rVq/Hy8soz7KxatSr29vbExsbSv3//XPtzAo9Tp05RunRp4PZi0w9aW1ZWVq7tHTt2pGTJknz44YfExMSwdevWAj1fQfvztm3baNKkCYMHDzb2FWaEXn78/f1ZsWIF5cuXp1SpUgU+79ChQ5w/f57p06cbfz927dr1u+sRERERERHJT5FOPTt//jytW7fmk08+4fvvvyc5OZlVq1YRFRVFaGjoH3qtGzdu0K9fPw4ePMimTZuIjIxkyJAhudYngtujD8LDw4mIiGDNmjUkJyeTmJjIm2++ycaNGwt13eDgYGrXrk14eDh79uwhMTGRiIgIWrZsabGwcmEFBwcTGBhI165d+fLLL0lJSeHbb7/ltddeK9AHybVr17Jq1SoWLVqEjY0NNjY2LFq0iHXr1rF69WpjrZSNGzfSpUsXvv76a1JSUti1axejR482wo5JkyYxevRo4uPjSU5OZu/evfTt25ebN2/Stm1bi2vOnz+fgIAAnn766UK1NSMjw5iOBbcXr963b58x9cbKyophw4bxxhtvsH79eg4cOEBERAQeHh7GFLeaNWvSvn17BgwYQGJiItu2bWPIkCF0797dmCq4ZMkSVq5cSVJSEsePH2flypWMHTuWsLCwXKNF8hMUFMRPP/3E5s2bLRbBbtmyJevWrePEiROPfCFruH1r+H/+859s2LCBI0eOcPjwYWbOnMmmTZuM99pLL73EhQsX6NGjBzt37uTYsWNs3ryZPn36kJWVRYkSJRgzZgyjR49m8eLFHDt2jO+++4758+cDUKVKFSpWrMikSZP46aef2LhxI2+99dYD1evl5cWOHTtISUnh3Llzxsgca2trevfuzdixY6latWqBRrsBBe7PVatWZdeuXWzevJkjR44wYcIEiymZDyo8PJyyZcsSGhpKQkKCMQ3xX//6l7HgdV48PT2xtbXlvffe4/jx46xfv54pU6b87npERERERETyU+R3PQsICGDWrFm0aNGCp59+mgkTJjBgwADmzJnzh16rTZs2VK1alRYtWhAWFkaXLl2YNGlSvsdHR0cTERHBiBEjqF69Ol27dmXnzp14enoW6rpWVlZ89tlnlC5dmhYtWhAcHEzlypVZsWLF72qPlZUVmzZtokWLFvTp04dq1arRvXt3fv755/vehercuXMMGjSIyMhIi9Cmdu3aREZGMnjwYM6dO0doaCjffvstxYsXp2fPntSoUYMePXpw6dIl3njjDeB2AHL8+HEiIiKoUaMGHTp0IC0tjS+//NK4vTfApUuXWL169QONJtq1axd+fn74+fkBMHz4cPz8/CzubDd69GiGDh3KwIEDjYV+Y2JiLBaDXrJkCTVq1KBNmzZ07NiRZs2a8dFHHxn7bWxsmDFjBo0aNaJOnTq8/vrrDBkyJNci0/cSGBiInZ0dZrPZGLkEEBAQwM2bNzGZTMYC5o+Sr68vDg4OjBgxgnr16tG4cWNWrlzJvHnz6NWrF3B7DaBt27aRlZVFu3btqF27NsOGDcPZ2dkIVCdMmMCIESOYOHEiNWvWJCwszJjSV7x4cZYtW8ahQ4eoU6cOM2bMMPpJYY0cORJra2t8fX2N6VY5+vXrx40bNyymNRZEQfrzCy+8wDPPPENYWBgBAQGcP3/eYnTRg3JwcGDr1q14enryzDPPULNmTfr168f169fvOcKoXLlyLFy4kFWrVuHr68v06dMLvGaWiIiIiIjIg7AyF2aV1z+p3r17k56e/odPZxORRy8hIYE2bdpw4sSJ+4aicnsappOTE9EL/XFwuP/0SREREZE/o+e6JRZ1CSKPvZzPBpcuXbrnF9aP5RpFIiJ3y8zM5OzZs0yaNIlu3bopJBIREREREXkIinTqmTw8tWrVsrjN+W8fed15qaikpqbmW6fJZMr3FuBF4V51JiQkFGltS5Ysybe2WrVqFWltf5Rly5ZRqVIl0tPTiYqKstj3JLRfRERERETkUXgipp49iX7++ec8b00O4OrqiqOj4yOuKG+3bt0iJSUl3/353YGrKBw9ejTffU899ZRxR72icOXKFU6fPp3nvuLFi1OpUqVHXNGj9aS3/1409UxERESeBJp6JnJ/mnr2hPuzfDC2sbGhSpUqRV1GgTzOdTo6Oj424V9ReNLbLyIiIiIi8kfR1DMREREREREREQEUFImIiIiIiIiIyB0KikREREREREREBFBQJCIiIiIiIiIidygoEhERERERERERQEGRiIiIiIiIiIjcoaBIREREREREREQABUUiIiIiIiIiInKHgiIREREREREREQEUFImIiIiIiIiIyB02RV2AiIg8fM/8PY5SpUoVdRkiIiIiIvKY04giEREREREREREBFBSJiIiIiIiIiMgdCopERERERERERATQGkUiIn9pZrMZgMuXLxdxJSIiIiIiUpRyPhPkfEbIj4IiEZG/sPPnzwNQsWLFIq5EREREREQeB1euXMHJySnf/QqKRET+wlxcXABITU295/8M5Mly+fJlKlasyIkTJ3Q3PLGgviF5Ub+QvKhfSH7UNx5fZrOZK1eu4OHhcc/jFBSJiPyFFSt2eyk6Jycn/Y9acilVqpT6heRJfUPyon4heVG/kPyobzyeCvLlsRazFhERERERERERQEGRiIiIiIiIiIjcoaBIROQvzM7OjsjISOzs7Iq6FHmMqF9IftQ3JC/qF5IX9QvJj/rGn5+V+X73RRMRERERERERkSeCRhSJiIiIiIiIiAigoEhERERERERERO5QUCQiIiIiIiIiIoCCIhERERERERERuUNBkYjIn9z777+Pl5cXJUqUICAggMTExHsev2rVKmrUqEGJEiWoXbs2mzZtekSVyqNUmH7x8ccf07x5c0qXLk3p0qUJDg6+bz+SP6/C/s3IsXz5cqysrOjatevDLVCKRGH7RXp6Oi+99BLu7u7Y2dlRrVo1/f/kL6iw/eKdd96hevXq2NvbU7FiRV555RWuX7/+iKqVR2Hr1q107twZDw8PrKysWLdu3X3PiY+Px9/fHzs7O6pUqcLChQsfep3y+ygoEhH5E1uxYgXDhw8nMjKSPXv2ULduXUJCQjhz5kyex3/77bf06NGDfv36sXfvXrp27UrXrl354YcfHnHl8jAVtl/Ex8fTo0cP4uLi2L59OxUrVqRdu3b83//93yOuXB62wvaNHCkpKYwcOZLmzZs/okrlUSpsv7hx4wZt27YlJSWFTz/9lMOHD/Pxxx/z1FNPPeLK5WEqbL9YunQpr776KpGRkSQlJTF//nxWrFjBuHHjHnHl8jBdvXqVunXr8v777xfo+OTkZDp16kRQUBD79u1j2LBh9O/fn82bNz/kSuX3sDKbzeaiLkJERB5MQEAADRs2ZM6cOQBkZ2dTsWJFhg4dyquvvprr+LCwMK5evcqGDRuMbY0bN6ZevXrMnTv3kdUtD1dh+8XdsrKyKF26NHPmzCEiIuJhlyuP0IP0jaysLFq0aEHfvn1JSEggPT29QN8gy59HYfvF3Llz+fe//82hQ4coXrz4oy5XHpHC9oshQ4aQlJREbGyssW3EiBHs2LGDb7755pHVLY+OlZUVa9euvedI0zFjxrBx40aLLyW7d+9Oeno6MTExj6BKeRAaUSQi8id148YNdu/eTXBwsLGtWLFiBAcHs3379jzP2b59u8XxACEhIfkeL38+D9Iv7nbt2jVu3ryJi4vLwypTisCD9o3JkydTvnx5+vXr9yjKlEfsQfrF+vXrCQwM5KWXXsLV1ZWnn36aadOmkZWV9ajKlofsQfpFkyZN2L17tzE97fjx42zatImOHTs+kprl8aR/e/452RR1ASIi8mDOnTtHVlYWrq6uFttdXV05dOhQnuekpaXleXxaWtpDq1MerQfpF3cbM2YMHh4euf5hJ39uD9I3vvnmG+bPn8++ffseQYVSFB6kXxw/fpz//e9/hIeHs2nTJo4ePcrgwYO5efMmkZGRj6JsecgepF/07NmTc+fO0axZM8xmM7du3WLQoEGaevaEy+/fnpcvX+bXX3/F3t6+iCqTe9GIIhERETFMnz6d5cuXs3btWkqUKFHU5UgRunLlCr169eLjjz+mbNmyRV2OPEays7MpX748H330EfXr1ycsLIzXXntNU5ifcPHx8UybNo0PPviAPXv2sGbNGjZu3MiUKVOKujQRKSSNKBIR+ZMqW7Ys1tbWnD592mL76dOncXNzy/McNze3Qh0vfz4P0i9yzJw5k+nTp/P1119Tp06dh1mmFIHC9o1jx46RkpJC586djW3Z2dkA2NjYcPjwYXx8fB5u0fLQPcjfDHd3d4oXL461tbWxrWbNmqSlpXHjxg1sbW0fas3y8D1Iv5gwYQK9evWif//+ANSuXZurV68ycOBAXnvtNYoV0xiFJ1F+//YsVaqURhM9xvRuFRH5k7K1taV+/foWi0ZmZ2cTGxtLYGBgnucEBgZaHA/w1Vdf5Xu8/Pk8SL8AiIqKYsqUKcTExNCgQYNHUao8YoXtGzVq1ODAgQPs27fPeHTp0sW4c03FihUfZfnykDzI34ymTZty9OhRIzgEOHLkCO7u7gqJ/iIepF9cu3YtVxiUEybq/klPLv3b80/KLCIif1rLly8329nZmRcuXGg+ePCgeeDAgWZnZ2dzWlqa2Ww2m3v16mV+9dVXjeO3bdtmtrGxMc+cOdOclJRkjoyMNBcvXtx84MCBomqCPASF7RfTp08329ramj/99FPzqVOnjMeVK1eKqgnykBS2b9zt+eefN4eGhj6iauVRKWy/SE1NNTs6OpqHDBliPnz4sHnDhg3m8uXLm994442iaoI8BIXtF5GRkWZHR0fzsmXLzMePHzd/+eWXZh8fH/Nzzz1XVE2Qh+DKlSvmvXv3mvfu3WsGzG+//bZ579695p9//tlsNpvNr776qrlXr17G8cePHzc7ODiYR40aZU5KSjK///77Zmtra3NMTExRNUEKQFPPRET+xMLCwjh79iwTJ04kLS2NevXqERMTYywamJqaavHtXpMmTVi6dCnjx49n3LhxVK1alXXr1vH0008XVRPkIShsv/jwww+5ceMG//jHPyyeJzIykkmTJj3K0uUhK2zfkCdDYftFxYoV2bx5M6+88gp16tThqaee4uWXX2bMmDFF1QR5CArbL8aPH4+VlRXjx4/n//7v/yhXrhydO3dm6tSpRdUEeQh27dpFUFCQ8fvw4cMBeP7551m4cCGnTp0iNTXV2O/t7c3GjRt55ZVXmD17NhUqVGDevHmEhIQ88tql4KzMZo0DFBERERERERERrVEkIiIiIiIiIiJ3KCgSERERERERERFAQZGIiIiIiIiIiNyhoEhERERERERERAAFRSIiIiIiIiIicoeCIhERERERERERARQUiYiIiIiIiIjIHQqKRERERERERESK2NatW+ncuTMeHh5YWVmxbt26Qj+H2Wxm5syZVKtWDTs7O5566immTp1aqOewKfRVRURERERERETkD3X16lXq1q1L3759eeaZZx7oOV5++WW+/PJLZs6cSe3atblw4QIXLlwo1HNYmc1m8wNdXURERERE/vJSUlLw9vZm79691KtXr6jLERF5IlhZWbF27Vq6du1qbMvMzOS1115j2bJlpKen8/TTTzNjxgxatWoFQFJSEnXq1OGHH36gevXqD3xtTT0TEREREREREXnMDRkyhO3bt7N8+XK+//57unXrRvv27fnpp58A+Pzzz6lcuTIbNmzA29sbLy8v+vfvX+gRRQqKREREREQeY9nZ2URFRVGlShXs7Ozw9PQ01ps4cOAArVu3xt7enjJlyjBw4EAyMjKMc1u1asWwYcMsnq9r16707t3b+N3Ly4tp06bRt29fHB0d8fT05KOPPjL2e3t7A+Dn54eVlZXxzbWIiDw6qampREdHs2rVKpo3b46Pjw8jR46kWbNmREdHA3D8+HF+/vlnVq1axeLFi1m4cCG7d+/mH//4R6GupaBIREREROQxNnbsWKZPn86ECRM4ePAgS5cuxdXVlatXrxISEkLp0qXZuXMnq1at4uuvv2bIkCGFvsZbb71FgwYN2Lt3L4MHD+bFF1/k8OHDACQmJgLw9ddfc+rUKdasWfOHtk9ERO7vwIEDZGVlUa1aNUwmk/HYsmULx44dA25/sZCZmcnixYtp3rw5rVq1Yv78+cTFxRl/0wtCi1mLiIiIiDymrly5wuzZs5kzZw7PP/88AD4+PjRr1oyPP/6Y69evs3jxYkqWLAnAnDlz6Ny5MzNmzMDV1bXA1+nYsSODBw8GYMyYMcyaNYu4uDiqV69OuXLlAChTpgxubm5/cAtFRKQgMjIysLa2Zvfu3VhbW1vsM5lMALi7u2NjY0O1atWMfTVr1gRuj0gq6LpFCopERERERB5TSUlJZGZm0qZNmzz31a1b1wiJAJo2bUp2djaHDx8uVFBUp04d42crKyvc3Nw4c+bM7yteRET+MH5+fmRlZXHmzBmaN2+e5zFNmzbl1q1bHDt2DB8fHwCOHDkCQKVKlQp8LQVFIiIiIiKPKXt7+991frFixbj7Jsc3b97MdVzx4sUtfreysiI7O/t3XVtERAonIyODo0ePGr8nJyezb98+XFxcqFatGuHh4URERPDWW2/h5+fH2bNniY2NpU6dOnTq1Ing4GD8/f3p27cv77zzDtnZ2bz00ku0bdvWYpTR/WiNIhERERGRx1TVqlWxt7cnNjY2176aNWuyf/9+rl69amzbtm0bxYoVM6YXlCtXjlOnThn7s7Ky+OGHHwpVg62trXGuiIg8PLt27cLPzw8/Pz8Ahg8fjp+fHxMnTgQgOjqaiIgIRowYQfXq1enatSs7d+7E09MTuP3lwOeff07ZsmVp0aIFnTp1ombNmixfvrxQdWhEkYiIiIjIY6pEiRKMGTOG0aNHY2trS9OmTTl79iw//vgj4eHhREZG8vzzzzNp0iTOnj3L0KFD6dWrlzHtrHXr1gwfPpyNGzfi4+PD22+/TXp6eqFqKF++PPb29sTExFChQgVKlCiBk5PTQ2itiMiTrVWrVrlGgf5W8eLFef3113n99dfzPcbDw4PVq1f/rjo0okhERERE5DE2YcIERowYwcSJE6lZsyZhYWGcOXMGBwcHNm/ezIULF2jYsCH/+Mc/aNOmDXPmzDHO7du3L88//zwRERG0bNmSypUrExQUVKjr29jY8O677/Kf//wHDw8PQkND/+gmiojIY8TKfK+4SkREREREREREnhgaUSQiIiIiIiIiIoCCIhERERERERERuUNBkYiIiIiIiIiIAAqKRERERERERETkDgVFIiIiIiIiIiICKCgSEREREREREZE7FBSJiIiIiIiIiAigoEhERERERERERO5QUCQiIiIiIiIiIoCCIhERERERERERuUNBkYiIiIiIiIiIAPD/AFfvljFRfsCbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sn.countplot(y=data['Device_Name'])\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sn.countplot(y=data['Attack_subType'])\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7062606, 27)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6440947, 27)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6440947, 27)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical or object fetaures  using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data['Device_Name'] = label_encoder.fit_transform(data['Device_Name'])\n",
    "data['Attack'] = label_encoder.fit_transform(data['Attack'])\n",
    "data['Attack_subType'] = label_encoder.fit_transform(data['Attack_subType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0                  1.000000         98.000000          0.000000e+00   \n",
       "1                  1.931640         98.000000          1.818989e-12   \n",
       "2                  2.904273         86.981750          2.311822e+02   \n",
       "3                  3.902546         83.655268          2.040614e+02   \n",
       "4                  4.902545         81.685828          1.775746e+02   \n",
       "...                     ...               ...                   ...   \n",
       "7062071            2.801727        294.039965          8.416085e+03   \n",
       "7062072            2.979945        215.501627          1.780468e+04   \n",
       "7062073            1.743927        281.157093          1.080196e+04   \n",
       "7062074            2.743925        298.957472          7.417844e+03   \n",
       "7062075            2.898497        216.515613          1.776208e+04   \n",
       "\n",
       "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
       "0             1.000000    98.000000     0.000000e+00        1.000000   \n",
       "1             1.931640    98.000000     1.818989e-12        1.931640   \n",
       "2             2.904273    86.981750     2.311822e+02        1.000000   \n",
       "3             3.902546    83.655268     2.040614e+02        1.000000   \n",
       "4             4.902545    81.685828     1.775746e+02        2.000000   \n",
       "...                ...          ...              ...             ...   \n",
       "7062071       2.801727   294.039965     8.416085e+03        1.214290   \n",
       "7062072       2.979945   215.501627     1.780468e+04        1.252204   \n",
       "7062073       1.743927   281.157093     1.080196e+04        1.214226   \n",
       "7062074       2.743925   298.957472     7.417844e+03        1.214226   \n",
       "7062075       2.898497   216.515613     1.776208e+04        1.216289   \n",
       "\n",
       "         HH_L0.1_mean   HH_L0.1_std  HH_L0.1_magnitude  ...  HpHp_L0.1_mean  \\\n",
       "0                98.0  0.000000e+00          98.000000  ...            98.0   \n",
       "1                98.0  1.348699e-06         138.592929  ...            98.0   \n",
       "2                66.0  0.000000e+00         114.856432  ...            66.0   \n",
       "3                74.0  0.000000e+00          74.000000  ...            74.0   \n",
       "4                74.0  9.536743e-07          74.000000  ...            74.0   \n",
       "...               ...           ...                ...  ...             ...   \n",
       "7062071         330.0  3.810000e-06         431.490440  ...           330.0   \n",
       "7062072          60.0  0.000000e+00          84.852814  ...            60.0   \n",
       "7062073         330.0  0.000000e+00         431.490440  ...           330.0   \n",
       "7062074         330.0  6.610000e-06         431.490440  ...           330.0   \n",
       "7062075          60.0  6.740000e-07          84.852814  ...            60.0   \n",
       "\n",
       "         HpHp_L0.1_std  HpHp_L0.1_magnitude  HpHp_L0.1_radius  \\\n",
       "0         0.000000e+00            98.000000      0.000000e+00   \n",
       "1         1.348699e-06           138.592929      1.818989e-12   \n",
       "2         0.000000e+00           114.856432      0.000000e+00   \n",
       "3         0.000000e+00            74.000000      0.000000e+00   \n",
       "4         0.000000e+00            74.000000      0.000000e+00   \n",
       "...                ...                  ...               ...   \n",
       "7062071   3.810000e-06           431.490440      2.060000e-11   \n",
       "7062072   0.000000e+00            84.852814      0.000000e+00   \n",
       "7062073   0.000000e+00           431.490440      2.910000e-11   \n",
       "7062074   6.610000e-06           431.490440      4.370000e-11   \n",
       "7062075   9.540000e-07            84.852814      9.090000e-13   \n",
       "\n",
       "         HpHp_L0.1_covariance  HpHp_L0.1_pcc  Device_Name  Attack  \\\n",
       "0                0.000000e+00   0.000000e+00            0       1   \n",
       "1                0.000000e+00   0.000000e+00            0       1   \n",
       "2                0.000000e+00   0.000000e+00            0       1   \n",
       "3                0.000000e+00   0.000000e+00            0       1   \n",
       "4                0.000000e+00   0.000000e+00            0       1   \n",
       "...                       ...            ...          ...     ...   \n",
       "7062071         -8.860000e-49  -6.090000e-38            8       0   \n",
       "7062072         -1.110000e-32   0.000000e+00            8       0   \n",
       "7062073         -1.430000e-28   0.000000e+00            8       0   \n",
       "7062074         -5.120000e-51   0.000000e+00            8       0   \n",
       "7062075         -6.450000e-36   0.000000e+00            8       0   \n",
       "\n",
       "         Attack_subType  label  \n",
       "0                     2      0  \n",
       "1                     2      0  \n",
       "2                     2      0  \n",
       "3                     2      0  \n",
       "4                     2      0  \n",
       "...                 ...    ...  \n",
       "7062071               0      1  \n",
       "7062072               0      1  \n",
       "7062073               0      1  \n",
       "7062074               0      1  \n",
       "7062075               0      1  \n",
       "\n",
       "[6440947 rows x 27 columns]>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6440947, 27)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data for outliers\n",
    "\n",
    "# Initializing the variables\n",
    "x={}\n",
    "X=[]\n",
    "\n",
    "# Calculating z-scores\n",
    "for i in data.columns.values:\n",
    "    data['z-scores']=(data[i]-data[i].mean())/(data[i].std())\n",
    "    outliers=np.abs(data['z-scores'] > 3).sum()\n",
    "    x[i]=outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MI_dir_L0.1_weight': 0, 'MI_dir_L0.1_mean': 887, 'MI_dir_L0.1_variance': 3942, 'H_L0.1_weight': 0, 'H_L0.1_mean': 887, 'H_L0.1_variance': 3942, 'HH_L0.1_weight': 0, 'HH_L0.1_mean': 1710, 'HH_L0.1_std': 60693, 'HH_L0.1_magnitude': 4859, 'HH_L0.1_radius': 51883, 'HH_L0.1_covariance': 6028, 'HH_L0.1_pcc': 74196, 'HH_jit_L0.1_weight': 0, 'HH_jit_L0.1_mean': 0, 'HH_jit_L0.1_variance': 153912, 'HpHp_L0.1_weight': 259771, 'HpHp_L0.1_mean': 2252, 'HpHp_L0.1_std': 46167, 'HpHp_L0.1_magnitude': 5931, 'HpHp_L0.1_radius': 33654, 'HpHp_L0.1_covariance': 22512, 'HpHp_L0.1_pcc': 33883, 'Device_Name': 0, 'Attack': 0, 'Attack_subType': 0, 'label': 513500}\n"
     ]
    }
   ],
   "source": [
    "for keys,values in x.items():\n",
    "    if values>0:\n",
    "        X.append(keys)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5465378\n"
     ]
    }
   ],
   "source": [
    "# Removing the outliers based on threshold criteria \n",
    "x=[]\n",
    "\n",
    "# if the data is less than or greater than the 2 standard deviation from mean then it is dropped\n",
    "thresh=2\n",
    "for i in data[X].columns.values:\n",
    "    upper=data[i].mean()+thresh*data[i].std()\n",
    "    lower=data[i].mean()-thresh*data[i].std()\n",
    "    data=data[(data[i]>lower)&(data[i]<upper)]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0                  1.000000         98.000000              0.000000   \n",
       "2                  2.904273         86.981750            231.182163   \n",
       "3                  3.902546         83.655268            204.061435   \n",
       "6                613.818538         74.095096              2.659110   \n",
       "7                614.778927         74.094941              2.654800   \n",
       "...                     ...               ...                   ...   \n",
       "6506669         5075.565056        391.477163          53804.160854   \n",
       "6506670         5076.183675        391.411862          53815.202870   \n",
       "6506671         5077.182249        391.346588          53826.232017   \n",
       "6506672         5078.181913        391.281339          53837.248304   \n",
       "6506673         5079.181578        391.216115          53848.251744   \n",
       "\n",
       "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
       "0             1.000000    98.000000         0.000000        1.000000   \n",
       "2             2.904273    86.981750       231.182163        1.000000   \n",
       "3             3.902546    83.655268       204.061435        1.000000   \n",
       "6           613.818538    74.095096         2.659110      610.152839   \n",
       "7           614.778927    74.094941         2.654800      611.113465   \n",
       "...                ...          ...              ...             ...   \n",
       "6506669    5075.565056   391.477163     53804.160854        1.000000   \n",
       "6506670    5076.183675   391.411862     53815.202870        1.000000   \n",
       "6506671    5077.182249   391.346588     53826.232017        1.000000   \n",
       "6506672    5078.181913   391.281339     53837.248304        1.000000   \n",
       "6506673    5079.181578   391.216115     53848.251744        1.000000   \n",
       "\n",
       "         HH_L0.1_mean  HH_L0.1_std  HH_L0.1_magnitude  ...  HpHp_L0.1_std  \\\n",
       "0                98.0     0.000000          98.000000  ...            0.0   \n",
       "2                66.0     0.000000         114.856432  ...            0.0   \n",
       "3                74.0     0.000000          74.000000  ...            0.0   \n",
       "6                74.0     0.000004          95.268043  ...            0.0   \n",
       "7                74.0     0.000004          95.268043  ...            0.0   \n",
       "...               ...          ...                ...  ...            ...   \n",
       "6506669          60.0     0.000000          60.000000  ...            0.0   \n",
       "6506670          60.0     0.000000          60.000000  ...            0.0   \n",
       "6506671          60.0     0.000000          60.000000  ...            0.0   \n",
       "6506672          60.0     0.000000          60.000000  ...            0.0   \n",
       "6506673          60.0     0.000000          60.000000  ...            0.0   \n",
       "\n",
       "         HpHp_L0.1_magnitude  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
       "0                  98.000000               0.0                   0.0   \n",
       "2                 114.856432               0.0                   0.0   \n",
       "3                  74.000000               0.0                   0.0   \n",
       "6                  74.000000               0.0                   0.0   \n",
       "7                  74.000000               0.0                   0.0   \n",
       "...                      ...               ...                   ...   \n",
       "6506669            60.000000               0.0                   0.0   \n",
       "6506670            60.000000               0.0                   0.0   \n",
       "6506671            60.000000               0.0                   0.0   \n",
       "6506672            60.000000               0.0                   0.0   \n",
       "6506673            60.000000               0.0                   0.0   \n",
       "\n",
       "         HpHp_L0.1_pcc  Device_Name  Attack  Attack_subType  label  z-scores  \n",
       "0                  0.0            0       1               2      0 -0.294331  \n",
       "2                  0.0            0       1               2      0 -0.294331  \n",
       "3                  0.0            0       1               2      0 -0.294331  \n",
       "6                  0.0            0       1               2      0 -0.294331  \n",
       "7                  0.0            0       1               2      0 -0.294331  \n",
       "...                ...          ...     ...             ...    ...       ...  \n",
       "6506669            0.0            8       2               8      0 -0.294331  \n",
       "6506670            0.0            8       2               8      0 -0.294331  \n",
       "6506671            0.0            8       2               8      0 -0.294331  \n",
       "6506672            0.0            8       2               8      0 -0.294331  \n",
       "6506673            0.0            8       2               8      0 -0.294331  \n",
       "\n",
       "[5465378 rows x 28 columns]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "res_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_dir_L0.1_weight      0\n",
      "MI_dir_L0.1_mean        0\n",
      "MI_dir_L0.1_variance    0\n",
      "H_L0.1_weight           0\n",
      "H_L0.1_mean             0\n",
      "H_L0.1_variance         0\n",
      "HH_L0.1_weight          0\n",
      "HH_L0.1_mean            0\n",
      "HH_L0.1_std             0\n",
      "HH_L0.1_magnitude       0\n",
      "HH_L0.1_radius          0\n",
      "HH_L0.1_covariance      0\n",
      "HH_L0.1_pcc             0\n",
      "HH_jit_L0.1_weight      0\n",
      "HH_jit_L0.1_mean        0\n",
      "HH_jit_L0.1_variance    0\n",
      "HpHp_L0.1_weight        0\n",
      "HpHp_L0.1_mean          0\n",
      "HpHp_L0.1_std           0\n",
      "HpHp_L0.1_magnitude     0\n",
      "HpHp_L0.1_radius        0\n",
      "HpHp_L0.1_covariance    0\n",
      "HpHp_L0.1_pcc           0\n",
      "Device_Name             0\n",
      "Attack                  0\n",
      "Attack_subType          0\n",
      "label                   0\n",
      "z-scores                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(res_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping z-scores and label columns as they are not required\n",
    "\n",
    "res_data.drop(['z-scores', 'label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5465378 entries, 0 to 5465377\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   MI_dir_L0.1_weight    float64\n",
      " 1   MI_dir_L0.1_mean      float64\n",
      " 2   MI_dir_L0.1_variance  float64\n",
      " 3   H_L0.1_weight         float64\n",
      " 4   H_L0.1_mean           float64\n",
      " 5   H_L0.1_variance       float64\n",
      " 6   HH_L0.1_weight        float64\n",
      " 7   HH_L0.1_mean          float64\n",
      " 8   HH_L0.1_std           float64\n",
      " 9   HH_L0.1_magnitude     float64\n",
      " 10  HH_L0.1_radius        float64\n",
      " 11  HH_L0.1_covariance    float64\n",
      " 12  HH_L0.1_pcc           float64\n",
      " 13  HH_jit_L0.1_weight    float64\n",
      " 14  HH_jit_L0.1_mean      float64\n",
      " 15  HH_jit_L0.1_variance  float64\n",
      " 16  HpHp_L0.1_weight      float64\n",
      " 17  HpHp_L0.1_mean        float64\n",
      " 18  HpHp_L0.1_std         float64\n",
      " 19  HpHp_L0.1_magnitude   float64\n",
      " 20  HpHp_L0.1_radius      float64\n",
      " 21  HpHp_L0.1_covariance  float64\n",
      " 22  HpHp_L0.1_pcc         float64\n",
      " 23  Device_Name           float64\n",
      " 24  Attack                float64\n",
      " 25  Attack_subType        float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "res_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into features and target feature \n",
    "X = res_data.drop(['Attack','Attack_subType'], axis=1)\n",
    "y_attack = res_data['Attack']\n",
    "y_subAttack = res_data['Attack_subType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for Attack: Index(['MI_dir_L0.1_weight', 'MI_dir_L0.1_mean', 'MI_dir_L0.1_variance',\n",
      "       'H_L0.1_weight', 'H_L0.1_mean', 'H_L0.1_variance', 'HH_L0.1_mean',\n",
      "       'HH_L0.1_magnitude', 'HpHp_L0.1_mean', 'HpHp_L0.1_magnitude'],\n",
      "      dtype='object')\n",
      "Selected Features for SubAttackType: Index(['MI_dir_L0.1_weight', 'MI_dir_L0.1_mean', 'MI_dir_L0.1_variance',\n",
      "       'H_L0.1_weight', 'H_L0.1_mean', 'H_L0.1_variance', 'HH_L0.1_weight',\n",
      "       'HH_L0.1_mean', 'HH_jit_L0.1_weight', 'HH_jit_L0.1_mean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new1 = selector.fit_transform(X, y_attack)\n",
    "selected_features_attack = X.columns[selector.get_support()]\n",
    "print(\"Selected Features for Attack:\", selected_features_attack)\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new2 = selector.fit_transform(X, y_subAttack)\n",
    "selected_features_sub = X.columns[selector.get_support()]\n",
    "print(\"Selected Features for SubAttackType:\", selected_features_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MI_dir_L0.1_mean', 'HH_L0.1_magnitude', 'HpHp_L0.1_mean', 'HH_L0.1_mean', 'H_L0.1_weight', 'HH_jit_L0.1_mean', 'H_L0.1_mean', 'MI_dir_L0.1_weight', 'H_L0.1_variance', 'HpHp_L0.1_magnitude', 'HH_L0.1_weight', 'MI_dir_L0.1_variance', 'HH_jit_L0.1_weight']\n"
     ]
    }
   ],
   "source": [
    "# Combining selected fetaures without any dupliacation\n",
    "\n",
    "all_selected_features = list(set(selected_features_attack) | set(selected_features_sub))\n",
    "print(all_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
      "0                  0.000000          0.097308              0.000000   \n",
      "1                  0.000213          0.069093              0.003262   \n",
      "2                  0.000324          0.060575              0.002880   \n",
      "3                  0.068502          0.036094              0.000038   \n",
      "4                  0.068609          0.036093              0.000037   \n",
      "...                     ...               ...                   ...   \n",
      "5465373            0.567244          0.848825              0.759266   \n",
      "5465374            0.567313          0.848658              0.759422   \n",
      "5465375            0.567425          0.848490              0.759578   \n",
      "5465376            0.567537          0.848323              0.759733   \n",
      "5465377            0.567648          0.848156              0.759888   \n",
      "\n",
      "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_mean  \\\n",
      "0             0.000000     0.097308         0.000000      0.075099   \n",
      "1             0.000213     0.069093         0.003262      0.011858   \n",
      "2             0.000324     0.060575         0.002880      0.027668   \n",
      "3             0.068502     0.036094         0.000038      0.027668   \n",
      "4             0.068609     0.036093         0.000037      0.027668   \n",
      "...                ...          ...              ...           ...   \n",
      "5465373       0.567244     0.848825         0.759266      0.000000   \n",
      "5465374       0.567313     0.848658         0.759422      0.000000   \n",
      "5465375       0.567425     0.848490         0.759578      0.000000   \n",
      "5465376       0.567537     0.848323         0.759733      0.000000   \n",
      "5465377       0.567648     0.848156         0.759888      0.000000   \n",
      "\n",
      "         HH_L0.1_magnitude  HpHp_L0.1_mean  HpHp_L0.1_magnitude  \\\n",
      "0                 0.075099        0.075099             0.075099   \n",
      "1                 0.108413        0.011858             0.108412   \n",
      "2                 0.027668        0.027668             0.027668   \n",
      "3                 0.069700        0.027668             0.027668   \n",
      "4                 0.069700        0.027668             0.027668   \n",
      "...                    ...             ...                  ...   \n",
      "5465373           0.000000        0.000000             0.000000   \n",
      "5465374           0.000000        0.000000             0.000000   \n",
      "5465375           0.000000        0.000000             0.000000   \n",
      "5465376           0.000000        0.000000             0.000000   \n",
      "5465377           0.000000        0.000000             0.000000   \n",
      "\n",
      "         MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
      "0                  0.000000          0.097308              0.000000   \n",
      "1                  0.000213          0.069093              0.003262   \n",
      "2                  0.000324          0.060575              0.002880   \n",
      "3                  0.068502          0.036094              0.000038   \n",
      "4                  0.068609          0.036093              0.000037   \n",
      "...                     ...               ...                   ...   \n",
      "5465373            0.567244          0.848825              0.759266   \n",
      "5465374            0.567313          0.848658              0.759422   \n",
      "5465375            0.567425          0.848490              0.759578   \n",
      "5465376            0.567537          0.848323              0.759733   \n",
      "5465377            0.567648          0.848156              0.759888   \n",
      "\n",
      "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
      "0             0.000000     0.097308         0.000000        0.000000   \n",
      "1             0.000213     0.069093         0.003262        0.000000   \n",
      "2             0.000324     0.060575         0.002880        0.000000   \n",
      "3             0.068502     0.036094         0.000038        0.076681   \n",
      "4             0.068609     0.036093         0.000037        0.076802   \n",
      "...                ...          ...              ...             ...   \n",
      "5465373       0.567244     0.848825         0.759266        0.000000   \n",
      "5465374       0.567313     0.848658         0.759422        0.000000   \n",
      "5465375       0.567425     0.848490         0.759578        0.000000   \n",
      "5465376       0.567537     0.848323         0.759733        0.000000   \n",
      "5465377       0.567648     0.848156         0.759888        0.000000   \n",
      "\n",
      "         HH_L0.1_mean  HH_jit_L0.1_weight  HH_jit_L0.1_mean  \n",
      "0            0.075099            0.000000          0.998842  \n",
      "1            0.011858            0.000000          0.998842  \n",
      "2            0.027668            0.000000          0.998842  \n",
      "3            0.027668            0.076681          0.001515  \n",
      "4            0.027668            0.076802          0.001513  \n",
      "...               ...                 ...               ...  \n",
      "5465373      0.000000            0.000000          1.000000  \n",
      "5465374      0.000000            0.000000          1.000000  \n",
      "5465375      0.000000            0.000000          1.000000  \n",
      "5465376      0.000000            0.000000          1.000000  \n",
      "5465377      0.000000            0.000000          1.000000  \n",
      "\n",
      "[5465378 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames for the selected features\n",
    "df_attack = pd.DataFrame(X_new1, columns=selected_features_attack)\n",
    "df_subAttack = pd.DataFrame(X_new2, columns=selected_features_sub)\n",
    "\n",
    "# Concatenate DataFrames into a single DataFrame\n",
    "X_selected = pd.concat([df_attack, df_subAttack], axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_dir_L0.1_weight      0\n",
      "MI_dir_L0.1_mean        0\n",
      "MI_dir_L0.1_variance    0\n",
      "H_L0.1_weight           0\n",
      "H_L0.1_mean             0\n",
      "H_L0.1_variance         0\n",
      "HH_L0.1_mean            0\n",
      "HH_L0.1_magnitude       0\n",
      "HpHp_L0.1_mean          0\n",
      "HpHp_L0.1_magnitude     0\n",
      "MI_dir_L0.1_weight      0\n",
      "MI_dir_L0.1_mean        0\n",
      "MI_dir_L0.1_variance    0\n",
      "H_L0.1_weight           0\n",
      "H_L0.1_mean             0\n",
      "H_L0.1_variance         0\n",
      "HH_L0.1_weight          0\n",
      "HH_L0.1_mean            0\n",
      "HH_jit_L0.1_weight      0\n",
      "HH_jit_L0.1_mean        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_selected.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0                  0.000000          0.097308              0.000000   \n",
       "1                  0.000213          0.069093              0.003262   \n",
       "2                  0.000324          0.060575              0.002880   \n",
       "3                  0.068502          0.036094              0.000038   \n",
       "4                  0.068609          0.036093              0.000037   \n",
       "...                     ...               ...                   ...   \n",
       "5465373            0.567244          0.848825              0.759266   \n",
       "5465374            0.567313          0.848658              0.759422   \n",
       "5465375            0.567425          0.848490              0.759578   \n",
       "5465376            0.567537          0.848323              0.759733   \n",
       "5465377            0.567648          0.848156              0.759888   \n",
       "\n",
       "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_mean  \\\n",
       "0             0.000000     0.097308         0.000000      0.075099   \n",
       "1             0.000213     0.069093         0.003262      0.011858   \n",
       "2             0.000324     0.060575         0.002880      0.027668   \n",
       "3             0.068502     0.036094         0.000038      0.027668   \n",
       "4             0.068609     0.036093         0.000037      0.027668   \n",
       "...                ...          ...              ...           ...   \n",
       "5465373       0.567244     0.848825         0.759266      0.000000   \n",
       "5465374       0.567313     0.848658         0.759422      0.000000   \n",
       "5465375       0.567425     0.848490         0.759578      0.000000   \n",
       "5465376       0.567537     0.848323         0.759733      0.000000   \n",
       "5465377       0.567648     0.848156         0.759888      0.000000   \n",
       "\n",
       "         HH_L0.1_magnitude  HpHp_L0.1_mean  HpHp_L0.1_magnitude  \\\n",
       "0                 0.075099        0.075099             0.075099   \n",
       "1                 0.108413        0.011858             0.108412   \n",
       "2                 0.027668        0.027668             0.027668   \n",
       "3                 0.069700        0.027668             0.027668   \n",
       "4                 0.069700        0.027668             0.027668   \n",
       "...                    ...             ...                  ...   \n",
       "5465373           0.000000        0.000000             0.000000   \n",
       "5465374           0.000000        0.000000             0.000000   \n",
       "5465375           0.000000        0.000000             0.000000   \n",
       "5465376           0.000000        0.000000             0.000000   \n",
       "5465377           0.000000        0.000000             0.000000   \n",
       "\n",
       "         MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0                  0.000000          0.097308              0.000000   \n",
       "1                  0.000213          0.069093              0.003262   \n",
       "2                  0.000324          0.060575              0.002880   \n",
       "3                  0.068502          0.036094              0.000038   \n",
       "4                  0.068609          0.036093              0.000037   \n",
       "...                     ...               ...                   ...   \n",
       "5465373            0.567244          0.848825              0.759266   \n",
       "5465374            0.567313          0.848658              0.759422   \n",
       "5465375            0.567425          0.848490              0.759578   \n",
       "5465376            0.567537          0.848323              0.759733   \n",
       "5465377            0.567648          0.848156              0.759888   \n",
       "\n",
       "         H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  \\\n",
       "0             0.000000     0.097308         0.000000        0.000000   \n",
       "1             0.000213     0.069093         0.003262        0.000000   \n",
       "2             0.000324     0.060575         0.002880        0.000000   \n",
       "3             0.068502     0.036094         0.000038        0.076681   \n",
       "4             0.068609     0.036093         0.000037        0.076802   \n",
       "...                ...          ...              ...             ...   \n",
       "5465373       0.567244     0.848825         0.759266        0.000000   \n",
       "5465374       0.567313     0.848658         0.759422        0.000000   \n",
       "5465375       0.567425     0.848490         0.759578        0.000000   \n",
       "5465376       0.567537     0.848323         0.759733        0.000000   \n",
       "5465377       0.567648     0.848156         0.759888        0.000000   \n",
       "\n",
       "         HH_L0.1_mean  HH_jit_L0.1_weight  HH_jit_L0.1_mean  \n",
       "0            0.075099            0.000000          0.998842  \n",
       "1            0.011858            0.000000          0.998842  \n",
       "2            0.027668            0.000000          0.998842  \n",
       "3            0.027668            0.076681          0.001515  \n",
       "4            0.027668            0.076802          0.001513  \n",
       "...               ...                 ...               ...  \n",
       "5465373      0.000000            0.000000          1.000000  \n",
       "5465374      0.000000            0.000000          1.000000  \n",
       "5465375      0.000000            0.000000          1.000000  \n",
       "5465376      0.000000            0.000000          1.000000  \n",
       "5465377      0.000000            0.000000          1.000000  \n",
       "\n",
       "[5465378 rows x 20 columns]>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_attack = res_data['Attack']\n",
    "# y_subAttack = res_data['Attack_subType']\n",
    "\n",
    "# Split the data into training and testing data\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X_selected, y_attack, y_subAttack, test_size=0.2)\n",
    "\n",
    "# label encoding again to convert the data that is continous\n",
    "# X_train, X_test, y1_train, y1_test, y2_train, y2_test\n",
    "\n",
    "y1_train = label_encoder.fit_transform(y1_train)\n",
    "y2_train = label_encoder.fit_transform(y2_train)\n",
    "y1_test = label_encoder.fit_transform(y1_test)\n",
    "y2_test = label_encoder.fit_transform(y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Attack): 0.9999981703010586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################### MODEL 1 : RANDOM FOREST ##########################\n",
    "\n",
    "\n",
    "# Random Forest for SubAttack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train the Random Forest classifier for 'Attack'\n",
    "rf = RandomForestClassifier(n_estimators=75, n_jobs=-1, max_depth=10, random_state=42)  # Example: Use 100 trees\n",
    "rf.fit(X_train, y1_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top k most important features\n",
    "k = 5  # Adjust the number of features you want to select\n",
    "selected_features_indices = indices[:k]\n",
    "selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "\n",
    "rf.fit(X_train[selected_features], y1_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y1_pred_RF = rf.predict(X_test[selected_features])\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y1_pred_RF)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "#print(\"\\nClassification Report (Attack):\")\n",
    "#print(classification_report(y1_test, y1_pred_RF))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Scores: [0.99998902 0.99998536 0.99999085 0.99999177 0.99999268]\n",
      "Mean Cross-validation Score: 0.9999899366529771\n",
      "Standard Deviation of Cross-validation Scores: 2.587582572260995e-06\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- HH_L0.1_magnitude\n- HH_L0.1_mean\n- HH_L0.1_weight\n- HH_jit_L0.1_mean\n- HH_jit_L0.1_weight\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandard Deviation of Cross-validation Scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, std_cv_score)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Make predictions for 'Attack'\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m y1_pred_RF \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Evaluate the performance of the classifier for 'Attack'\u001b[39;00m\n\u001b[0;32m     47\u001b[0m accuracy_attack \u001b[38;5;241m=\u001b[39m accuracy_score(y1_test, y1_pred_RF)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:529\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    466\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    471\u001b[0m ):\n\u001b[0;32m    472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    533\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:462\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    458\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- HH_L0.1_magnitude\n- HH_L0.1_mean\n- HH_L0.1_weight\n- HH_jit_L0.1_mean\n- HH_jit_L0.1_weight\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Random Forest for SubAttack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest classifier for 'Attack'\n",
    "rf = RandomForestClassifier(n_estimators=75, n_jobs=-1, max_depth=5, random_state=42)  # Example: Use 100 trees\n",
    "rf.fit(X_train, y1_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top k most important features\n",
    "k = 5  # Adjust the number of features you want to select\n",
    "selected_features_indices = indices[:k]\n",
    "selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "\n",
    "#rf.fit(X_train[selected_features], y1_train)\n",
    "\n",
    "# Initialize the k-fold cross-validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(rf, X[selected_features], y_attack, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_cv_score = cv_scores.mean()\n",
    "std_cv_score = cv_scores.std()\n",
    "\n",
    "print(\"Mean Cross-validation Score:\", mean_cv_score)\n",
    "print(\"Standard Deviation of Cross-validation Scores:\", std_cv_score)\n",
    "\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y1_pred_RF = rf.predict(X_test[selected_features])\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y1_pred_RF)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "#print(\"\\nClassification Report (Attack):\")\n",
    "#print(classification_report(y1_test, y1_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (AttackSubType): 0.7970571122227549\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Random Forest classifier for 'Sub Attack'\n",
    "rf = RandomForestClassifier(n_estimators=75, n_jobs=-1, max_depth=5, random_state=42)  # Example: Use 100 trees\n",
    "rf.fit(X_train, y2_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top k most important features\n",
    "k = 5  # Adjust the number of features you want to select\n",
    "selected_features_indices = indices[:k]\n",
    "selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "rf.fit(X_train[selected_features], y2_train)\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y2_pred_RF = rf.predict(X_test[selected_features])\n",
    "\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y2_pred_RF)\n",
    "print(\"\\nAccuracy (AttackSubType):\", accuracy_subattack)\n",
    "#print(\"\\nClassification Report (AttackSubType):\")\n",
    "\n",
    "#print(classification_report(y2_test, y2_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Attack): 1.0\n",
      "\n",
      "Classification Report (Attack):\n",
      "\n",
      "Accuracy (AttackSubType): 0.8792224877318686\n",
      "\n",
      "Classification Report (AttackSubType):\n"
     ]
    }
   ],
   "source": [
    "###################### MODEL 2 : DECISION TREES ##########################\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train the Decision Tree classifier for 'Attack'\n",
    "dt_attack = DecisionTreeClassifier(max_depth=10, random_state=42)  # Example: Limit maximum depth to 5\n",
    "dt_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the Decision Tree classifier for 'AttackSubType'\n",
    "dt_subattack = DecisionTreeClassifier(max_depth=10, random_state=42)  # Example: Limit maximum depth to 5\n",
    "dt_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_DT = dt_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_DT)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "print(\"\\nClassification Report (Attack):\")\n",
    "#print(classification_report(y1_test, y_attack_pred_DT))\n",
    "\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_DT = dt_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_DT)\n",
    "print(\"\\nAccuracy (AttackSubType):\", accuracy_subattack)\n",
    "print(\"\\nClassification Report (AttackSubType):\")\n",
    "#print(classification_report(y2_test, y_subAttack_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train.dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Attack): 0.7626450493835745\n",
      "\n",
      "Accuracy (AttackSubType): 0.5715741631871892\n"
     ]
    }
   ],
   "source": [
    "###################### MODEL 3 : NAIVE BAYES ##########################\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create and train the Naive Bayes classifier for 'Attack'\n",
    "nb_attack = GaussianNB()\n",
    "nb_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the Naive Bayes classifier for 'AttackSubType'\n",
    "nb_subattack = GaussianNB()\n",
    "nb_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_NB = nb_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_NB)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "#print(\"\\nClassification Report (Attack):\")\n",
    "#print(classification_report(y1_test, y_attack_pred_NB))\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_NB = nb_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_NB)\n",
    "print(\"\\nAccuracy (AttackSubType):\", accuracy_subattack)\n",
    "#print(\"\\nClassification Report (AttackSubType):\")\n",
    "#print(classification_report(y2_test, y_subAttack_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### MODEL 5 : Gradient Boosting Classifier ##########################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and train the Gradient Boosting classifier for 'Attack'\n",
    "gb_attack = GradientBoostingClassifier()\n",
    "gb_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the Gradient Boosting classifier for 'AttackSubType'\n",
    "gb_subattack = GradientBoostingClassifier()\n",
    "gb_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_GB = gb_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_GB)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_GB = gb_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_GB)\n",
    "print(\"Accuracy (AttackSubType):\", accuracy_subattack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create and train the AdaBoost classifier for 'AttackSubType'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m adaboost_subattack \u001b[38;5;241m=\u001b[39m AdaBoostClassifier()\n\u001b[1;32m---> 11\u001b[0m \u001b[43madaboost_subattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Make predictions for 'Attack'\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_attack_pred_adaboost \u001b[38;5;241m=\u001b[39m adaboost_attack\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:578\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    576\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 578\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################### MODEL 6 : Ada Boosting Classifier ##########################\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create and train the AdaBoost classifier for 'Attack'\n",
    "adaboost_attack = AdaBoostClassifier()\n",
    "adaboost_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the AdaBoost classifier for 'AttackSubType'\n",
    "adaboost_subattack = AdaBoostClassifier()\n",
    "adaboost_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_adaboost = adaboost_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_adaboost)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_adaboost = adaboost_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_adaboost)\n",
    "print(\"Accuracy (AttackSubType):\", accuracy_subattack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### MODEL 7 : SVM ##########################\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the SVM classifier for 'Attack'\n",
    "svm_attack = SVC(probability=True)\n",
    "svm_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the SVM classifier for 'AttackSubType'\n",
    "svm_subattack = SVC(probability=True)\n",
    "svm_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_svm = svm_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_svm)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_svm = svm_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_svm)\n",
    "print(\"Accuracy (AttackSubType):\", accuracy_subattack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### MODEL 8 : MLPClassifier ##########################\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create and train the MLP classifier for 'Attack'\n",
    "mlp_attack = MLPClassifier(max_iter=10000)\n",
    "mlp_attack.fit(X_train, y1_train)\n",
    "\n",
    "# Create and train the MLP classifier for 'AttackSubType'\n",
    "mlp_subattack = MLPClassifier()\n",
    "mlp_subattack.fit(X_train, y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y_attack_pred_mlp = mlp_attack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y1_test, y_attack_pred_mlp)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "\n",
    "# Make predictions for 'AttackSubType'\n",
    "y_subAttack_pred_mlp = mlp_subattack.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier for 'AttackSubType'\n",
    "accuracy_subattack = accuracy_score(y2_test, y_subAttack_pred_mlp)\n",
    "print(\"Accuracy (AttackSubType):\", accuracy_subattack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Creating ENSEMBLE model ###########################\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10, random_state=42),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "attack_results = []\n",
    "\n",
    "# Train, test and evaluate each model\n",
    "for name, attack_model in models.items():\n",
    "    attack_model.fit(X_train, y1_train)\n",
    "\n",
    "    # selecting important features only to make model efficient\n",
    "\n",
    "    # Get feature importances\n",
    "    #importances = attack_model.feature_importances_\n",
    "\n",
    "    # Sort feature importances in descending order\n",
    "    #indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Select the top k most important features\n",
    "    #k = 5  # Adjust the number of features you want to select\n",
    "    #selected_features_indices = indices[:k]\n",
    "    #selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "    #attack_model.fit(X_train[selected_features], y1_train)\n",
    "\n",
    "    # Make predictions for 'Attack'\n",
    "    #y1_pred_RF = attack_model.predict(X_test[selected_features])\n",
    "\n",
    "    #### ends feature selection\n",
    "    y_pred = attack_model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y1_test, y_pred)\n",
    "    precision = precision_score(y1_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y1_test, y_pred, average='weighted')\n",
    "\n",
    "    attack_results.append({\n",
    "\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Attack Type :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.762436</td>\n",
       "      <td>0.846874</td>\n",
       "      <td>0.762436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall\n",
       "0         Decision Tree  1.000000   1.000000  1.000000\n",
       "1         Random Forest  1.000000   1.000000  1.000000\n",
       "2  Gaussian Naive Bayes  0.762436   0.846874  0.762436"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a DataFrame and sort by Accuracy\n",
    "final_results_df = pd.DataFrame(attack_results).sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Results for Attack Type :\")\n",
    "final_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a combined ensemble model using all other models\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "attack_ensemble_results =[]\n",
    "\n",
    "attack_ensemble_model = StackingClassifier(estimators=[(name, models[name])])\n",
    "attack_ensemble_model.fit(X_train, y1_train)\n",
    "y_pred_ensemble = attack_ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y1_test, y_pred_ensemble)\n",
    "precision_ensemble = precision_score(y1_test, y_pred_ensemble, average='weighted')\n",
    "recall_ensemble = recall_score(y1_test, y_pred_ensemble, average='weighted')\n",
    "\n",
    "# Add the ensemble model's results to the results list\n",
    "attack_ensemble_results.append({\n",
    "    'Model': 'Ensemble Model',\n",
    "    'Accuracy': accuracy_ensemble,\n",
    "    'Precision': precision_ensemble,\n",
    "    'Recall': recall_ensemble\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Attack Type ensemble model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Model</td>\n",
       "      <td>0.762273</td>\n",
       "      <td>0.846579</td>\n",
       "      <td>0.762273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision    Recall\n",
       "0  Ensemble Model  0.762273   0.846579  0.762273"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a DataFrame and sort by Accuracy\n",
    "en_final_results_df = pd.DataFrame(attack_ensemble_results).sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Results for Attack Type ensemble model:\")\n",
    "en_final_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble model to the disk\n",
    "import pickle\n",
    "file_path= 'attack_ensemble_model.sav'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(attack_ensemble_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Creating ENSEMBLE model for subattack type ###########################\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10, random_state=42),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "sub_attack_results = []\n",
    "\n",
    "# Train, test and evaluate each model\n",
    "for name, sub_attack_model in models.items():\n",
    "    sub_attack_model.fit(X_train, y2_train)\n",
    "\n",
    "    # selecting important features only to make model efficient\n",
    "\n",
    "    # Get feature importances\n",
    "    #importances = attack_model.feature_importances_\n",
    "\n",
    "    # Sort feature importances in descending order\n",
    "    #indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Select the top k most important features\n",
    "    #k = 5  # Adjust the number of features you want to select\n",
    "    #selected_features_indices = indices[:k]\n",
    "    #selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "    #attack_model.fit(X_train[selected_features], y1_train)\n",
    "\n",
    "    # Make predictions for 'Attack'\n",
    "    #y1_pred_RF = attack_model.predict(X_test[selected_features])\n",
    "\n",
    "    #### ends feature selection\n",
    "    y2_pred = sub_attack_model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y2_test, y2_pred)\n",
    "    precision = precision_score(y2_test, y2_pred, average='weighted')\n",
    "    recall = recall_score(y2_test, y2_pred, average='weighted')\n",
    "\n",
    "    sub_attack_results.append({\n",
    "\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Sub Attack Type :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.888768</td>\n",
       "      <td>0.897045</td>\n",
       "      <td>0.888768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.879297</td>\n",
       "      <td>0.887583</td>\n",
       "      <td>0.879297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.569628</td>\n",
       "      <td>0.474223</td>\n",
       "      <td>0.569628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall\n",
       "1         Random Forest  0.888768   0.897045  0.888768\n",
       "0         Decision Tree  0.879297   0.887583  0.879297\n",
       "2  Gaussian Naive Bayes  0.569628   0.474223  0.569628"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a DataFrame and sort by Accuracy\n",
    "final_sub_results_df = pd.DataFrame(sub_attack_results).sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Results for Sub Attack Type :\")\n",
    "final_sub_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used in the ensemble: Random Forest, Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# Get the top 3 models\n",
    "top_models = final_sub_results_df.head(2)['Model'].tolist()\n",
    "\n",
    "# Print the names of the models used in the ensemble\n",
    "print(f\"Models used in the ensemble: {', '.join(top_models)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m sub_attack_ensemble_results \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      7\u001b[0m sub_attack_ensemble_model \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39m[(name, models[name]) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m top_models])\n\u001b[1;32m----> 8\u001b[0m \u001b[43msub_attack_ensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m y_sub_pred_ensemble \u001b[38;5;241m=\u001b[39m sub_attack_ensemble_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate the ensemble model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:660\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    659\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:252\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[0;32m    249\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    250\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     )\n\u001b[1;32m--> 252\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    270\u001b[0m     meth\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 986\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1068\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1070\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:434\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating a combined ensemble model for subattack using all other models\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "sub_attack_ensemble_results =[]\n",
    "\n",
    "sub_attack_ensemble_model = StackingClassifier(estimators=[(name, models[name]) for name in top_models])\n",
    "sub_attack_ensemble_model.fit(X_train, y2_train)\n",
    "y_sub_pred_ensemble = sub_attack_ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y2_test, y_sub_pred_ensemble)\n",
    "precision_ensemble = precision_score(y2_test, y_sub_pred_ensemble, average='weighted')\n",
    "recall_ensemble = recall_score(y2_test, y_sub_pred_ensemble, average='weighted')\n",
    "\n",
    "# Add the ensemble model's results to the results list\n",
    "sub_attack_ensemble_results.append({\n",
    "    'Model': 'Ensemble Model',\n",
    "    'Accuracy': accuracy_ensemble,\n",
    "    'Precision': precision_ensemble,\n",
    "    'Recall': recall_ensemble\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Attack): 0.8483618705378217\n"
     ]
    }
   ],
   "source": [
    "###################### MODEL 1 : RANDOM FOREST ##########################\n",
    "\n",
    "\n",
    "# Random Forest for SubAttack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train the Random Forest classifier for 'Attack'\n",
    "sub_rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10, random_state=42)  # Example: Use 100 trees\n",
    "sub_rf.fit(X_train, y2_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = sub_rf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top k most important features\n",
    "k = 5  # Adjust the number of features you want to select\n",
    "selected_features_indices = indices[:k]\n",
    "selected_features = X_train.columns[selected_features_indices]\n",
    "\n",
    "\n",
    "sub_rf.fit(X_train[selected_features], y2_train)\n",
    "\n",
    "# Make predictions for 'Attack'\n",
    "y2_pred_RF = sub_rf.predict(X_test[selected_features])\n",
    "\n",
    "# Evaluate the performance of the classifier for 'Attack'\n",
    "accuracy_attack = accuracy_score(y2_test, y2_pred_RF)\n",
    "print(\"Accuracy (Attack):\", accuracy_attack)\n",
    "#print(\"\\nClassification Report (Attack):\")\n",
    "#print(classification_report(y1_test, y1_pred_RF))\n",
    "accuracy = accuracy_score(y2_test, y2_pred)\n",
    "precision = precision_score(y2_test, y2_pred, average='weighted')\n",
    "recall = recall_score(y2_test, y2_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble model to the disk\n",
    "import pickle\n",
    "file_path= 'sub_attack_ensemble_model.sav'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(sub_rf, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
